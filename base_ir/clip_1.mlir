module @compiled_clip {
  util.global private @_params.text_encoder_model.text_model.embeddings.token_embedding.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.embeddings.token_embedding.weight"> : tensor<49408x768xf16>
  util.global private @_params.text_encoder_model.text_model.embeddings.position_embedding.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.embeddings.position_embedding.weight"> : tensor<77x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.0.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.0.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.1.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.1.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.2.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.2.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.3.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.3.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.4.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.4.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.5.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.5.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.6.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.6.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.7.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.7.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.8.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.8.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.9.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.9.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.10.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.10.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.k_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.self_attn.k_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.k_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.self_attn.k_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.v_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.self_attn.v_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.v_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.self_attn.v_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.q_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.self_attn.q_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.q_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.self_attn.q_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.out_proj.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.self_attn.out_proj.weight"> : tensor<768x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.out_proj.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.self_attn.out_proj.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.layer_norm1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.layer_norm1.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.layer_norm1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.layer_norm1.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc1.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.mlp.fc1.weight"> : tensor<3072x768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc1.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.mlp.fc1.bias"> : tensor<3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.mlp.fc2.weight"> : tensor<768x3072xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.mlp.fc2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.layer_norm2.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.layer_norm2.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.encoder.layers.11.layer_norm2.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.encoder.layers.11.layer_norm2.bias"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.final_layer_norm.weight {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.final_layer_norm.weight"> : tensor<768xf16>
  util.global private @_params.text_encoder_model.text_model.final_layer_norm.bias {noinline} = #stream.parameter.named<"model"::"text_encoder_model.text_model.final_layer_norm.bias"> : tensor<768xf16>
  func.func @main(%arg0: tensor<1x64xi64>) -> (tensor<1x64x768xf16>, tensor<1x64x768xf16>) attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.return_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]}]"} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<1x64xi64> -> !torch.vtensor<[1,64],si64>
    %1:2 = call @forward(%0) : (!torch.vtensor<[1,64],si64>) -> (!torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>)
    %2 = torch_c.to_builtin_tensor %1#0 : !torch.vtensor<[1,64,768],f16> -> tensor<1x64x768xf16>
    %3 = torch_c.to_builtin_tensor %1#1 : !torch.vtensor<[1,64,768],f16> -> tensor<1x64x768xf16>
    return %2, %3 : tensor<1x64x768xf16>, tensor<1x64x768xf16>
  }
  func.func private @forward(%arg0: !torch.vtensor<[1,64],si64>) -> (!torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>) {
    %int-1 = torch.constant.int -1
    %int64 = torch.constant.int 64
    %0 = torch.prim.ListConstruct %int-1, %int64 : (!torch.int, !torch.int) -> !torch.list<int>
    %1 = torch.aten.view %arg0, %0 : !torch.vtensor<[1,64],si64>, !torch.list<int> -> !torch.vtensor<[1,64],si64>
    %2 = torch.vtensor.literal(dense_resource<torch_tensor_1_77_torch.int64> : tensor<1x77xsi64>) : !torch.vtensor<[1,77],si64>
    %int0 = torch.constant.int 0
    %int0_0 = torch.constant.int 0
    %int9223372036854775807 = torch.constant.int 9223372036854775807
    %int1 = torch.constant.int 1
    %3 = torch.aten.slice.Tensor %2, %int0, %int0_0, %int9223372036854775807, %int1 : !torch.vtensor<[1,77],si64>, !torch.int, !torch.int, !torch.int, !torch.int -> !torch.vtensor<[1,77],si64>
    %int1_1 = torch.constant.int 1
    %int0_2 = torch.constant.int 0
    %int64_3 = torch.constant.int 64
    %int1_4 = torch.constant.int 1
    %4 = torch.aten.slice.Tensor %3, %int1_1, %int0_2, %int64_3, %int1_4 : !torch.vtensor<[1,77],si64>, !torch.int, !torch.int, !torch.int, !torch.int -> !torch.vtensor<[1,64],si64>
    %_params.text_encoder_model.text_model.embeddings.token_embedding.weight = util.global.load @_params.text_encoder_model.text_model.embeddings.token_embedding.weight : tensor<49408x768xf16>
    %5 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.embeddings.token_embedding.weight : tensor<49408x768xf16> -> !torch.vtensor<[49408,768],f16>
    %int-1_5 = torch.constant.int -1
    %false = torch.constant.bool false
    %false_6 = torch.constant.bool false
    %6 = torch.aten.embedding %5, %1, %int-1_5, %false, %false_6 : !torch.vtensor<[49408,768],f16>, !torch.vtensor<[1,64],si64>, !torch.int, !torch.bool, !torch.bool -> !torch.vtensor<[1,64,768],f16>
    %_params.text_encoder_model.text_model.embeddings.position_embedding.weight = util.global.load @_params.text_encoder_model.text_model.embeddings.position_embedding.weight : tensor<77x768xf16>
    %7 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.embeddings.position_embedding.weight : tensor<77x768xf16> -> !torch.vtensor<[77,768],f16>
    %int-1_7 = torch.constant.int -1
    %false_8 = torch.constant.bool false
    %false_9 = torch.constant.bool false
    %8 = torch.aten.embedding %7, %4, %int-1_7, %false_8, %false_9 : !torch.vtensor<[77,768],f16>, !torch.vtensor<[1,64],si64>, !torch.int, !torch.bool, !torch.bool -> !torch.vtensor<[1,64,768],f16>
    %int1_10 = torch.constant.int 1
    %9 = torch.aten.add.Tensor %6, %8, %int1_10 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int64_11 = torch.constant.int 64
    %int64_12 = torch.constant.int 64
    %10 = torch.prim.ListConstruct %int64_11, %int64_12 : (!torch.int, !torch.int) -> !torch.list<int>
    %int64_13 = torch.constant.int 64
    %int1_14 = torch.constant.int 1
    %11 = torch.prim.ListConstruct %int64_13, %int1_14 : (!torch.int, !torch.int) -> !torch.list<int>
    %int6 = torch.constant.int 6
    %int0_15 = torch.constant.int 0
    %cpu = torch.constant.device "cpu"
    %false_16 = torch.constant.bool false
    %12 = torch.aten.empty_strided %10, %11, %int6, %int0_15, %cpu, %false_16 : !torch.list<int>, !torch.list<int>, !torch.int, !torch.int, !torch.Device, !torch.bool -> !torch.vtensor<[64,64],f32>
    %float-6.550400e04 = torch.constant.float -6.550400e+04
    %13 = torch.aten.fill.Scalar %12, %float-6.550400e04 : !torch.vtensor<[64,64],f32>, !torch.float -> !torch.vtensor<[64,64],f32>
    %int64_17 = torch.constant.int 64
    %none = torch.constant.none
    %none_18 = torch.constant.none
    %cpu_19 = torch.constant.device "cpu"
    %false_20 = torch.constant.bool false
    %14 = torch.aten.arange %int64_17, %none, %none_18, %cpu_19, %false_20 : !torch.int, !torch.none, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[64],si64>
    %int1_21 = torch.constant.int 1
    %int1_22 = torch.constant.int 1
    %15 = torch.aten.add.Scalar %14, %int1_21, %int1_22 : !torch.vtensor<[64],si64>, !torch.int, !torch.int -> !torch.vtensor<[64],si64>
    %int64_23 = torch.constant.int 64
    %int1_24 = torch.constant.int 1
    %16 = torch.prim.ListConstruct %int64_23, %int1_24 : (!torch.int, !torch.int) -> !torch.list<int>
    %17 = torch.aten.view %15, %16 : !torch.vtensor<[64],si64>, !torch.list<int> -> !torch.vtensor<[64,1],si64>
    %18 = torch.aten.lt.Tensor %14, %17 : !torch.vtensor<[64],si64>, !torch.vtensor<[64,1],si64> -> !torch.vtensor<[64,64],i1>
    %float0.000000e00 = torch.constant.float 0.000000e+00
    %int6_25 = torch.constant.int 6
    %int0_26 = torch.constant.int 0
    %cpu_27 = torch.constant.device "cpu"
    %none_28 = torch.constant.none
    %19 = torch.aten.scalar_tensor %float0.000000e00, %int6_25, %int0_26, %cpu_27, %none_28 : !torch.float, !torch.int, !torch.int, !torch.Device, !torch.none -> !torch.vtensor<[],f32>
    %20 = torch.aten.where.self %18, %19, %13 : !torch.vtensor<[64,64],i1>, !torch.vtensor<[],f32>, !torch.vtensor<[64,64],f32> -> !torch.vtensor<[64,64],f32>
    %int5 = torch.constant.int 5
    %21 = torch.prims.convert_element_type %20, %int5 : !torch.vtensor<[64,64],f32>, !torch.int -> !torch.vtensor<[64,64],f16>
    %int0_29 = torch.constant.int 0
    %22 = torch.aten.unsqueeze %21, %int0_29 : !torch.vtensor<[64,64],f16>, !torch.int -> !torch.vtensor<[1,64,64],f16>
    %int1_30 = torch.constant.int 1
    %23 = torch.aten.unsqueeze %22, %int1_30 : !torch.vtensor<[1,64,64],f16>, !torch.int -> !torch.vtensor<[1,1,64,64],f16>
    %int2 = torch.constant.int 2
    %int0_31 = torch.constant.int 0
    %int9223372036854775807_32 = torch.constant.int 9223372036854775807
    %int1_33 = torch.constant.int 1
    %24 = torch.aten.slice.Tensor %23, %int2, %int0_31, %int9223372036854775807_32, %int1_33 : !torch.vtensor<[1,1,64,64],f16>, !torch.int, !torch.int, !torch.int, !torch.int -> !torch.vtensor<[1,1,64,64],f16>
    %int3 = torch.constant.int 3
    %int0_34 = torch.constant.int 0
    %int9223372036854775807_35 = torch.constant.int 9223372036854775807
    %int1_36 = torch.constant.int 1
    %25 = torch.aten.slice.Tensor %24, %int3, %int0_34, %int9223372036854775807_35, %int1_36 : !torch.vtensor<[1,1,64,64],f16>, !torch.int, !torch.int, !torch.int, !torch.int -> !torch.vtensor<[1,1,64,64],f16>
    %int1_37 = torch.constant.int 1
    %int1_38 = torch.constant.int 1
    %int64_39 = torch.constant.int 64
    %int64_40 = torch.constant.int 64
    %26 = torch.prim.ListConstruct %int1_37, %int1_38, %int64_39, %int64_40 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_41 = torch.constant.bool false
    %27 = torch.aten.expand %25, %26, %false_41 : !torch.vtensor<[1,1,64,64],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,64,64],f16>
    %int6_42 = torch.constant.int 6
    %28 = torch.prims.convert_element_type %9, %int6_42 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_43 = torch.constant.int 2
    %29 = torch.prim.ListConstruct %int2_43 : (!torch.int) -> !torch.list<int>
    %int0_44 = torch.constant.int 0
    %true = torch.constant.bool true
    %result0, %result1 = torch.aten.var_mean.correction %28, %29, %int0_44, %true : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05 = torch.constant.float 1.000000e-05
    %int1_45 = torch.constant.int 1
    %30 = torch.aten.add.Scalar %result0, %float1.000000e-05, %int1_45 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %31 = torch.aten.rsqrt %30 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_46 = torch.constant.int 1
    %32 = torch.aten.sub.Tensor %9, %result1, %int1_46 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %33 = torch.aten.mul.Tensor %32, %31 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.0.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.layer_norm1.weight : tensor<768xf16>
    %34 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %35 = torch.aten.mul.Tensor %33, %34 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.0.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.layer_norm1.bias : tensor<768xf16>
    %36 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_47 = torch.constant.int 1
    %37 = torch.aten.add.Tensor %35, %36, %int1_47 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_48 = torch.constant.int 5
    %38 = torch.prims.convert_element_type %37, %int5_48 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_49 = torch.constant.int 5
    %39 = torch.prims.convert_element_type %result1, %int5_49 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_50 = torch.constant.int 5
    %40 = torch.prims.convert_element_type %31, %int5_50 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_51 = torch.constant.int 64
    %int768 = torch.constant.int 768
    %41 = torch.prim.ListConstruct %int64_51, %int768 : (!torch.int, !torch.int) -> !torch.list<int>
    %42 = torch.aten.view %38, %41 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.q_proj.weight : tensor<768x768xf16>
    %43 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_52 = torch.constant.int 0
    %int1_53 = torch.constant.int 1
    %44 = torch.aten.transpose.int %43, %int0_52, %int1_53 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.q_proj.bias : tensor<768xf16>
    %45 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_54 = torch.constant.int 6
    %46 = torch.prims.convert_element_type %45, %int6_54 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_55 = torch.constant.int 6
    %47 = torch.prims.convert_element_type %42, %int6_55 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_56 = torch.constant.int 6
    %48 = torch.prims.convert_element_type %44, %int6_56 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %49 = torch.aten.mm %47, %48 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_57 = torch.constant.int 1
    %50 = torch.aten.mul.Scalar %49, %int1_57 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_58 = torch.constant.int 1
    %51 = torch.aten.mul.Scalar %46, %int1_58 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_59 = torch.constant.int 1
    %52 = torch.aten.add.Tensor %50, %51, %int1_59 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_60 = torch.constant.int 5
    %53 = torch.prims.convert_element_type %52, %int5_60 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_61 = torch.constant.int 1
    %int64_62 = torch.constant.int 64
    %int768_63 = torch.constant.int 768
    %54 = torch.prim.ListConstruct %int1_61, %int64_62, %int768_63 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %55 = torch.aten.view %53, %54 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01 = torch.constant.float 1.250000e-01
    %56 = torch.aten.mul.Scalar %55, %float1.250000e-01 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_64 = torch.constant.int 64
    %int768_65 = torch.constant.int 768
    %57 = torch.prim.ListConstruct %int64_64, %int768_65 : (!torch.int, !torch.int) -> !torch.list<int>
    %58 = torch.aten.view %38, %57 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.k_proj.weight : tensor<768x768xf16>
    %59 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_66 = torch.constant.int 0
    %int1_67 = torch.constant.int 1
    %60 = torch.aten.transpose.int %59, %int0_66, %int1_67 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.k_proj.bias : tensor<768xf16>
    %61 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_68 = torch.constant.int 6
    %62 = torch.prims.convert_element_type %61, %int6_68 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_69 = torch.constant.int 6
    %63 = torch.prims.convert_element_type %58, %int6_69 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_70 = torch.constant.int 6
    %64 = torch.prims.convert_element_type %60, %int6_70 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %65 = torch.aten.mm %63, %64 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_71 = torch.constant.int 1
    %66 = torch.aten.mul.Scalar %65, %int1_71 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_72 = torch.constant.int 1
    %67 = torch.aten.mul.Scalar %62, %int1_72 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_73 = torch.constant.int 1
    %68 = torch.aten.add.Tensor %66, %67, %int1_73 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_74 = torch.constant.int 5
    %69 = torch.prims.convert_element_type %68, %int5_74 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_75 = torch.constant.int 1
    %int64_76 = torch.constant.int 64
    %int768_77 = torch.constant.int 768
    %70 = torch.prim.ListConstruct %int1_75, %int64_76, %int768_77 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %71 = torch.aten.view %69, %70 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_78 = torch.constant.int 1
    %int-1_79 = torch.constant.int -1
    %int12 = torch.constant.int 12
    %int64_80 = torch.constant.int 64
    %72 = torch.prim.ListConstruct %int1_78, %int-1_79, %int12, %int64_80 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %73 = torch.aten.view %71, %72 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_81 = torch.constant.int 1
    %int2_82 = torch.constant.int 2
    %74 = torch.aten.transpose.int %73, %int1_81, %int2_82 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_83 = torch.constant.int 0
    %75 = torch.aten.clone %74, %int0_83 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_84 = torch.constant.int 64
    %int768_85 = torch.constant.int 768
    %76 = torch.prim.ListConstruct %int64_84, %int768_85 : (!torch.int, !torch.int) -> !torch.list<int>
    %77 = torch.aten.view %38, %76 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.v_proj.weight : tensor<768x768xf16>
    %78 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_86 = torch.constant.int 0
    %int1_87 = torch.constant.int 1
    %79 = torch.aten.transpose.int %78, %int0_86, %int1_87 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.v_proj.bias : tensor<768xf16>
    %80 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_88 = torch.constant.int 6
    %81 = torch.prims.convert_element_type %80, %int6_88 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_89 = torch.constant.int 6
    %82 = torch.prims.convert_element_type %77, %int6_89 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_90 = torch.constant.int 6
    %83 = torch.prims.convert_element_type %79, %int6_90 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %84 = torch.aten.mm %82, %83 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_91 = torch.constant.int 1
    %85 = torch.aten.mul.Scalar %84, %int1_91 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_92 = torch.constant.int 1
    %86 = torch.aten.mul.Scalar %81, %int1_92 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_93 = torch.constant.int 1
    %87 = torch.aten.add.Tensor %85, %86, %int1_93 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_94 = torch.constant.int 5
    %88 = torch.prims.convert_element_type %87, %int5_94 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_95 = torch.constant.int 1
    %int64_96 = torch.constant.int 64
    %int768_97 = torch.constant.int 768
    %89 = torch.prim.ListConstruct %int1_95, %int64_96, %int768_97 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %90 = torch.aten.view %88, %89 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_98 = torch.constant.int 1
    %int-1_99 = torch.constant.int -1
    %int12_100 = torch.constant.int 12
    %int64_101 = torch.constant.int 64
    %91 = torch.prim.ListConstruct %int1_98, %int-1_99, %int12_100, %int64_101 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %92 = torch.aten.view %90, %91 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_102 = torch.constant.int 1
    %int2_103 = torch.constant.int 2
    %93 = torch.aten.transpose.int %92, %int1_102, %int2_103 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_104 = torch.constant.int 0
    %94 = torch.aten.clone %93, %int0_104 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_105 = torch.constant.int 1
    %int64_106 = torch.constant.int 64
    %int12_107 = torch.constant.int 12
    %int64_108 = torch.constant.int 64
    %95 = torch.prim.ListConstruct %int1_105, %int64_106, %int12_107, %int64_108 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %96 = torch.aten.view %56, %95 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_109 = torch.constant.int 1
    %int2_110 = torch.constant.int 2
    %97 = torch.aten.transpose.int %96, %int1_109, %int2_110 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_111 = torch.constant.int 0
    %98 = torch.aten.clone %97, %int0_111 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_112 = torch.constant.int 12
    %int-1_113 = torch.constant.int -1
    %int64_114 = torch.constant.int 64
    %99 = torch.prim.ListConstruct %int12_112, %int-1_113, %int64_114 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %100 = torch.aten.view %98, %99 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_115 = torch.constant.int 12
    %int-1_116 = torch.constant.int -1
    %int64_117 = torch.constant.int 64
    %101 = torch.prim.ListConstruct %int12_115, %int-1_116, %int64_117 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %102 = torch.aten.view %75, %101 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_118 = torch.constant.int 12
    %int-1_119 = torch.constant.int -1
    %int64_120 = torch.constant.int 64
    %103 = torch.prim.ListConstruct %int12_118, %int-1_119, %int64_120 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %104 = torch.aten.view %94, %103 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_121 = torch.constant.int 1
    %int2_122 = torch.constant.int 2
    %105 = torch.aten.transpose.int %102, %int1_121, %int2_122 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %106 = torch.aten.bmm %100, %105 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_123 = torch.constant.int 1
    %int12_124 = torch.constant.int 12
    %int64_125 = torch.constant.int 64
    %int64_126 = torch.constant.int 64
    %107 = torch.prim.ListConstruct %int1_123, %int12_124, %int64_125, %int64_126 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %108 = torch.aten.view %106, %107 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_127 = torch.constant.int 1
    %109 = torch.aten.add.Tensor %108, %27, %int1_127 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_128 = torch.constant.int 12
    %int64_129 = torch.constant.int 64
    %int64_130 = torch.constant.int 64
    %110 = torch.prim.ListConstruct %int12_128, %int64_129, %int64_130 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %111 = torch.aten.view %109, %110 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_131 = torch.constant.int -1
    %false_132 = torch.constant.bool false
    %112 = torch.aten._softmax %111, %int-1_131, %false_132 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %113 = torch.aten.detach %112 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_133 = torch.constant.none
    %114 = torch.aten.clone %112, %none_133 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %115 = torch.aten.bmm %114, %104 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_134 = torch.constant.int 1
    %int12_135 = torch.constant.int 12
    %int64_136 = torch.constant.int 64
    %int64_137 = torch.constant.int 64
    %116 = torch.prim.ListConstruct %int1_134, %int12_135, %int64_136, %int64_137 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %117 = torch.aten.view %115, %116 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_138 = torch.constant.int 1
    %int2_139 = torch.constant.int 2
    %118 = torch.aten.transpose.int %117, %int1_138, %int2_139 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_140 = torch.constant.int 0
    %119 = torch.aten.clone %118, %int0_140 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_141 = torch.constant.int 1
    %int64_142 = torch.constant.int 64
    %int768_143 = torch.constant.int 768
    %120 = torch.prim.ListConstruct %int1_141, %int64_142, %int768_143 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %121 = torch.aten._unsafe_view %119, %120 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_144 = torch.constant.int 64
    %int768_145 = torch.constant.int 768
    %122 = torch.prim.ListConstruct %int64_144, %int768_145 : (!torch.int, !torch.int) -> !torch.list<int>
    %123 = torch.aten.view %121, %122 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.out_proj.weight : tensor<768x768xf16>
    %124 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_146 = torch.constant.int 0
    %int1_147 = torch.constant.int 1
    %125 = torch.aten.transpose.int %124, %int0_146, %int1_147 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.self_attn.out_proj.bias : tensor<768xf16>
    %126 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_148 = torch.constant.int 6
    %127 = torch.prims.convert_element_type %126, %int6_148 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_149 = torch.constant.int 6
    %128 = torch.prims.convert_element_type %123, %int6_149 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_150 = torch.constant.int 6
    %129 = torch.prims.convert_element_type %125, %int6_150 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %130 = torch.aten.mm %128, %129 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_151 = torch.constant.int 1
    %131 = torch.aten.mul.Scalar %130, %int1_151 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_152 = torch.constant.int 1
    %132 = torch.aten.mul.Scalar %127, %int1_152 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_153 = torch.constant.int 1
    %133 = torch.aten.add.Tensor %131, %132, %int1_153 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_154 = torch.constant.int 5
    %134 = torch.prims.convert_element_type %133, %int5_154 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_155 = torch.constant.int 1
    %int64_156 = torch.constant.int 64
    %int768_157 = torch.constant.int 768
    %135 = torch.prim.ListConstruct %int1_155, %int64_156, %int768_157 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %136 = torch.aten.view %134, %135 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_158 = torch.constant.int 1
    %137 = torch.aten.add.Tensor %9, %136, %int1_158 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_159 = torch.constant.int 6
    %138 = torch.prims.convert_element_type %137, %int6_159 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_160 = torch.constant.int 2
    %139 = torch.prim.ListConstruct %int2_160 : (!torch.int) -> !torch.list<int>
    %int0_161 = torch.constant.int 0
    %true_162 = torch.constant.bool true
    %result0_163, %result1_164 = torch.aten.var_mean.correction %138, %139, %int0_161, %true_162 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_165 = torch.constant.float 1.000000e-05
    %int1_166 = torch.constant.int 1
    %140 = torch.aten.add.Scalar %result0_163, %float1.000000e-05_165, %int1_166 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %141 = torch.aten.rsqrt %140 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_167 = torch.constant.int 1
    %142 = torch.aten.sub.Tensor %137, %result1_164, %int1_167 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %143 = torch.aten.mul.Tensor %142, %141 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.0.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.layer_norm2.weight : tensor<768xf16>
    %144 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %145 = torch.aten.mul.Tensor %143, %144 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.0.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.layer_norm2.bias : tensor<768xf16>
    %146 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_168 = torch.constant.int 1
    %147 = torch.aten.add.Tensor %145, %146, %int1_168 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_169 = torch.constant.int 5
    %148 = torch.prims.convert_element_type %147, %int5_169 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_170 = torch.constant.int 5
    %149 = torch.prims.convert_element_type %result1_164, %int5_170 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_171 = torch.constant.int 5
    %150 = torch.prims.convert_element_type %141, %int5_171 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_172 = torch.constant.int 64
    %int768_173 = torch.constant.int 768
    %151 = torch.prim.ListConstruct %int64_172, %int768_173 : (!torch.int, !torch.int) -> !torch.list<int>
    %152 = torch.aten.view %148, %151 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc1.weight : tensor<3072x768xf16>
    %153 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_174 = torch.constant.int 0
    %int1_175 = torch.constant.int 1
    %154 = torch.aten.transpose.int %153, %int0_174, %int1_175 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc1.bias : tensor<3072xf16>
    %155 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_176 = torch.constant.int 6
    %156 = torch.prims.convert_element_type %155, %int6_176 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_177 = torch.constant.int 6
    %157 = torch.prims.convert_element_type %152, %int6_177 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_178 = torch.constant.int 6
    %158 = torch.prims.convert_element_type %154, %int6_178 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %159 = torch.aten.mm %157, %158 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_179 = torch.constant.int 1
    %160 = torch.aten.mul.Scalar %159, %int1_179 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_180 = torch.constant.int 1
    %161 = torch.aten.mul.Scalar %156, %int1_180 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_181 = torch.constant.int 1
    %162 = torch.aten.add.Tensor %160, %161, %int1_181 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_182 = torch.constant.int 5
    %163 = torch.prims.convert_element_type %162, %int5_182 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_183 = torch.constant.int 1
    %int64_184 = torch.constant.int 64
    %int3072 = torch.constant.int 3072
    %164 = torch.prim.ListConstruct %int1_183, %int64_184, %int3072 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %165 = torch.aten.view %163, %164 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00 = torch.constant.float 1.702000e+00
    %166 = torch.aten.mul.Scalar %165, %float1.702000e00 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %167 = torch.aten.sigmoid %166 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %168 = torch.aten.detach %167 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %169 = torch.aten.mul.Tensor %165, %167 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_185 = torch.constant.int 64
    %int3072_186 = torch.constant.int 3072
    %170 = torch.prim.ListConstruct %int64_185, %int3072_186 : (!torch.int, !torch.int) -> !torch.list<int>
    %171 = torch.aten.view %169, %170 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc2.weight : tensor<768x3072xf16>
    %172 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_187 = torch.constant.int 0
    %int1_188 = torch.constant.int 1
    %173 = torch.aten.transpose.int %172, %int0_187, %int1_188 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc2.bias : tensor<768xf16>
    %174 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.0.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_189 = torch.constant.int 6
    %175 = torch.prims.convert_element_type %174, %int6_189 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_190 = torch.constant.int 6
    %176 = torch.prims.convert_element_type %171, %int6_190 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_191 = torch.constant.int 6
    %177 = torch.prims.convert_element_type %173, %int6_191 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %178 = torch.aten.mm %176, %177 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_192 = torch.constant.int 1
    %179 = torch.aten.mul.Scalar %178, %int1_192 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_193 = torch.constant.int 1
    %180 = torch.aten.mul.Scalar %175, %int1_193 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_194 = torch.constant.int 1
    %181 = torch.aten.add.Tensor %179, %180, %int1_194 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_195 = torch.constant.int 5
    %182 = torch.prims.convert_element_type %181, %int5_195 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_196 = torch.constant.int 1
    %int64_197 = torch.constant.int 64
    %int768_198 = torch.constant.int 768
    %183 = torch.prim.ListConstruct %int1_196, %int64_197, %int768_198 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %184 = torch.aten.view %182, %183 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_199 = torch.constant.int 1
    %185 = torch.aten.add.Tensor %137, %184, %int1_199 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_200 = torch.constant.int 6
    %186 = torch.prims.convert_element_type %185, %int6_200 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_201 = torch.constant.int 2
    %187 = torch.prim.ListConstruct %int2_201 : (!torch.int) -> !torch.list<int>
    %int0_202 = torch.constant.int 0
    %true_203 = torch.constant.bool true
    %result0_204, %result1_205 = torch.aten.var_mean.correction %186, %187, %int0_202, %true_203 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_206 = torch.constant.float 1.000000e-05
    %int1_207 = torch.constant.int 1
    %188 = torch.aten.add.Scalar %result0_204, %float1.000000e-05_206, %int1_207 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %189 = torch.aten.rsqrt %188 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_208 = torch.constant.int 1
    %190 = torch.aten.sub.Tensor %185, %result1_205, %int1_208 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %191 = torch.aten.mul.Tensor %190, %189 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.1.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.layer_norm1.weight : tensor<768xf16>
    %192 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %193 = torch.aten.mul.Tensor %191, %192 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.1.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.layer_norm1.bias : tensor<768xf16>
    %194 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_209 = torch.constant.int 1
    %195 = torch.aten.add.Tensor %193, %194, %int1_209 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_210 = torch.constant.int 5
    %196 = torch.prims.convert_element_type %195, %int5_210 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_211 = torch.constant.int 5
    %197 = torch.prims.convert_element_type %result1_205, %int5_211 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_212 = torch.constant.int 5
    %198 = torch.prims.convert_element_type %189, %int5_212 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_213 = torch.constant.int 64
    %int768_214 = torch.constant.int 768
    %199 = torch.prim.ListConstruct %int64_213, %int768_214 : (!torch.int, !torch.int) -> !torch.list<int>
    %200 = torch.aten.view %196, %199 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.q_proj.weight : tensor<768x768xf16>
    %201 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_215 = torch.constant.int 0
    %int1_216 = torch.constant.int 1
    %202 = torch.aten.transpose.int %201, %int0_215, %int1_216 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.q_proj.bias : tensor<768xf16>
    %203 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_217 = torch.constant.int 6
    %204 = torch.prims.convert_element_type %203, %int6_217 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_218 = torch.constant.int 6
    %205 = torch.prims.convert_element_type %200, %int6_218 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_219 = torch.constant.int 6
    %206 = torch.prims.convert_element_type %202, %int6_219 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %207 = torch.aten.mm %205, %206 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_220 = torch.constant.int 1
    %208 = torch.aten.mul.Scalar %207, %int1_220 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_221 = torch.constant.int 1
    %209 = torch.aten.mul.Scalar %204, %int1_221 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_222 = torch.constant.int 1
    %210 = torch.aten.add.Tensor %208, %209, %int1_222 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_223 = torch.constant.int 5
    %211 = torch.prims.convert_element_type %210, %int5_223 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_224 = torch.constant.int 1
    %int64_225 = torch.constant.int 64
    %int768_226 = torch.constant.int 768
    %212 = torch.prim.ListConstruct %int1_224, %int64_225, %int768_226 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %213 = torch.aten.view %211, %212 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01_227 = torch.constant.float 1.250000e-01
    %214 = torch.aten.mul.Scalar %213, %float1.250000e-01_227 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_228 = torch.constant.int 64
    %int768_229 = torch.constant.int 768
    %215 = torch.prim.ListConstruct %int64_228, %int768_229 : (!torch.int, !torch.int) -> !torch.list<int>
    %216 = torch.aten.view %196, %215 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.k_proj.weight : tensor<768x768xf16>
    %217 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_230 = torch.constant.int 0
    %int1_231 = torch.constant.int 1
    %218 = torch.aten.transpose.int %217, %int0_230, %int1_231 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.k_proj.bias : tensor<768xf16>
    %219 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_232 = torch.constant.int 6
    %220 = torch.prims.convert_element_type %219, %int6_232 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_233 = torch.constant.int 6
    %221 = torch.prims.convert_element_type %216, %int6_233 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_234 = torch.constant.int 6
    %222 = torch.prims.convert_element_type %218, %int6_234 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %223 = torch.aten.mm %221, %222 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_235 = torch.constant.int 1
    %224 = torch.aten.mul.Scalar %223, %int1_235 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_236 = torch.constant.int 1
    %225 = torch.aten.mul.Scalar %220, %int1_236 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_237 = torch.constant.int 1
    %226 = torch.aten.add.Tensor %224, %225, %int1_237 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_238 = torch.constant.int 5
    %227 = torch.prims.convert_element_type %226, %int5_238 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_239 = torch.constant.int 1
    %int64_240 = torch.constant.int 64
    %int768_241 = torch.constant.int 768
    %228 = torch.prim.ListConstruct %int1_239, %int64_240, %int768_241 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %229 = torch.aten.view %227, %228 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_242 = torch.constant.int 1
    %int-1_243 = torch.constant.int -1
    %int12_244 = torch.constant.int 12
    %int64_245 = torch.constant.int 64
    %230 = torch.prim.ListConstruct %int1_242, %int-1_243, %int12_244, %int64_245 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %231 = torch.aten.view %229, %230 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_246 = torch.constant.int 1
    %int2_247 = torch.constant.int 2
    %232 = torch.aten.transpose.int %231, %int1_246, %int2_247 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_248 = torch.constant.int 0
    %233 = torch.aten.clone %232, %int0_248 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_249 = torch.constant.int 64
    %int768_250 = torch.constant.int 768
    %234 = torch.prim.ListConstruct %int64_249, %int768_250 : (!torch.int, !torch.int) -> !torch.list<int>
    %235 = torch.aten.view %196, %234 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.v_proj.weight : tensor<768x768xf16>
    %236 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_251 = torch.constant.int 0
    %int1_252 = torch.constant.int 1
    %237 = torch.aten.transpose.int %236, %int0_251, %int1_252 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.v_proj.bias : tensor<768xf16>
    %238 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_253 = torch.constant.int 6
    %239 = torch.prims.convert_element_type %238, %int6_253 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_254 = torch.constant.int 6
    %240 = torch.prims.convert_element_type %235, %int6_254 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_255 = torch.constant.int 6
    %241 = torch.prims.convert_element_type %237, %int6_255 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %242 = torch.aten.mm %240, %241 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_256 = torch.constant.int 1
    %243 = torch.aten.mul.Scalar %242, %int1_256 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_257 = torch.constant.int 1
    %244 = torch.aten.mul.Scalar %239, %int1_257 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_258 = torch.constant.int 1
    %245 = torch.aten.add.Tensor %243, %244, %int1_258 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_259 = torch.constant.int 5
    %246 = torch.prims.convert_element_type %245, %int5_259 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_260 = torch.constant.int 1
    %int64_261 = torch.constant.int 64
    %int768_262 = torch.constant.int 768
    %247 = torch.prim.ListConstruct %int1_260, %int64_261, %int768_262 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %248 = torch.aten.view %246, %247 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_263 = torch.constant.int 1
    %int-1_264 = torch.constant.int -1
    %int12_265 = torch.constant.int 12
    %int64_266 = torch.constant.int 64
    %249 = torch.prim.ListConstruct %int1_263, %int-1_264, %int12_265, %int64_266 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %250 = torch.aten.view %248, %249 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_267 = torch.constant.int 1
    %int2_268 = torch.constant.int 2
    %251 = torch.aten.transpose.int %250, %int1_267, %int2_268 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_269 = torch.constant.int 0
    %252 = torch.aten.clone %251, %int0_269 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_270 = torch.constant.int 1
    %int64_271 = torch.constant.int 64
    %int12_272 = torch.constant.int 12
    %int64_273 = torch.constant.int 64
    %253 = torch.prim.ListConstruct %int1_270, %int64_271, %int12_272, %int64_273 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %254 = torch.aten.view %214, %253 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_274 = torch.constant.int 1
    %int2_275 = torch.constant.int 2
    %255 = torch.aten.transpose.int %254, %int1_274, %int2_275 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_276 = torch.constant.int 0
    %256 = torch.aten.clone %255, %int0_276 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_277 = torch.constant.int 12
    %int-1_278 = torch.constant.int -1
    %int64_279 = torch.constant.int 64
    %257 = torch.prim.ListConstruct %int12_277, %int-1_278, %int64_279 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %258 = torch.aten.view %256, %257 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_280 = torch.constant.int 12
    %int-1_281 = torch.constant.int -1
    %int64_282 = torch.constant.int 64
    %259 = torch.prim.ListConstruct %int12_280, %int-1_281, %int64_282 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %260 = torch.aten.view %233, %259 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_283 = torch.constant.int 12
    %int-1_284 = torch.constant.int -1
    %int64_285 = torch.constant.int 64
    %261 = torch.prim.ListConstruct %int12_283, %int-1_284, %int64_285 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %262 = torch.aten.view %252, %261 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_286 = torch.constant.int 1
    %int2_287 = torch.constant.int 2
    %263 = torch.aten.transpose.int %260, %int1_286, %int2_287 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %264 = torch.aten.bmm %258, %263 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_288 = torch.constant.int 1
    %int12_289 = torch.constant.int 12
    %int64_290 = torch.constant.int 64
    %int64_291 = torch.constant.int 64
    %265 = torch.prim.ListConstruct %int1_288, %int12_289, %int64_290, %int64_291 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %266 = torch.aten.view %264, %265 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_292 = torch.constant.int 1
    %267 = torch.aten.add.Tensor %266, %27, %int1_292 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_293 = torch.constant.int 12
    %int64_294 = torch.constant.int 64
    %int64_295 = torch.constant.int 64
    %268 = torch.prim.ListConstruct %int12_293, %int64_294, %int64_295 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %269 = torch.aten.view %267, %268 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_296 = torch.constant.int -1
    %false_297 = torch.constant.bool false
    %270 = torch.aten._softmax %269, %int-1_296, %false_297 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %271 = torch.aten.detach %270 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_298 = torch.constant.none
    %272 = torch.aten.clone %270, %none_298 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %273 = torch.aten.bmm %272, %262 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_299 = torch.constant.int 1
    %int12_300 = torch.constant.int 12
    %int64_301 = torch.constant.int 64
    %int64_302 = torch.constant.int 64
    %274 = torch.prim.ListConstruct %int1_299, %int12_300, %int64_301, %int64_302 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %275 = torch.aten.view %273, %274 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_303 = torch.constant.int 1
    %int2_304 = torch.constant.int 2
    %276 = torch.aten.transpose.int %275, %int1_303, %int2_304 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_305 = torch.constant.int 0
    %277 = torch.aten.clone %276, %int0_305 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_306 = torch.constant.int 1
    %int64_307 = torch.constant.int 64
    %int768_308 = torch.constant.int 768
    %278 = torch.prim.ListConstruct %int1_306, %int64_307, %int768_308 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %279 = torch.aten._unsafe_view %277, %278 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_309 = torch.constant.int 64
    %int768_310 = torch.constant.int 768
    %280 = torch.prim.ListConstruct %int64_309, %int768_310 : (!torch.int, !torch.int) -> !torch.list<int>
    %281 = torch.aten.view %279, %280 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.out_proj.weight : tensor<768x768xf16>
    %282 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_311 = torch.constant.int 0
    %int1_312 = torch.constant.int 1
    %283 = torch.aten.transpose.int %282, %int0_311, %int1_312 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.self_attn.out_proj.bias : tensor<768xf16>
    %284 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_313 = torch.constant.int 6
    %285 = torch.prims.convert_element_type %284, %int6_313 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_314 = torch.constant.int 6
    %286 = torch.prims.convert_element_type %281, %int6_314 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_315 = torch.constant.int 6
    %287 = torch.prims.convert_element_type %283, %int6_315 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %288 = torch.aten.mm %286, %287 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_316 = torch.constant.int 1
    %289 = torch.aten.mul.Scalar %288, %int1_316 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_317 = torch.constant.int 1
    %290 = torch.aten.mul.Scalar %285, %int1_317 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_318 = torch.constant.int 1
    %291 = torch.aten.add.Tensor %289, %290, %int1_318 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_319 = torch.constant.int 5
    %292 = torch.prims.convert_element_type %291, %int5_319 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_320 = torch.constant.int 1
    %int64_321 = torch.constant.int 64
    %int768_322 = torch.constant.int 768
    %293 = torch.prim.ListConstruct %int1_320, %int64_321, %int768_322 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %294 = torch.aten.view %292, %293 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_323 = torch.constant.int 1
    %295 = torch.aten.add.Tensor %185, %294, %int1_323 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_324 = torch.constant.int 6
    %296 = torch.prims.convert_element_type %295, %int6_324 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_325 = torch.constant.int 2
    %297 = torch.prim.ListConstruct %int2_325 : (!torch.int) -> !torch.list<int>
    %int0_326 = torch.constant.int 0
    %true_327 = torch.constant.bool true
    %result0_328, %result1_329 = torch.aten.var_mean.correction %296, %297, %int0_326, %true_327 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_330 = torch.constant.float 1.000000e-05
    %int1_331 = torch.constant.int 1
    %298 = torch.aten.add.Scalar %result0_328, %float1.000000e-05_330, %int1_331 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %299 = torch.aten.rsqrt %298 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_332 = torch.constant.int 1
    %300 = torch.aten.sub.Tensor %295, %result1_329, %int1_332 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %301 = torch.aten.mul.Tensor %300, %299 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.1.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.layer_norm2.weight : tensor<768xf16>
    %302 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %303 = torch.aten.mul.Tensor %301, %302 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.1.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.layer_norm2.bias : tensor<768xf16>
    %304 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_333 = torch.constant.int 1
    %305 = torch.aten.add.Tensor %303, %304, %int1_333 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_334 = torch.constant.int 5
    %306 = torch.prims.convert_element_type %305, %int5_334 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_335 = torch.constant.int 5
    %307 = torch.prims.convert_element_type %result1_329, %int5_335 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_336 = torch.constant.int 5
    %308 = torch.prims.convert_element_type %299, %int5_336 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_337 = torch.constant.int 64
    %int768_338 = torch.constant.int 768
    %309 = torch.prim.ListConstruct %int64_337, %int768_338 : (!torch.int, !torch.int) -> !torch.list<int>
    %310 = torch.aten.view %306, %309 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc1.weight : tensor<3072x768xf16>
    %311 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_339 = torch.constant.int 0
    %int1_340 = torch.constant.int 1
    %312 = torch.aten.transpose.int %311, %int0_339, %int1_340 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc1.bias : tensor<3072xf16>
    %313 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_341 = torch.constant.int 6
    %314 = torch.prims.convert_element_type %313, %int6_341 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_342 = torch.constant.int 6
    %315 = torch.prims.convert_element_type %310, %int6_342 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_343 = torch.constant.int 6
    %316 = torch.prims.convert_element_type %312, %int6_343 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %317 = torch.aten.mm %315, %316 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_344 = torch.constant.int 1
    %318 = torch.aten.mul.Scalar %317, %int1_344 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_345 = torch.constant.int 1
    %319 = torch.aten.mul.Scalar %314, %int1_345 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_346 = torch.constant.int 1
    %320 = torch.aten.add.Tensor %318, %319, %int1_346 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_347 = torch.constant.int 5
    %321 = torch.prims.convert_element_type %320, %int5_347 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_348 = torch.constant.int 1
    %int64_349 = torch.constant.int 64
    %int3072_350 = torch.constant.int 3072
    %322 = torch.prim.ListConstruct %int1_348, %int64_349, %int3072_350 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %323 = torch.aten.view %321, %322 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00_351 = torch.constant.float 1.702000e+00
    %324 = torch.aten.mul.Scalar %323, %float1.702000e00_351 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %325 = torch.aten.sigmoid %324 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %326 = torch.aten.detach %325 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %327 = torch.aten.mul.Tensor %323, %325 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_352 = torch.constant.int 64
    %int3072_353 = torch.constant.int 3072
    %328 = torch.prim.ListConstruct %int64_352, %int3072_353 : (!torch.int, !torch.int) -> !torch.list<int>
    %329 = torch.aten.view %327, %328 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc2.weight : tensor<768x3072xf16>
    %330 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_354 = torch.constant.int 0
    %int1_355 = torch.constant.int 1
    %331 = torch.aten.transpose.int %330, %int0_354, %int1_355 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc2.bias : tensor<768xf16>
    %332 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.1.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_356 = torch.constant.int 6
    %333 = torch.prims.convert_element_type %332, %int6_356 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_357 = torch.constant.int 6
    %334 = torch.prims.convert_element_type %329, %int6_357 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_358 = torch.constant.int 6
    %335 = torch.prims.convert_element_type %331, %int6_358 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %336 = torch.aten.mm %334, %335 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_359 = torch.constant.int 1
    %337 = torch.aten.mul.Scalar %336, %int1_359 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_360 = torch.constant.int 1
    %338 = torch.aten.mul.Scalar %333, %int1_360 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_361 = torch.constant.int 1
    %339 = torch.aten.add.Tensor %337, %338, %int1_361 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_362 = torch.constant.int 5
    %340 = torch.prims.convert_element_type %339, %int5_362 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_363 = torch.constant.int 1
    %int64_364 = torch.constant.int 64
    %int768_365 = torch.constant.int 768
    %341 = torch.prim.ListConstruct %int1_363, %int64_364, %int768_365 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %342 = torch.aten.view %340, %341 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_366 = torch.constant.int 1
    %343 = torch.aten.add.Tensor %295, %342, %int1_366 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_367 = torch.constant.int 6
    %344 = torch.prims.convert_element_type %343, %int6_367 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_368 = torch.constant.int 2
    %345 = torch.prim.ListConstruct %int2_368 : (!torch.int) -> !torch.list<int>
    %int0_369 = torch.constant.int 0
    %true_370 = torch.constant.bool true
    %result0_371, %result1_372 = torch.aten.var_mean.correction %344, %345, %int0_369, %true_370 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_373 = torch.constant.float 1.000000e-05
    %int1_374 = torch.constant.int 1
    %346 = torch.aten.add.Scalar %result0_371, %float1.000000e-05_373, %int1_374 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %347 = torch.aten.rsqrt %346 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_375 = torch.constant.int 1
    %348 = torch.aten.sub.Tensor %343, %result1_372, %int1_375 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %349 = torch.aten.mul.Tensor %348, %347 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.2.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.layer_norm1.weight : tensor<768xf16>
    %350 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %351 = torch.aten.mul.Tensor %349, %350 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.2.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.layer_norm1.bias : tensor<768xf16>
    %352 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_376 = torch.constant.int 1
    %353 = torch.aten.add.Tensor %351, %352, %int1_376 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_377 = torch.constant.int 5
    %354 = torch.prims.convert_element_type %353, %int5_377 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_378 = torch.constant.int 5
    %355 = torch.prims.convert_element_type %result1_372, %int5_378 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_379 = torch.constant.int 5
    %356 = torch.prims.convert_element_type %347, %int5_379 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_380 = torch.constant.int 64
    %int768_381 = torch.constant.int 768
    %357 = torch.prim.ListConstruct %int64_380, %int768_381 : (!torch.int, !torch.int) -> !torch.list<int>
    %358 = torch.aten.view %354, %357 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.q_proj.weight : tensor<768x768xf16>
    %359 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_382 = torch.constant.int 0
    %int1_383 = torch.constant.int 1
    %360 = torch.aten.transpose.int %359, %int0_382, %int1_383 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.q_proj.bias : tensor<768xf16>
    %361 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_384 = torch.constant.int 6
    %362 = torch.prims.convert_element_type %361, %int6_384 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_385 = torch.constant.int 6
    %363 = torch.prims.convert_element_type %358, %int6_385 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_386 = torch.constant.int 6
    %364 = torch.prims.convert_element_type %360, %int6_386 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %365 = torch.aten.mm %363, %364 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_387 = torch.constant.int 1
    %366 = torch.aten.mul.Scalar %365, %int1_387 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_388 = torch.constant.int 1
    %367 = torch.aten.mul.Scalar %362, %int1_388 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_389 = torch.constant.int 1
    %368 = torch.aten.add.Tensor %366, %367, %int1_389 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_390 = torch.constant.int 5
    %369 = torch.prims.convert_element_type %368, %int5_390 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_391 = torch.constant.int 1
    %int64_392 = torch.constant.int 64
    %int768_393 = torch.constant.int 768
    %370 = torch.prim.ListConstruct %int1_391, %int64_392, %int768_393 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %371 = torch.aten.view %369, %370 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01_394 = torch.constant.float 1.250000e-01
    %372 = torch.aten.mul.Scalar %371, %float1.250000e-01_394 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_395 = torch.constant.int 64
    %int768_396 = torch.constant.int 768
    %373 = torch.prim.ListConstruct %int64_395, %int768_396 : (!torch.int, !torch.int) -> !torch.list<int>
    %374 = torch.aten.view %354, %373 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.k_proj.weight : tensor<768x768xf16>
    %375 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_397 = torch.constant.int 0
    %int1_398 = torch.constant.int 1
    %376 = torch.aten.transpose.int %375, %int0_397, %int1_398 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.k_proj.bias : tensor<768xf16>
    %377 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_399 = torch.constant.int 6
    %378 = torch.prims.convert_element_type %377, %int6_399 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_400 = torch.constant.int 6
    %379 = torch.prims.convert_element_type %374, %int6_400 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_401 = torch.constant.int 6
    %380 = torch.prims.convert_element_type %376, %int6_401 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %381 = torch.aten.mm %379, %380 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_402 = torch.constant.int 1
    %382 = torch.aten.mul.Scalar %381, %int1_402 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_403 = torch.constant.int 1
    %383 = torch.aten.mul.Scalar %378, %int1_403 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_404 = torch.constant.int 1
    %384 = torch.aten.add.Tensor %382, %383, %int1_404 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_405 = torch.constant.int 5
    %385 = torch.prims.convert_element_type %384, %int5_405 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_406 = torch.constant.int 1
    %int64_407 = torch.constant.int 64
    %int768_408 = torch.constant.int 768
    %386 = torch.prim.ListConstruct %int1_406, %int64_407, %int768_408 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %387 = torch.aten.view %385, %386 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_409 = torch.constant.int 1
    %int-1_410 = torch.constant.int -1
    %int12_411 = torch.constant.int 12
    %int64_412 = torch.constant.int 64
    %388 = torch.prim.ListConstruct %int1_409, %int-1_410, %int12_411, %int64_412 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %389 = torch.aten.view %387, %388 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_413 = torch.constant.int 1
    %int2_414 = torch.constant.int 2
    %390 = torch.aten.transpose.int %389, %int1_413, %int2_414 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_415 = torch.constant.int 0
    %391 = torch.aten.clone %390, %int0_415 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_416 = torch.constant.int 64
    %int768_417 = torch.constant.int 768
    %392 = torch.prim.ListConstruct %int64_416, %int768_417 : (!torch.int, !torch.int) -> !torch.list<int>
    %393 = torch.aten.view %354, %392 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.v_proj.weight : tensor<768x768xf16>
    %394 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_418 = torch.constant.int 0
    %int1_419 = torch.constant.int 1
    %395 = torch.aten.transpose.int %394, %int0_418, %int1_419 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.v_proj.bias : tensor<768xf16>
    %396 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_420 = torch.constant.int 6
    %397 = torch.prims.convert_element_type %396, %int6_420 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_421 = torch.constant.int 6
    %398 = torch.prims.convert_element_type %393, %int6_421 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_422 = torch.constant.int 6
    %399 = torch.prims.convert_element_type %395, %int6_422 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %400 = torch.aten.mm %398, %399 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_423 = torch.constant.int 1
    %401 = torch.aten.mul.Scalar %400, %int1_423 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_424 = torch.constant.int 1
    %402 = torch.aten.mul.Scalar %397, %int1_424 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_425 = torch.constant.int 1
    %403 = torch.aten.add.Tensor %401, %402, %int1_425 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_426 = torch.constant.int 5
    %404 = torch.prims.convert_element_type %403, %int5_426 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_427 = torch.constant.int 1
    %int64_428 = torch.constant.int 64
    %int768_429 = torch.constant.int 768
    %405 = torch.prim.ListConstruct %int1_427, %int64_428, %int768_429 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %406 = torch.aten.view %404, %405 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_430 = torch.constant.int 1
    %int-1_431 = torch.constant.int -1
    %int12_432 = torch.constant.int 12
    %int64_433 = torch.constant.int 64
    %407 = torch.prim.ListConstruct %int1_430, %int-1_431, %int12_432, %int64_433 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %408 = torch.aten.view %406, %407 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_434 = torch.constant.int 1
    %int2_435 = torch.constant.int 2
    %409 = torch.aten.transpose.int %408, %int1_434, %int2_435 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_436 = torch.constant.int 0
    %410 = torch.aten.clone %409, %int0_436 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_437 = torch.constant.int 1
    %int64_438 = torch.constant.int 64
    %int12_439 = torch.constant.int 12
    %int64_440 = torch.constant.int 64
    %411 = torch.prim.ListConstruct %int1_437, %int64_438, %int12_439, %int64_440 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %412 = torch.aten.view %372, %411 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_441 = torch.constant.int 1
    %int2_442 = torch.constant.int 2
    %413 = torch.aten.transpose.int %412, %int1_441, %int2_442 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_443 = torch.constant.int 0
    %414 = torch.aten.clone %413, %int0_443 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_444 = torch.constant.int 12
    %int-1_445 = torch.constant.int -1
    %int64_446 = torch.constant.int 64
    %415 = torch.prim.ListConstruct %int12_444, %int-1_445, %int64_446 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %416 = torch.aten.view %414, %415 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_447 = torch.constant.int 12
    %int-1_448 = torch.constant.int -1
    %int64_449 = torch.constant.int 64
    %417 = torch.prim.ListConstruct %int12_447, %int-1_448, %int64_449 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %418 = torch.aten.view %391, %417 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_450 = torch.constant.int 12
    %int-1_451 = torch.constant.int -1
    %int64_452 = torch.constant.int 64
    %419 = torch.prim.ListConstruct %int12_450, %int-1_451, %int64_452 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %420 = torch.aten.view %410, %419 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_453 = torch.constant.int 1
    %int2_454 = torch.constant.int 2
    %421 = torch.aten.transpose.int %418, %int1_453, %int2_454 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %422 = torch.aten.bmm %416, %421 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_455 = torch.constant.int 1
    %int12_456 = torch.constant.int 12
    %int64_457 = torch.constant.int 64
    %int64_458 = torch.constant.int 64
    %423 = torch.prim.ListConstruct %int1_455, %int12_456, %int64_457, %int64_458 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %424 = torch.aten.view %422, %423 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_459 = torch.constant.int 1
    %425 = torch.aten.add.Tensor %424, %27, %int1_459 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_460 = torch.constant.int 12
    %int64_461 = torch.constant.int 64
    %int64_462 = torch.constant.int 64
    %426 = torch.prim.ListConstruct %int12_460, %int64_461, %int64_462 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %427 = torch.aten.view %425, %426 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_463 = torch.constant.int -1
    %false_464 = torch.constant.bool false
    %428 = torch.aten._softmax %427, %int-1_463, %false_464 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %429 = torch.aten.detach %428 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_465 = torch.constant.none
    %430 = torch.aten.clone %428, %none_465 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %431 = torch.aten.bmm %430, %420 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_466 = torch.constant.int 1
    %int12_467 = torch.constant.int 12
    %int64_468 = torch.constant.int 64
    %int64_469 = torch.constant.int 64
    %432 = torch.prim.ListConstruct %int1_466, %int12_467, %int64_468, %int64_469 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %433 = torch.aten.view %431, %432 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_470 = torch.constant.int 1
    %int2_471 = torch.constant.int 2
    %434 = torch.aten.transpose.int %433, %int1_470, %int2_471 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_472 = torch.constant.int 0
    %435 = torch.aten.clone %434, %int0_472 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_473 = torch.constant.int 1
    %int64_474 = torch.constant.int 64
    %int768_475 = torch.constant.int 768
    %436 = torch.prim.ListConstruct %int1_473, %int64_474, %int768_475 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %437 = torch.aten._unsafe_view %435, %436 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_476 = torch.constant.int 64
    %int768_477 = torch.constant.int 768
    %438 = torch.prim.ListConstruct %int64_476, %int768_477 : (!torch.int, !torch.int) -> !torch.list<int>
    %439 = torch.aten.view %437, %438 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.out_proj.weight : tensor<768x768xf16>
    %440 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_478 = torch.constant.int 0
    %int1_479 = torch.constant.int 1
    %441 = torch.aten.transpose.int %440, %int0_478, %int1_479 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.self_attn.out_proj.bias : tensor<768xf16>
    %442 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_480 = torch.constant.int 6
    %443 = torch.prims.convert_element_type %442, %int6_480 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_481 = torch.constant.int 6
    %444 = torch.prims.convert_element_type %439, %int6_481 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_482 = torch.constant.int 6
    %445 = torch.prims.convert_element_type %441, %int6_482 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %446 = torch.aten.mm %444, %445 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_483 = torch.constant.int 1
    %447 = torch.aten.mul.Scalar %446, %int1_483 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_484 = torch.constant.int 1
    %448 = torch.aten.mul.Scalar %443, %int1_484 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_485 = torch.constant.int 1
    %449 = torch.aten.add.Tensor %447, %448, %int1_485 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_486 = torch.constant.int 5
    %450 = torch.prims.convert_element_type %449, %int5_486 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_487 = torch.constant.int 1
    %int64_488 = torch.constant.int 64
    %int768_489 = torch.constant.int 768
    %451 = torch.prim.ListConstruct %int1_487, %int64_488, %int768_489 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %452 = torch.aten.view %450, %451 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_490 = torch.constant.int 1
    %453 = torch.aten.add.Tensor %343, %452, %int1_490 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_491 = torch.constant.int 6
    %454 = torch.prims.convert_element_type %453, %int6_491 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_492 = torch.constant.int 2
    %455 = torch.prim.ListConstruct %int2_492 : (!torch.int) -> !torch.list<int>
    %int0_493 = torch.constant.int 0
    %true_494 = torch.constant.bool true
    %result0_495, %result1_496 = torch.aten.var_mean.correction %454, %455, %int0_493, %true_494 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_497 = torch.constant.float 1.000000e-05
    %int1_498 = torch.constant.int 1
    %456 = torch.aten.add.Scalar %result0_495, %float1.000000e-05_497, %int1_498 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %457 = torch.aten.rsqrt %456 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_499 = torch.constant.int 1
    %458 = torch.aten.sub.Tensor %453, %result1_496, %int1_499 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %459 = torch.aten.mul.Tensor %458, %457 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.2.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.layer_norm2.weight : tensor<768xf16>
    %460 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %461 = torch.aten.mul.Tensor %459, %460 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.2.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.layer_norm2.bias : tensor<768xf16>
    %462 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_500 = torch.constant.int 1
    %463 = torch.aten.add.Tensor %461, %462, %int1_500 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_501 = torch.constant.int 5
    %464 = torch.prims.convert_element_type %463, %int5_501 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_502 = torch.constant.int 5
    %465 = torch.prims.convert_element_type %result1_496, %int5_502 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_503 = torch.constant.int 5
    %466 = torch.prims.convert_element_type %457, %int5_503 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_504 = torch.constant.int 64
    %int768_505 = torch.constant.int 768
    %467 = torch.prim.ListConstruct %int64_504, %int768_505 : (!torch.int, !torch.int) -> !torch.list<int>
    %468 = torch.aten.view %464, %467 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc1.weight : tensor<3072x768xf16>
    %469 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_506 = torch.constant.int 0
    %int1_507 = torch.constant.int 1
    %470 = torch.aten.transpose.int %469, %int0_506, %int1_507 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc1.bias : tensor<3072xf16>
    %471 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_508 = torch.constant.int 6
    %472 = torch.prims.convert_element_type %471, %int6_508 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_509 = torch.constant.int 6
    %473 = torch.prims.convert_element_type %468, %int6_509 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_510 = torch.constant.int 6
    %474 = torch.prims.convert_element_type %470, %int6_510 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %475 = torch.aten.mm %473, %474 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_511 = torch.constant.int 1
    %476 = torch.aten.mul.Scalar %475, %int1_511 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_512 = torch.constant.int 1
    %477 = torch.aten.mul.Scalar %472, %int1_512 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_513 = torch.constant.int 1
    %478 = torch.aten.add.Tensor %476, %477, %int1_513 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_514 = torch.constant.int 5
    %479 = torch.prims.convert_element_type %478, %int5_514 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_515 = torch.constant.int 1
    %int64_516 = torch.constant.int 64
    %int3072_517 = torch.constant.int 3072
    %480 = torch.prim.ListConstruct %int1_515, %int64_516, %int3072_517 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %481 = torch.aten.view %479, %480 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00_518 = torch.constant.float 1.702000e+00
    %482 = torch.aten.mul.Scalar %481, %float1.702000e00_518 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %483 = torch.aten.sigmoid %482 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %484 = torch.aten.detach %483 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %485 = torch.aten.mul.Tensor %481, %483 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_519 = torch.constant.int 64
    %int3072_520 = torch.constant.int 3072
    %486 = torch.prim.ListConstruct %int64_519, %int3072_520 : (!torch.int, !torch.int) -> !torch.list<int>
    %487 = torch.aten.view %485, %486 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc2.weight : tensor<768x3072xf16>
    %488 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_521 = torch.constant.int 0
    %int1_522 = torch.constant.int 1
    %489 = torch.aten.transpose.int %488, %int0_521, %int1_522 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc2.bias : tensor<768xf16>
    %490 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.2.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_523 = torch.constant.int 6
    %491 = torch.prims.convert_element_type %490, %int6_523 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_524 = torch.constant.int 6
    %492 = torch.prims.convert_element_type %487, %int6_524 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_525 = torch.constant.int 6
    %493 = torch.prims.convert_element_type %489, %int6_525 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %494 = torch.aten.mm %492, %493 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_526 = torch.constant.int 1
    %495 = torch.aten.mul.Scalar %494, %int1_526 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_527 = torch.constant.int 1
    %496 = torch.aten.mul.Scalar %491, %int1_527 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_528 = torch.constant.int 1
    %497 = torch.aten.add.Tensor %495, %496, %int1_528 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_529 = torch.constant.int 5
    %498 = torch.prims.convert_element_type %497, %int5_529 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_530 = torch.constant.int 1
    %int64_531 = torch.constant.int 64
    %int768_532 = torch.constant.int 768
    %499 = torch.prim.ListConstruct %int1_530, %int64_531, %int768_532 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %500 = torch.aten.view %498, %499 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_533 = torch.constant.int 1
    %501 = torch.aten.add.Tensor %453, %500, %int1_533 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_534 = torch.constant.int 6
    %502 = torch.prims.convert_element_type %501, %int6_534 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_535 = torch.constant.int 2
    %503 = torch.prim.ListConstruct %int2_535 : (!torch.int) -> !torch.list<int>
    %int0_536 = torch.constant.int 0
    %true_537 = torch.constant.bool true
    %result0_538, %result1_539 = torch.aten.var_mean.correction %502, %503, %int0_536, %true_537 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_540 = torch.constant.float 1.000000e-05
    %int1_541 = torch.constant.int 1
    %504 = torch.aten.add.Scalar %result0_538, %float1.000000e-05_540, %int1_541 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %505 = torch.aten.rsqrt %504 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_542 = torch.constant.int 1
    %506 = torch.aten.sub.Tensor %501, %result1_539, %int1_542 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %507 = torch.aten.mul.Tensor %506, %505 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.3.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.layer_norm1.weight : tensor<768xf16>
    %508 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %509 = torch.aten.mul.Tensor %507, %508 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.3.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.layer_norm1.bias : tensor<768xf16>
    %510 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_543 = torch.constant.int 1
    %511 = torch.aten.add.Tensor %509, %510, %int1_543 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_544 = torch.constant.int 5
    %512 = torch.prims.convert_element_type %511, %int5_544 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_545 = torch.constant.int 5
    %513 = torch.prims.convert_element_type %result1_539, %int5_545 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_546 = torch.constant.int 5
    %514 = torch.prims.convert_element_type %505, %int5_546 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_547 = torch.constant.int 64
    %int768_548 = torch.constant.int 768
    %515 = torch.prim.ListConstruct %int64_547, %int768_548 : (!torch.int, !torch.int) -> !torch.list<int>
    %516 = torch.aten.view %512, %515 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.q_proj.weight : tensor<768x768xf16>
    %517 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_549 = torch.constant.int 0
    %int1_550 = torch.constant.int 1
    %518 = torch.aten.transpose.int %517, %int0_549, %int1_550 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.q_proj.bias : tensor<768xf16>
    %519 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_551 = torch.constant.int 6
    %520 = torch.prims.convert_element_type %519, %int6_551 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_552 = torch.constant.int 6
    %521 = torch.prims.convert_element_type %516, %int6_552 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_553 = torch.constant.int 6
    %522 = torch.prims.convert_element_type %518, %int6_553 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %523 = torch.aten.mm %521, %522 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_554 = torch.constant.int 1
    %524 = torch.aten.mul.Scalar %523, %int1_554 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_555 = torch.constant.int 1
    %525 = torch.aten.mul.Scalar %520, %int1_555 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_556 = torch.constant.int 1
    %526 = torch.aten.add.Tensor %524, %525, %int1_556 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_557 = torch.constant.int 5
    %527 = torch.prims.convert_element_type %526, %int5_557 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_558 = torch.constant.int 1
    %int64_559 = torch.constant.int 64
    %int768_560 = torch.constant.int 768
    %528 = torch.prim.ListConstruct %int1_558, %int64_559, %int768_560 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %529 = torch.aten.view %527, %528 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01_561 = torch.constant.float 1.250000e-01
    %530 = torch.aten.mul.Scalar %529, %float1.250000e-01_561 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_562 = torch.constant.int 64
    %int768_563 = torch.constant.int 768
    %531 = torch.prim.ListConstruct %int64_562, %int768_563 : (!torch.int, !torch.int) -> !torch.list<int>
    %532 = torch.aten.view %512, %531 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.k_proj.weight : tensor<768x768xf16>
    %533 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_564 = torch.constant.int 0
    %int1_565 = torch.constant.int 1
    %534 = torch.aten.transpose.int %533, %int0_564, %int1_565 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.k_proj.bias : tensor<768xf16>
    %535 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_566 = torch.constant.int 6
    %536 = torch.prims.convert_element_type %535, %int6_566 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_567 = torch.constant.int 6
    %537 = torch.prims.convert_element_type %532, %int6_567 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_568 = torch.constant.int 6
    %538 = torch.prims.convert_element_type %534, %int6_568 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %539 = torch.aten.mm %537, %538 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_569 = torch.constant.int 1
    %540 = torch.aten.mul.Scalar %539, %int1_569 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_570 = torch.constant.int 1
    %541 = torch.aten.mul.Scalar %536, %int1_570 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_571 = torch.constant.int 1
    %542 = torch.aten.add.Tensor %540, %541, %int1_571 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_572 = torch.constant.int 5
    %543 = torch.prims.convert_element_type %542, %int5_572 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_573 = torch.constant.int 1
    %int64_574 = torch.constant.int 64
    %int768_575 = torch.constant.int 768
    %544 = torch.prim.ListConstruct %int1_573, %int64_574, %int768_575 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %545 = torch.aten.view %543, %544 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_576 = torch.constant.int 1
    %int-1_577 = torch.constant.int -1
    %int12_578 = torch.constant.int 12
    %int64_579 = torch.constant.int 64
    %546 = torch.prim.ListConstruct %int1_576, %int-1_577, %int12_578, %int64_579 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %547 = torch.aten.view %545, %546 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_580 = torch.constant.int 1
    %int2_581 = torch.constant.int 2
    %548 = torch.aten.transpose.int %547, %int1_580, %int2_581 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_582 = torch.constant.int 0
    %549 = torch.aten.clone %548, %int0_582 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_583 = torch.constant.int 64
    %int768_584 = torch.constant.int 768
    %550 = torch.prim.ListConstruct %int64_583, %int768_584 : (!torch.int, !torch.int) -> !torch.list<int>
    %551 = torch.aten.view %512, %550 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.v_proj.weight : tensor<768x768xf16>
    %552 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_585 = torch.constant.int 0
    %int1_586 = torch.constant.int 1
    %553 = torch.aten.transpose.int %552, %int0_585, %int1_586 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.v_proj.bias : tensor<768xf16>
    %554 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_587 = torch.constant.int 6
    %555 = torch.prims.convert_element_type %554, %int6_587 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_588 = torch.constant.int 6
    %556 = torch.prims.convert_element_type %551, %int6_588 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_589 = torch.constant.int 6
    %557 = torch.prims.convert_element_type %553, %int6_589 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %558 = torch.aten.mm %556, %557 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_590 = torch.constant.int 1
    %559 = torch.aten.mul.Scalar %558, %int1_590 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_591 = torch.constant.int 1
    %560 = torch.aten.mul.Scalar %555, %int1_591 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_592 = torch.constant.int 1
    %561 = torch.aten.add.Tensor %559, %560, %int1_592 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_593 = torch.constant.int 5
    %562 = torch.prims.convert_element_type %561, %int5_593 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_594 = torch.constant.int 1
    %int64_595 = torch.constant.int 64
    %int768_596 = torch.constant.int 768
    %563 = torch.prim.ListConstruct %int1_594, %int64_595, %int768_596 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %564 = torch.aten.view %562, %563 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_597 = torch.constant.int 1
    %int-1_598 = torch.constant.int -1
    %int12_599 = torch.constant.int 12
    %int64_600 = torch.constant.int 64
    %565 = torch.prim.ListConstruct %int1_597, %int-1_598, %int12_599, %int64_600 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %566 = torch.aten.view %564, %565 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_601 = torch.constant.int 1
    %int2_602 = torch.constant.int 2
    %567 = torch.aten.transpose.int %566, %int1_601, %int2_602 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_603 = torch.constant.int 0
    %568 = torch.aten.clone %567, %int0_603 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_604 = torch.constant.int 1
    %int64_605 = torch.constant.int 64
    %int12_606 = torch.constant.int 12
    %int64_607 = torch.constant.int 64
    %569 = torch.prim.ListConstruct %int1_604, %int64_605, %int12_606, %int64_607 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %570 = torch.aten.view %530, %569 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_608 = torch.constant.int 1
    %int2_609 = torch.constant.int 2
    %571 = torch.aten.transpose.int %570, %int1_608, %int2_609 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_610 = torch.constant.int 0
    %572 = torch.aten.clone %571, %int0_610 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_611 = torch.constant.int 12
    %int-1_612 = torch.constant.int -1
    %int64_613 = torch.constant.int 64
    %573 = torch.prim.ListConstruct %int12_611, %int-1_612, %int64_613 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %574 = torch.aten.view %572, %573 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_614 = torch.constant.int 12
    %int-1_615 = torch.constant.int -1
    %int64_616 = torch.constant.int 64
    %575 = torch.prim.ListConstruct %int12_614, %int-1_615, %int64_616 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %576 = torch.aten.view %549, %575 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_617 = torch.constant.int 12
    %int-1_618 = torch.constant.int -1
    %int64_619 = torch.constant.int 64
    %577 = torch.prim.ListConstruct %int12_617, %int-1_618, %int64_619 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %578 = torch.aten.view %568, %577 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_620 = torch.constant.int 1
    %int2_621 = torch.constant.int 2
    %579 = torch.aten.transpose.int %576, %int1_620, %int2_621 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %580 = torch.aten.bmm %574, %579 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_622 = torch.constant.int 1
    %int12_623 = torch.constant.int 12
    %int64_624 = torch.constant.int 64
    %int64_625 = torch.constant.int 64
    %581 = torch.prim.ListConstruct %int1_622, %int12_623, %int64_624, %int64_625 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %582 = torch.aten.view %580, %581 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_626 = torch.constant.int 1
    %583 = torch.aten.add.Tensor %582, %27, %int1_626 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_627 = torch.constant.int 12
    %int64_628 = torch.constant.int 64
    %int64_629 = torch.constant.int 64
    %584 = torch.prim.ListConstruct %int12_627, %int64_628, %int64_629 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %585 = torch.aten.view %583, %584 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_630 = torch.constant.int -1
    %false_631 = torch.constant.bool false
    %586 = torch.aten._softmax %585, %int-1_630, %false_631 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %587 = torch.aten.detach %586 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_632 = torch.constant.none
    %588 = torch.aten.clone %586, %none_632 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %589 = torch.aten.bmm %588, %578 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_633 = torch.constant.int 1
    %int12_634 = torch.constant.int 12
    %int64_635 = torch.constant.int 64
    %int64_636 = torch.constant.int 64
    %590 = torch.prim.ListConstruct %int1_633, %int12_634, %int64_635, %int64_636 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %591 = torch.aten.view %589, %590 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_637 = torch.constant.int 1
    %int2_638 = torch.constant.int 2
    %592 = torch.aten.transpose.int %591, %int1_637, %int2_638 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_639 = torch.constant.int 0
    %593 = torch.aten.clone %592, %int0_639 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_640 = torch.constant.int 1
    %int64_641 = torch.constant.int 64
    %int768_642 = torch.constant.int 768
    %594 = torch.prim.ListConstruct %int1_640, %int64_641, %int768_642 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %595 = torch.aten._unsafe_view %593, %594 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_643 = torch.constant.int 64
    %int768_644 = torch.constant.int 768
    %596 = torch.prim.ListConstruct %int64_643, %int768_644 : (!torch.int, !torch.int) -> !torch.list<int>
    %597 = torch.aten.view %595, %596 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.out_proj.weight : tensor<768x768xf16>
    %598 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_645 = torch.constant.int 0
    %int1_646 = torch.constant.int 1
    %599 = torch.aten.transpose.int %598, %int0_645, %int1_646 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.self_attn.out_proj.bias : tensor<768xf16>
    %600 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_647 = torch.constant.int 6
    %601 = torch.prims.convert_element_type %600, %int6_647 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_648 = torch.constant.int 6
    %602 = torch.prims.convert_element_type %597, %int6_648 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_649 = torch.constant.int 6
    %603 = torch.prims.convert_element_type %599, %int6_649 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %604 = torch.aten.mm %602, %603 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_650 = torch.constant.int 1
    %605 = torch.aten.mul.Scalar %604, %int1_650 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_651 = torch.constant.int 1
    %606 = torch.aten.mul.Scalar %601, %int1_651 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_652 = torch.constant.int 1
    %607 = torch.aten.add.Tensor %605, %606, %int1_652 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_653 = torch.constant.int 5
    %608 = torch.prims.convert_element_type %607, %int5_653 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_654 = torch.constant.int 1
    %int64_655 = torch.constant.int 64
    %int768_656 = torch.constant.int 768
    %609 = torch.prim.ListConstruct %int1_654, %int64_655, %int768_656 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %610 = torch.aten.view %608, %609 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_657 = torch.constant.int 1
    %611 = torch.aten.add.Tensor %501, %610, %int1_657 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_658 = torch.constant.int 6
    %612 = torch.prims.convert_element_type %611, %int6_658 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_659 = torch.constant.int 2
    %613 = torch.prim.ListConstruct %int2_659 : (!torch.int) -> !torch.list<int>
    %int0_660 = torch.constant.int 0
    %true_661 = torch.constant.bool true
    %result0_662, %result1_663 = torch.aten.var_mean.correction %612, %613, %int0_660, %true_661 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_664 = torch.constant.float 1.000000e-05
    %int1_665 = torch.constant.int 1
    %614 = torch.aten.add.Scalar %result0_662, %float1.000000e-05_664, %int1_665 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %615 = torch.aten.rsqrt %614 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_666 = torch.constant.int 1
    %616 = torch.aten.sub.Tensor %611, %result1_663, %int1_666 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %617 = torch.aten.mul.Tensor %616, %615 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.3.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.layer_norm2.weight : tensor<768xf16>
    %618 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %619 = torch.aten.mul.Tensor %617, %618 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.3.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.layer_norm2.bias : tensor<768xf16>
    %620 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_667 = torch.constant.int 1
    %621 = torch.aten.add.Tensor %619, %620, %int1_667 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_668 = torch.constant.int 5
    %622 = torch.prims.convert_element_type %621, %int5_668 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_669 = torch.constant.int 5
    %623 = torch.prims.convert_element_type %result1_663, %int5_669 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_670 = torch.constant.int 5
    %624 = torch.prims.convert_element_type %615, %int5_670 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_671 = torch.constant.int 64
    %int768_672 = torch.constant.int 768
    %625 = torch.prim.ListConstruct %int64_671, %int768_672 : (!torch.int, !torch.int) -> !torch.list<int>
    %626 = torch.aten.view %622, %625 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc1.weight : tensor<3072x768xf16>
    %627 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_673 = torch.constant.int 0
    %int1_674 = torch.constant.int 1
    %628 = torch.aten.transpose.int %627, %int0_673, %int1_674 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc1.bias : tensor<3072xf16>
    %629 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_675 = torch.constant.int 6
    %630 = torch.prims.convert_element_type %629, %int6_675 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_676 = torch.constant.int 6
    %631 = torch.prims.convert_element_type %626, %int6_676 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_677 = torch.constant.int 6
    %632 = torch.prims.convert_element_type %628, %int6_677 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %633 = torch.aten.mm %631, %632 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_678 = torch.constant.int 1
    %634 = torch.aten.mul.Scalar %633, %int1_678 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_679 = torch.constant.int 1
    %635 = torch.aten.mul.Scalar %630, %int1_679 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_680 = torch.constant.int 1
    %636 = torch.aten.add.Tensor %634, %635, %int1_680 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_681 = torch.constant.int 5
    %637 = torch.prims.convert_element_type %636, %int5_681 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_682 = torch.constant.int 1
    %int64_683 = torch.constant.int 64
    %int3072_684 = torch.constant.int 3072
    %638 = torch.prim.ListConstruct %int1_682, %int64_683, %int3072_684 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %639 = torch.aten.view %637, %638 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00_685 = torch.constant.float 1.702000e+00
    %640 = torch.aten.mul.Scalar %639, %float1.702000e00_685 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %641 = torch.aten.sigmoid %640 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %642 = torch.aten.detach %641 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %643 = torch.aten.mul.Tensor %639, %641 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_686 = torch.constant.int 64
    %int3072_687 = torch.constant.int 3072
    %644 = torch.prim.ListConstruct %int64_686, %int3072_687 : (!torch.int, !torch.int) -> !torch.list<int>
    %645 = torch.aten.view %643, %644 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc2.weight : tensor<768x3072xf16>
    %646 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_688 = torch.constant.int 0
    %int1_689 = torch.constant.int 1
    %647 = torch.aten.transpose.int %646, %int0_688, %int1_689 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc2.bias : tensor<768xf16>
    %648 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.3.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_690 = torch.constant.int 6
    %649 = torch.prims.convert_element_type %648, %int6_690 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_691 = torch.constant.int 6
    %650 = torch.prims.convert_element_type %645, %int6_691 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_692 = torch.constant.int 6
    %651 = torch.prims.convert_element_type %647, %int6_692 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %652 = torch.aten.mm %650, %651 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_693 = torch.constant.int 1
    %653 = torch.aten.mul.Scalar %652, %int1_693 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_694 = torch.constant.int 1
    %654 = torch.aten.mul.Scalar %649, %int1_694 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_695 = torch.constant.int 1
    %655 = torch.aten.add.Tensor %653, %654, %int1_695 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_696 = torch.constant.int 5
    %656 = torch.prims.convert_element_type %655, %int5_696 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_697 = torch.constant.int 1
    %int64_698 = torch.constant.int 64
    %int768_699 = torch.constant.int 768
    %657 = torch.prim.ListConstruct %int1_697, %int64_698, %int768_699 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %658 = torch.aten.view %656, %657 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_700 = torch.constant.int 1
    %659 = torch.aten.add.Tensor %611, %658, %int1_700 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_701 = torch.constant.int 6
    %660 = torch.prims.convert_element_type %659, %int6_701 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_702 = torch.constant.int 2
    %661 = torch.prim.ListConstruct %int2_702 : (!torch.int) -> !torch.list<int>
    %int0_703 = torch.constant.int 0
    %true_704 = torch.constant.bool true
    %result0_705, %result1_706 = torch.aten.var_mean.correction %660, %661, %int0_703, %true_704 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_707 = torch.constant.float 1.000000e-05
    %int1_708 = torch.constant.int 1
    %662 = torch.aten.add.Scalar %result0_705, %float1.000000e-05_707, %int1_708 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %663 = torch.aten.rsqrt %662 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_709 = torch.constant.int 1
    %664 = torch.aten.sub.Tensor %659, %result1_706, %int1_709 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %665 = torch.aten.mul.Tensor %664, %663 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.4.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.layer_norm1.weight : tensor<768xf16>
    %666 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %667 = torch.aten.mul.Tensor %665, %666 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.4.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.layer_norm1.bias : tensor<768xf16>
    %668 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_710 = torch.constant.int 1
    %669 = torch.aten.add.Tensor %667, %668, %int1_710 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_711 = torch.constant.int 5
    %670 = torch.prims.convert_element_type %669, %int5_711 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_712 = torch.constant.int 5
    %671 = torch.prims.convert_element_type %result1_706, %int5_712 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_713 = torch.constant.int 5
    %672 = torch.prims.convert_element_type %663, %int5_713 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_714 = torch.constant.int 64
    %int768_715 = torch.constant.int 768
    %673 = torch.prim.ListConstruct %int64_714, %int768_715 : (!torch.int, !torch.int) -> !torch.list<int>
    %674 = torch.aten.view %670, %673 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.q_proj.weight : tensor<768x768xf16>
    %675 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_716 = torch.constant.int 0
    %int1_717 = torch.constant.int 1
    %676 = torch.aten.transpose.int %675, %int0_716, %int1_717 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.q_proj.bias : tensor<768xf16>
    %677 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_718 = torch.constant.int 6
    %678 = torch.prims.convert_element_type %677, %int6_718 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_719 = torch.constant.int 6
    %679 = torch.prims.convert_element_type %674, %int6_719 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_720 = torch.constant.int 6
    %680 = torch.prims.convert_element_type %676, %int6_720 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %681 = torch.aten.mm %679, %680 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_721 = torch.constant.int 1
    %682 = torch.aten.mul.Scalar %681, %int1_721 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_722 = torch.constant.int 1
    %683 = torch.aten.mul.Scalar %678, %int1_722 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_723 = torch.constant.int 1
    %684 = torch.aten.add.Tensor %682, %683, %int1_723 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_724 = torch.constant.int 5
    %685 = torch.prims.convert_element_type %684, %int5_724 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_725 = torch.constant.int 1
    %int64_726 = torch.constant.int 64
    %int768_727 = torch.constant.int 768
    %686 = torch.prim.ListConstruct %int1_725, %int64_726, %int768_727 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %687 = torch.aten.view %685, %686 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01_728 = torch.constant.float 1.250000e-01
    %688 = torch.aten.mul.Scalar %687, %float1.250000e-01_728 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_729 = torch.constant.int 64
    %int768_730 = torch.constant.int 768
    %689 = torch.prim.ListConstruct %int64_729, %int768_730 : (!torch.int, !torch.int) -> !torch.list<int>
    %690 = torch.aten.view %670, %689 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.k_proj.weight : tensor<768x768xf16>
    %691 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_731 = torch.constant.int 0
    %int1_732 = torch.constant.int 1
    %692 = torch.aten.transpose.int %691, %int0_731, %int1_732 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.k_proj.bias : tensor<768xf16>
    %693 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_733 = torch.constant.int 6
    %694 = torch.prims.convert_element_type %693, %int6_733 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_734 = torch.constant.int 6
    %695 = torch.prims.convert_element_type %690, %int6_734 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_735 = torch.constant.int 6
    %696 = torch.prims.convert_element_type %692, %int6_735 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %697 = torch.aten.mm %695, %696 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_736 = torch.constant.int 1
    %698 = torch.aten.mul.Scalar %697, %int1_736 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_737 = torch.constant.int 1
    %699 = torch.aten.mul.Scalar %694, %int1_737 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_738 = torch.constant.int 1
    %700 = torch.aten.add.Tensor %698, %699, %int1_738 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_739 = torch.constant.int 5
    %701 = torch.prims.convert_element_type %700, %int5_739 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_740 = torch.constant.int 1
    %int64_741 = torch.constant.int 64
    %int768_742 = torch.constant.int 768
    %702 = torch.prim.ListConstruct %int1_740, %int64_741, %int768_742 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %703 = torch.aten.view %701, %702 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_743 = torch.constant.int 1
    %int-1_744 = torch.constant.int -1
    %int12_745 = torch.constant.int 12
    %int64_746 = torch.constant.int 64
    %704 = torch.prim.ListConstruct %int1_743, %int-1_744, %int12_745, %int64_746 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %705 = torch.aten.view %703, %704 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_747 = torch.constant.int 1
    %int2_748 = torch.constant.int 2
    %706 = torch.aten.transpose.int %705, %int1_747, %int2_748 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_749 = torch.constant.int 0
    %707 = torch.aten.clone %706, %int0_749 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_750 = torch.constant.int 64
    %int768_751 = torch.constant.int 768
    %708 = torch.prim.ListConstruct %int64_750, %int768_751 : (!torch.int, !torch.int) -> !torch.list<int>
    %709 = torch.aten.view %670, %708 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.v_proj.weight : tensor<768x768xf16>
    %710 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_752 = torch.constant.int 0
    %int1_753 = torch.constant.int 1
    %711 = torch.aten.transpose.int %710, %int0_752, %int1_753 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.v_proj.bias : tensor<768xf16>
    %712 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_754 = torch.constant.int 6
    %713 = torch.prims.convert_element_type %712, %int6_754 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_755 = torch.constant.int 6
    %714 = torch.prims.convert_element_type %709, %int6_755 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_756 = torch.constant.int 6
    %715 = torch.prims.convert_element_type %711, %int6_756 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %716 = torch.aten.mm %714, %715 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_757 = torch.constant.int 1
    %717 = torch.aten.mul.Scalar %716, %int1_757 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_758 = torch.constant.int 1
    %718 = torch.aten.mul.Scalar %713, %int1_758 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_759 = torch.constant.int 1
    %719 = torch.aten.add.Tensor %717, %718, %int1_759 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_760 = torch.constant.int 5
    %720 = torch.prims.convert_element_type %719, %int5_760 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_761 = torch.constant.int 1
    %int64_762 = torch.constant.int 64
    %int768_763 = torch.constant.int 768
    %721 = torch.prim.ListConstruct %int1_761, %int64_762, %int768_763 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %722 = torch.aten.view %720, %721 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_764 = torch.constant.int 1
    %int-1_765 = torch.constant.int -1
    %int12_766 = torch.constant.int 12
    %int64_767 = torch.constant.int 64
    %723 = torch.prim.ListConstruct %int1_764, %int-1_765, %int12_766, %int64_767 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %724 = torch.aten.view %722, %723 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_768 = torch.constant.int 1
    %int2_769 = torch.constant.int 2
    %725 = torch.aten.transpose.int %724, %int1_768, %int2_769 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_770 = torch.constant.int 0
    %726 = torch.aten.clone %725, %int0_770 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_771 = torch.constant.int 1
    %int64_772 = torch.constant.int 64
    %int12_773 = torch.constant.int 12
    %int64_774 = torch.constant.int 64
    %727 = torch.prim.ListConstruct %int1_771, %int64_772, %int12_773, %int64_774 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %728 = torch.aten.view %688, %727 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_775 = torch.constant.int 1
    %int2_776 = torch.constant.int 2
    %729 = torch.aten.transpose.int %728, %int1_775, %int2_776 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_777 = torch.constant.int 0
    %730 = torch.aten.clone %729, %int0_777 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_778 = torch.constant.int 12
    %int-1_779 = torch.constant.int -1
    %int64_780 = torch.constant.int 64
    %731 = torch.prim.ListConstruct %int12_778, %int-1_779, %int64_780 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %732 = torch.aten.view %730, %731 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_781 = torch.constant.int 12
    %int-1_782 = torch.constant.int -1
    %int64_783 = torch.constant.int 64
    %733 = torch.prim.ListConstruct %int12_781, %int-1_782, %int64_783 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %734 = torch.aten.view %707, %733 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_784 = torch.constant.int 12
    %int-1_785 = torch.constant.int -1
    %int64_786 = torch.constant.int 64
    %735 = torch.prim.ListConstruct %int12_784, %int-1_785, %int64_786 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %736 = torch.aten.view %726, %735 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_787 = torch.constant.int 1
    %int2_788 = torch.constant.int 2
    %737 = torch.aten.transpose.int %734, %int1_787, %int2_788 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %738 = torch.aten.bmm %732, %737 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_789 = torch.constant.int 1
    %int12_790 = torch.constant.int 12
    %int64_791 = torch.constant.int 64
    %int64_792 = torch.constant.int 64
    %739 = torch.prim.ListConstruct %int1_789, %int12_790, %int64_791, %int64_792 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %740 = torch.aten.view %738, %739 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_793 = torch.constant.int 1
    %741 = torch.aten.add.Tensor %740, %27, %int1_793 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_794 = torch.constant.int 12
    %int64_795 = torch.constant.int 64
    %int64_796 = torch.constant.int 64
    %742 = torch.prim.ListConstruct %int12_794, %int64_795, %int64_796 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %743 = torch.aten.view %741, %742 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_797 = torch.constant.int -1
    %false_798 = torch.constant.bool false
    %744 = torch.aten._softmax %743, %int-1_797, %false_798 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %745 = torch.aten.detach %744 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_799 = torch.constant.none
    %746 = torch.aten.clone %744, %none_799 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %747 = torch.aten.bmm %746, %736 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_800 = torch.constant.int 1
    %int12_801 = torch.constant.int 12
    %int64_802 = torch.constant.int 64
    %int64_803 = torch.constant.int 64
    %748 = torch.prim.ListConstruct %int1_800, %int12_801, %int64_802, %int64_803 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %749 = torch.aten.view %747, %748 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_804 = torch.constant.int 1
    %int2_805 = torch.constant.int 2
    %750 = torch.aten.transpose.int %749, %int1_804, %int2_805 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_806 = torch.constant.int 0
    %751 = torch.aten.clone %750, %int0_806 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_807 = torch.constant.int 1
    %int64_808 = torch.constant.int 64
    %int768_809 = torch.constant.int 768
    %752 = torch.prim.ListConstruct %int1_807, %int64_808, %int768_809 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %753 = torch.aten._unsafe_view %751, %752 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_810 = torch.constant.int 64
    %int768_811 = torch.constant.int 768
    %754 = torch.prim.ListConstruct %int64_810, %int768_811 : (!torch.int, !torch.int) -> !torch.list<int>
    %755 = torch.aten.view %753, %754 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.out_proj.weight : tensor<768x768xf16>
    %756 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_812 = torch.constant.int 0
    %int1_813 = torch.constant.int 1
    %757 = torch.aten.transpose.int %756, %int0_812, %int1_813 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.self_attn.out_proj.bias : tensor<768xf16>
    %758 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_814 = torch.constant.int 6
    %759 = torch.prims.convert_element_type %758, %int6_814 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_815 = torch.constant.int 6
    %760 = torch.prims.convert_element_type %755, %int6_815 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_816 = torch.constant.int 6
    %761 = torch.prims.convert_element_type %757, %int6_816 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %762 = torch.aten.mm %760, %761 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_817 = torch.constant.int 1
    %763 = torch.aten.mul.Scalar %762, %int1_817 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_818 = torch.constant.int 1
    %764 = torch.aten.mul.Scalar %759, %int1_818 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_819 = torch.constant.int 1
    %765 = torch.aten.add.Tensor %763, %764, %int1_819 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_820 = torch.constant.int 5
    %766 = torch.prims.convert_element_type %765, %int5_820 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_821 = torch.constant.int 1
    %int64_822 = torch.constant.int 64
    %int768_823 = torch.constant.int 768
    %767 = torch.prim.ListConstruct %int1_821, %int64_822, %int768_823 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %768 = torch.aten.view %766, %767 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_824 = torch.constant.int 1
    %769 = torch.aten.add.Tensor %659, %768, %int1_824 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_825 = torch.constant.int 6
    %770 = torch.prims.convert_element_type %769, %int6_825 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_826 = torch.constant.int 2
    %771 = torch.prim.ListConstruct %int2_826 : (!torch.int) -> !torch.list<int>
    %int0_827 = torch.constant.int 0
    %true_828 = torch.constant.bool true
    %result0_829, %result1_830 = torch.aten.var_mean.correction %770, %771, %int0_827, %true_828 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_831 = torch.constant.float 1.000000e-05
    %int1_832 = torch.constant.int 1
    %772 = torch.aten.add.Scalar %result0_829, %float1.000000e-05_831, %int1_832 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %773 = torch.aten.rsqrt %772 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_833 = torch.constant.int 1
    %774 = torch.aten.sub.Tensor %769, %result1_830, %int1_833 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %775 = torch.aten.mul.Tensor %774, %773 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.4.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.layer_norm2.weight : tensor<768xf16>
    %776 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %777 = torch.aten.mul.Tensor %775, %776 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.4.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.layer_norm2.bias : tensor<768xf16>
    %778 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_834 = torch.constant.int 1
    %779 = torch.aten.add.Tensor %777, %778, %int1_834 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_835 = torch.constant.int 5
    %780 = torch.prims.convert_element_type %779, %int5_835 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_836 = torch.constant.int 5
    %781 = torch.prims.convert_element_type %result1_830, %int5_836 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_837 = torch.constant.int 5
    %782 = torch.prims.convert_element_type %773, %int5_837 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_838 = torch.constant.int 64
    %int768_839 = torch.constant.int 768
    %783 = torch.prim.ListConstruct %int64_838, %int768_839 : (!torch.int, !torch.int) -> !torch.list<int>
    %784 = torch.aten.view %780, %783 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc1.weight : tensor<3072x768xf16>
    %785 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_840 = torch.constant.int 0
    %int1_841 = torch.constant.int 1
    %786 = torch.aten.transpose.int %785, %int0_840, %int1_841 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc1.bias : tensor<3072xf16>
    %787 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_842 = torch.constant.int 6
    %788 = torch.prims.convert_element_type %787, %int6_842 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_843 = torch.constant.int 6
    %789 = torch.prims.convert_element_type %784, %int6_843 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_844 = torch.constant.int 6
    %790 = torch.prims.convert_element_type %786, %int6_844 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %791 = torch.aten.mm %789, %790 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_845 = torch.constant.int 1
    %792 = torch.aten.mul.Scalar %791, %int1_845 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_846 = torch.constant.int 1
    %793 = torch.aten.mul.Scalar %788, %int1_846 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_847 = torch.constant.int 1
    %794 = torch.aten.add.Tensor %792, %793, %int1_847 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_848 = torch.constant.int 5
    %795 = torch.prims.convert_element_type %794, %int5_848 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_849 = torch.constant.int 1
    %int64_850 = torch.constant.int 64
    %int3072_851 = torch.constant.int 3072
    %796 = torch.prim.ListConstruct %int1_849, %int64_850, %int3072_851 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %797 = torch.aten.view %795, %796 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00_852 = torch.constant.float 1.702000e+00
    %798 = torch.aten.mul.Scalar %797, %float1.702000e00_852 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %799 = torch.aten.sigmoid %798 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %800 = torch.aten.detach %799 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %801 = torch.aten.mul.Tensor %797, %799 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_853 = torch.constant.int 64
    %int3072_854 = torch.constant.int 3072
    %802 = torch.prim.ListConstruct %int64_853, %int3072_854 : (!torch.int, !torch.int) -> !torch.list<int>
    %803 = torch.aten.view %801, %802 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc2.weight : tensor<768x3072xf16>
    %804 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_855 = torch.constant.int 0
    %int1_856 = torch.constant.int 1
    %805 = torch.aten.transpose.int %804, %int0_855, %int1_856 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc2.bias : tensor<768xf16>
    %806 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.4.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_857 = torch.constant.int 6
    %807 = torch.prims.convert_element_type %806, %int6_857 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_858 = torch.constant.int 6
    %808 = torch.prims.convert_element_type %803, %int6_858 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_859 = torch.constant.int 6
    %809 = torch.prims.convert_element_type %805, %int6_859 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %810 = torch.aten.mm %808, %809 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_860 = torch.constant.int 1
    %811 = torch.aten.mul.Scalar %810, %int1_860 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_861 = torch.constant.int 1
    %812 = torch.aten.mul.Scalar %807, %int1_861 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_862 = torch.constant.int 1
    %813 = torch.aten.add.Tensor %811, %812, %int1_862 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_863 = torch.constant.int 5
    %814 = torch.prims.convert_element_type %813, %int5_863 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_864 = torch.constant.int 1
    %int64_865 = torch.constant.int 64
    %int768_866 = torch.constant.int 768
    %815 = torch.prim.ListConstruct %int1_864, %int64_865, %int768_866 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %816 = torch.aten.view %814, %815 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_867 = torch.constant.int 1
    %817 = torch.aten.add.Tensor %769, %816, %int1_867 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_868 = torch.constant.int 6
    %818 = torch.prims.convert_element_type %817, %int6_868 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_869 = torch.constant.int 2
    %819 = torch.prim.ListConstruct %int2_869 : (!torch.int) -> !torch.list<int>
    %int0_870 = torch.constant.int 0
    %true_871 = torch.constant.bool true
    %result0_872, %result1_873 = torch.aten.var_mean.correction %818, %819, %int0_870, %true_871 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_874 = torch.constant.float 1.000000e-05
    %int1_875 = torch.constant.int 1
    %820 = torch.aten.add.Scalar %result0_872, %float1.000000e-05_874, %int1_875 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %821 = torch.aten.rsqrt %820 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_876 = torch.constant.int 1
    %822 = torch.aten.sub.Tensor %817, %result1_873, %int1_876 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %823 = torch.aten.mul.Tensor %822, %821 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.5.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.layer_norm1.weight : tensor<768xf16>
    %824 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %825 = torch.aten.mul.Tensor %823, %824 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.5.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.layer_norm1.bias : tensor<768xf16>
    %826 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_877 = torch.constant.int 1
    %827 = torch.aten.add.Tensor %825, %826, %int1_877 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_878 = torch.constant.int 5
    %828 = torch.prims.convert_element_type %827, %int5_878 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_879 = torch.constant.int 5
    %829 = torch.prims.convert_element_type %result1_873, %int5_879 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_880 = torch.constant.int 5
    %830 = torch.prims.convert_element_type %821, %int5_880 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_881 = torch.constant.int 64
    %int768_882 = torch.constant.int 768
    %831 = torch.prim.ListConstruct %int64_881, %int768_882 : (!torch.int, !torch.int) -> !torch.list<int>
    %832 = torch.aten.view %828, %831 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.q_proj.weight : tensor<768x768xf16>
    %833 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_883 = torch.constant.int 0
    %int1_884 = torch.constant.int 1
    %834 = torch.aten.transpose.int %833, %int0_883, %int1_884 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.q_proj.bias : tensor<768xf16>
    %835 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_885 = torch.constant.int 6
    %836 = torch.prims.convert_element_type %835, %int6_885 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_886 = torch.constant.int 6
    %837 = torch.prims.convert_element_type %832, %int6_886 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_887 = torch.constant.int 6
    %838 = torch.prims.convert_element_type %834, %int6_887 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %839 = torch.aten.mm %837, %838 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_888 = torch.constant.int 1
    %840 = torch.aten.mul.Scalar %839, %int1_888 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_889 = torch.constant.int 1
    %841 = torch.aten.mul.Scalar %836, %int1_889 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_890 = torch.constant.int 1
    %842 = torch.aten.add.Tensor %840, %841, %int1_890 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_891 = torch.constant.int 5
    %843 = torch.prims.convert_element_type %842, %int5_891 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_892 = torch.constant.int 1
    %int64_893 = torch.constant.int 64
    %int768_894 = torch.constant.int 768
    %844 = torch.prim.ListConstruct %int1_892, %int64_893, %int768_894 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %845 = torch.aten.view %843, %844 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01_895 = torch.constant.float 1.250000e-01
    %846 = torch.aten.mul.Scalar %845, %float1.250000e-01_895 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_896 = torch.constant.int 64
    %int768_897 = torch.constant.int 768
    %847 = torch.prim.ListConstruct %int64_896, %int768_897 : (!torch.int, !torch.int) -> !torch.list<int>
    %848 = torch.aten.view %828, %847 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.k_proj.weight : tensor<768x768xf16>
    %849 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_898 = torch.constant.int 0
    %int1_899 = torch.constant.int 1
    %850 = torch.aten.transpose.int %849, %int0_898, %int1_899 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.k_proj.bias : tensor<768xf16>
    %851 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_900 = torch.constant.int 6
    %852 = torch.prims.convert_element_type %851, %int6_900 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_901 = torch.constant.int 6
    %853 = torch.prims.convert_element_type %848, %int6_901 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_902 = torch.constant.int 6
    %854 = torch.prims.convert_element_type %850, %int6_902 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %855 = torch.aten.mm %853, %854 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_903 = torch.constant.int 1
    %856 = torch.aten.mul.Scalar %855, %int1_903 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_904 = torch.constant.int 1
    %857 = torch.aten.mul.Scalar %852, %int1_904 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_905 = torch.constant.int 1
    %858 = torch.aten.add.Tensor %856, %857, %int1_905 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_906 = torch.constant.int 5
    %859 = torch.prims.convert_element_type %858, %int5_906 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_907 = torch.constant.int 1
    %int64_908 = torch.constant.int 64
    %int768_909 = torch.constant.int 768
    %860 = torch.prim.ListConstruct %int1_907, %int64_908, %int768_909 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %861 = torch.aten.view %859, %860 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_910 = torch.constant.int 1
    %int-1_911 = torch.constant.int -1
    %int12_912 = torch.constant.int 12
    %int64_913 = torch.constant.int 64
    %862 = torch.prim.ListConstruct %int1_910, %int-1_911, %int12_912, %int64_913 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %863 = torch.aten.view %861, %862 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_914 = torch.constant.int 1
    %int2_915 = torch.constant.int 2
    %864 = torch.aten.transpose.int %863, %int1_914, %int2_915 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_916 = torch.constant.int 0
    %865 = torch.aten.clone %864, %int0_916 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_917 = torch.constant.int 64
    %int768_918 = torch.constant.int 768
    %866 = torch.prim.ListConstruct %int64_917, %int768_918 : (!torch.int, !torch.int) -> !torch.list<int>
    %867 = torch.aten.view %828, %866 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.v_proj.weight : tensor<768x768xf16>
    %868 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_919 = torch.constant.int 0
    %int1_920 = torch.constant.int 1
    %869 = torch.aten.transpose.int %868, %int0_919, %int1_920 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.v_proj.bias : tensor<768xf16>
    %870 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_921 = torch.constant.int 6
    %871 = torch.prims.convert_element_type %870, %int6_921 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_922 = torch.constant.int 6
    %872 = torch.prims.convert_element_type %867, %int6_922 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_923 = torch.constant.int 6
    %873 = torch.prims.convert_element_type %869, %int6_923 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %874 = torch.aten.mm %872, %873 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_924 = torch.constant.int 1
    %875 = torch.aten.mul.Scalar %874, %int1_924 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_925 = torch.constant.int 1
    %876 = torch.aten.mul.Scalar %871, %int1_925 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_926 = torch.constant.int 1
    %877 = torch.aten.add.Tensor %875, %876, %int1_926 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_927 = torch.constant.int 5
    %878 = torch.prims.convert_element_type %877, %int5_927 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_928 = torch.constant.int 1
    %int64_929 = torch.constant.int 64
    %int768_930 = torch.constant.int 768
    %879 = torch.prim.ListConstruct %int1_928, %int64_929, %int768_930 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %880 = torch.aten.view %878, %879 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_931 = torch.constant.int 1
    %int-1_932 = torch.constant.int -1
    %int12_933 = torch.constant.int 12
    %int64_934 = torch.constant.int 64
    %881 = torch.prim.ListConstruct %int1_931, %int-1_932, %int12_933, %int64_934 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %882 = torch.aten.view %880, %881 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_935 = torch.constant.int 1
    %int2_936 = torch.constant.int 2
    %883 = torch.aten.transpose.int %882, %int1_935, %int2_936 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_937 = torch.constant.int 0
    %884 = torch.aten.clone %883, %int0_937 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_938 = torch.constant.int 1
    %int64_939 = torch.constant.int 64
    %int12_940 = torch.constant.int 12
    %int64_941 = torch.constant.int 64
    %885 = torch.prim.ListConstruct %int1_938, %int64_939, %int12_940, %int64_941 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %886 = torch.aten.view %846, %885 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_942 = torch.constant.int 1
    %int2_943 = torch.constant.int 2
    %887 = torch.aten.transpose.int %886, %int1_942, %int2_943 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_944 = torch.constant.int 0
    %888 = torch.aten.clone %887, %int0_944 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_945 = torch.constant.int 12
    %int-1_946 = torch.constant.int -1
    %int64_947 = torch.constant.int 64
    %889 = torch.prim.ListConstruct %int12_945, %int-1_946, %int64_947 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %890 = torch.aten.view %888, %889 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_948 = torch.constant.int 12
    %int-1_949 = torch.constant.int -1
    %int64_950 = torch.constant.int 64
    %891 = torch.prim.ListConstruct %int12_948, %int-1_949, %int64_950 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %892 = torch.aten.view %865, %891 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_951 = torch.constant.int 12
    %int-1_952 = torch.constant.int -1
    %int64_953 = torch.constant.int 64
    %893 = torch.prim.ListConstruct %int12_951, %int-1_952, %int64_953 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %894 = torch.aten.view %884, %893 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_954 = torch.constant.int 1
    %int2_955 = torch.constant.int 2
    %895 = torch.aten.transpose.int %892, %int1_954, %int2_955 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %896 = torch.aten.bmm %890, %895 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_956 = torch.constant.int 1
    %int12_957 = torch.constant.int 12
    %int64_958 = torch.constant.int 64
    %int64_959 = torch.constant.int 64
    %897 = torch.prim.ListConstruct %int1_956, %int12_957, %int64_958, %int64_959 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %898 = torch.aten.view %896, %897 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_960 = torch.constant.int 1
    %899 = torch.aten.add.Tensor %898, %27, %int1_960 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_961 = torch.constant.int 12
    %int64_962 = torch.constant.int 64
    %int64_963 = torch.constant.int 64
    %900 = torch.prim.ListConstruct %int12_961, %int64_962, %int64_963 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %901 = torch.aten.view %899, %900 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_964 = torch.constant.int -1
    %false_965 = torch.constant.bool false
    %902 = torch.aten._softmax %901, %int-1_964, %false_965 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %903 = torch.aten.detach %902 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_966 = torch.constant.none
    %904 = torch.aten.clone %902, %none_966 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %905 = torch.aten.bmm %904, %894 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_967 = torch.constant.int 1
    %int12_968 = torch.constant.int 12
    %int64_969 = torch.constant.int 64
    %int64_970 = torch.constant.int 64
    %906 = torch.prim.ListConstruct %int1_967, %int12_968, %int64_969, %int64_970 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %907 = torch.aten.view %905, %906 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_971 = torch.constant.int 1
    %int2_972 = torch.constant.int 2
    %908 = torch.aten.transpose.int %907, %int1_971, %int2_972 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_973 = torch.constant.int 0
    %909 = torch.aten.clone %908, %int0_973 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_974 = torch.constant.int 1
    %int64_975 = torch.constant.int 64
    %int768_976 = torch.constant.int 768
    %910 = torch.prim.ListConstruct %int1_974, %int64_975, %int768_976 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %911 = torch.aten._unsafe_view %909, %910 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_977 = torch.constant.int 64
    %int768_978 = torch.constant.int 768
    %912 = torch.prim.ListConstruct %int64_977, %int768_978 : (!torch.int, !torch.int) -> !torch.list<int>
    %913 = torch.aten.view %911, %912 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.out_proj.weight : tensor<768x768xf16>
    %914 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_979 = torch.constant.int 0
    %int1_980 = torch.constant.int 1
    %915 = torch.aten.transpose.int %914, %int0_979, %int1_980 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.self_attn.out_proj.bias : tensor<768xf16>
    %916 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_981 = torch.constant.int 6
    %917 = torch.prims.convert_element_type %916, %int6_981 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_982 = torch.constant.int 6
    %918 = torch.prims.convert_element_type %913, %int6_982 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_983 = torch.constant.int 6
    %919 = torch.prims.convert_element_type %915, %int6_983 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %920 = torch.aten.mm %918, %919 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_984 = torch.constant.int 1
    %921 = torch.aten.mul.Scalar %920, %int1_984 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_985 = torch.constant.int 1
    %922 = torch.aten.mul.Scalar %917, %int1_985 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_986 = torch.constant.int 1
    %923 = torch.aten.add.Tensor %921, %922, %int1_986 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_987 = torch.constant.int 5
    %924 = torch.prims.convert_element_type %923, %int5_987 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_988 = torch.constant.int 1
    %int64_989 = torch.constant.int 64
    %int768_990 = torch.constant.int 768
    %925 = torch.prim.ListConstruct %int1_988, %int64_989, %int768_990 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %926 = torch.aten.view %924, %925 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_991 = torch.constant.int 1
    %927 = torch.aten.add.Tensor %817, %926, %int1_991 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_992 = torch.constant.int 6
    %928 = torch.prims.convert_element_type %927, %int6_992 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_993 = torch.constant.int 2
    %929 = torch.prim.ListConstruct %int2_993 : (!torch.int) -> !torch.list<int>
    %int0_994 = torch.constant.int 0
    %true_995 = torch.constant.bool true
    %result0_996, %result1_997 = torch.aten.var_mean.correction %928, %929, %int0_994, %true_995 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_998 = torch.constant.float 1.000000e-05
    %int1_999 = torch.constant.int 1
    %930 = torch.aten.add.Scalar %result0_996, %float1.000000e-05_998, %int1_999 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %931 = torch.aten.rsqrt %930 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1000 = torch.constant.int 1
    %932 = torch.aten.sub.Tensor %927, %result1_997, %int1_1000 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %933 = torch.aten.mul.Tensor %932, %931 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.5.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.layer_norm2.weight : tensor<768xf16>
    %934 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %935 = torch.aten.mul.Tensor %933, %934 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.5.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.layer_norm2.bias : tensor<768xf16>
    %936 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1001 = torch.constant.int 1
    %937 = torch.aten.add.Tensor %935, %936, %int1_1001 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1002 = torch.constant.int 5
    %938 = torch.prims.convert_element_type %937, %int5_1002 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1003 = torch.constant.int 5
    %939 = torch.prims.convert_element_type %result1_997, %int5_1003 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1004 = torch.constant.int 5
    %940 = torch.prims.convert_element_type %931, %int5_1004 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1005 = torch.constant.int 64
    %int768_1006 = torch.constant.int 768
    %941 = torch.prim.ListConstruct %int64_1005, %int768_1006 : (!torch.int, !torch.int) -> !torch.list<int>
    %942 = torch.aten.view %938, %941 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc1.weight : tensor<3072x768xf16>
    %943 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_1007 = torch.constant.int 0
    %int1_1008 = torch.constant.int 1
    %944 = torch.aten.transpose.int %943, %int0_1007, %int1_1008 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc1.bias : tensor<3072xf16>
    %945 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_1009 = torch.constant.int 6
    %946 = torch.prims.convert_element_type %945, %int6_1009 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_1010 = torch.constant.int 6
    %947 = torch.prims.convert_element_type %942, %int6_1010 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1011 = torch.constant.int 6
    %948 = torch.prims.convert_element_type %944, %int6_1011 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %949 = torch.aten.mm %947, %948 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_1012 = torch.constant.int 1
    %950 = torch.aten.mul.Scalar %949, %int1_1012 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_1013 = torch.constant.int 1
    %951 = torch.aten.mul.Scalar %946, %int1_1013 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_1014 = torch.constant.int 1
    %952 = torch.aten.add.Tensor %950, %951, %int1_1014 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_1015 = torch.constant.int 5
    %953 = torch.prims.convert_element_type %952, %int5_1015 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_1016 = torch.constant.int 1
    %int64_1017 = torch.constant.int 64
    %int3072_1018 = torch.constant.int 3072
    %954 = torch.prim.ListConstruct %int1_1016, %int64_1017, %int3072_1018 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %955 = torch.aten.view %953, %954 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00_1019 = torch.constant.float 1.702000e+00
    %956 = torch.aten.mul.Scalar %955, %float1.702000e00_1019 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %957 = torch.aten.sigmoid %956 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %958 = torch.aten.detach %957 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %959 = torch.aten.mul.Tensor %955, %957 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_1020 = torch.constant.int 64
    %int3072_1021 = torch.constant.int 3072
    %960 = torch.prim.ListConstruct %int64_1020, %int3072_1021 : (!torch.int, !torch.int) -> !torch.list<int>
    %961 = torch.aten.view %959, %960 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc2.weight : tensor<768x3072xf16>
    %962 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_1022 = torch.constant.int 0
    %int1_1023 = torch.constant.int 1
    %963 = torch.aten.transpose.int %962, %int0_1022, %int1_1023 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc2.bias : tensor<768xf16>
    %964 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.5.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1024 = torch.constant.int 6
    %965 = torch.prims.convert_element_type %964, %int6_1024 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1025 = torch.constant.int 6
    %966 = torch.prims.convert_element_type %961, %int6_1025 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_1026 = torch.constant.int 6
    %967 = torch.prims.convert_element_type %963, %int6_1026 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %968 = torch.aten.mm %966, %967 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1027 = torch.constant.int 1
    %969 = torch.aten.mul.Scalar %968, %int1_1027 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1028 = torch.constant.int 1
    %970 = torch.aten.mul.Scalar %965, %int1_1028 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1029 = torch.constant.int 1
    %971 = torch.aten.add.Tensor %969, %970, %int1_1029 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1030 = torch.constant.int 5
    %972 = torch.prims.convert_element_type %971, %int5_1030 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1031 = torch.constant.int 1
    %int64_1032 = torch.constant.int 64
    %int768_1033 = torch.constant.int 768
    %973 = torch.prim.ListConstruct %int1_1031, %int64_1032, %int768_1033 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %974 = torch.aten.view %972, %973 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1034 = torch.constant.int 1
    %975 = torch.aten.add.Tensor %927, %974, %int1_1034 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1035 = torch.constant.int 6
    %976 = torch.prims.convert_element_type %975, %int6_1035 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1036 = torch.constant.int 2
    %977 = torch.prim.ListConstruct %int2_1036 : (!torch.int) -> !torch.list<int>
    %int0_1037 = torch.constant.int 0
    %true_1038 = torch.constant.bool true
    %result0_1039, %result1_1040 = torch.aten.var_mean.correction %976, %977, %int0_1037, %true_1038 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_1041 = torch.constant.float 1.000000e-05
    %int1_1042 = torch.constant.int 1
    %978 = torch.aten.add.Scalar %result0_1039, %float1.000000e-05_1041, %int1_1042 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %979 = torch.aten.rsqrt %978 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1043 = torch.constant.int 1
    %980 = torch.aten.sub.Tensor %975, %result1_1040, %int1_1043 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %981 = torch.aten.mul.Tensor %980, %979 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.6.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.layer_norm1.weight : tensor<768xf16>
    %982 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %983 = torch.aten.mul.Tensor %981, %982 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.6.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.layer_norm1.bias : tensor<768xf16>
    %984 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1044 = torch.constant.int 1
    %985 = torch.aten.add.Tensor %983, %984, %int1_1044 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1045 = torch.constant.int 5
    %986 = torch.prims.convert_element_type %985, %int5_1045 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1046 = torch.constant.int 5
    %987 = torch.prims.convert_element_type %result1_1040, %int5_1046 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1047 = torch.constant.int 5
    %988 = torch.prims.convert_element_type %979, %int5_1047 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1048 = torch.constant.int 64
    %int768_1049 = torch.constant.int 768
    %989 = torch.prim.ListConstruct %int64_1048, %int768_1049 : (!torch.int, !torch.int) -> !torch.list<int>
    %990 = torch.aten.view %986, %989 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.q_proj.weight : tensor<768x768xf16>
    %991 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1050 = torch.constant.int 0
    %int1_1051 = torch.constant.int 1
    %992 = torch.aten.transpose.int %991, %int0_1050, %int1_1051 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.q_proj.bias : tensor<768xf16>
    %993 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1052 = torch.constant.int 6
    %994 = torch.prims.convert_element_type %993, %int6_1052 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1053 = torch.constant.int 6
    %995 = torch.prims.convert_element_type %990, %int6_1053 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1054 = torch.constant.int 6
    %996 = torch.prims.convert_element_type %992, %int6_1054 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %997 = torch.aten.mm %995, %996 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1055 = torch.constant.int 1
    %998 = torch.aten.mul.Scalar %997, %int1_1055 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1056 = torch.constant.int 1
    %999 = torch.aten.mul.Scalar %994, %int1_1056 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1057 = torch.constant.int 1
    %1000 = torch.aten.add.Tensor %998, %999, %int1_1057 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1058 = torch.constant.int 5
    %1001 = torch.prims.convert_element_type %1000, %int5_1058 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1059 = torch.constant.int 1
    %int64_1060 = torch.constant.int 64
    %int768_1061 = torch.constant.int 768
    %1002 = torch.prim.ListConstruct %int1_1059, %int64_1060, %int768_1061 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1003 = torch.aten.view %1001, %1002 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01_1062 = torch.constant.float 1.250000e-01
    %1004 = torch.aten.mul.Scalar %1003, %float1.250000e-01_1062 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_1063 = torch.constant.int 64
    %int768_1064 = torch.constant.int 768
    %1005 = torch.prim.ListConstruct %int64_1063, %int768_1064 : (!torch.int, !torch.int) -> !torch.list<int>
    %1006 = torch.aten.view %986, %1005 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.k_proj.weight : tensor<768x768xf16>
    %1007 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1065 = torch.constant.int 0
    %int1_1066 = torch.constant.int 1
    %1008 = torch.aten.transpose.int %1007, %int0_1065, %int1_1066 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.k_proj.bias : tensor<768xf16>
    %1009 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1067 = torch.constant.int 6
    %1010 = torch.prims.convert_element_type %1009, %int6_1067 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1068 = torch.constant.int 6
    %1011 = torch.prims.convert_element_type %1006, %int6_1068 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1069 = torch.constant.int 6
    %1012 = torch.prims.convert_element_type %1008, %int6_1069 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1013 = torch.aten.mm %1011, %1012 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1070 = torch.constant.int 1
    %1014 = torch.aten.mul.Scalar %1013, %int1_1070 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1071 = torch.constant.int 1
    %1015 = torch.aten.mul.Scalar %1010, %int1_1071 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1072 = torch.constant.int 1
    %1016 = torch.aten.add.Tensor %1014, %1015, %int1_1072 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1073 = torch.constant.int 5
    %1017 = torch.prims.convert_element_type %1016, %int5_1073 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1074 = torch.constant.int 1
    %int64_1075 = torch.constant.int 64
    %int768_1076 = torch.constant.int 768
    %1018 = torch.prim.ListConstruct %int1_1074, %int64_1075, %int768_1076 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1019 = torch.aten.view %1017, %1018 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1077 = torch.constant.int 1
    %int-1_1078 = torch.constant.int -1
    %int12_1079 = torch.constant.int 12
    %int64_1080 = torch.constant.int 64
    %1020 = torch.prim.ListConstruct %int1_1077, %int-1_1078, %int12_1079, %int64_1080 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1021 = torch.aten.view %1019, %1020 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1081 = torch.constant.int 1
    %int2_1082 = torch.constant.int 2
    %1022 = torch.aten.transpose.int %1021, %int1_1081, %int2_1082 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1083 = torch.constant.int 0
    %1023 = torch.aten.clone %1022, %int0_1083 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_1084 = torch.constant.int 64
    %int768_1085 = torch.constant.int 768
    %1024 = torch.prim.ListConstruct %int64_1084, %int768_1085 : (!torch.int, !torch.int) -> !torch.list<int>
    %1025 = torch.aten.view %986, %1024 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.v_proj.weight : tensor<768x768xf16>
    %1026 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1086 = torch.constant.int 0
    %int1_1087 = torch.constant.int 1
    %1027 = torch.aten.transpose.int %1026, %int0_1086, %int1_1087 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.v_proj.bias : tensor<768xf16>
    %1028 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1088 = torch.constant.int 6
    %1029 = torch.prims.convert_element_type %1028, %int6_1088 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1089 = torch.constant.int 6
    %1030 = torch.prims.convert_element_type %1025, %int6_1089 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1090 = torch.constant.int 6
    %1031 = torch.prims.convert_element_type %1027, %int6_1090 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1032 = torch.aten.mm %1030, %1031 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1091 = torch.constant.int 1
    %1033 = torch.aten.mul.Scalar %1032, %int1_1091 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1092 = torch.constant.int 1
    %1034 = torch.aten.mul.Scalar %1029, %int1_1092 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1093 = torch.constant.int 1
    %1035 = torch.aten.add.Tensor %1033, %1034, %int1_1093 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1094 = torch.constant.int 5
    %1036 = torch.prims.convert_element_type %1035, %int5_1094 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1095 = torch.constant.int 1
    %int64_1096 = torch.constant.int 64
    %int768_1097 = torch.constant.int 768
    %1037 = torch.prim.ListConstruct %int1_1095, %int64_1096, %int768_1097 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1038 = torch.aten.view %1036, %1037 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1098 = torch.constant.int 1
    %int-1_1099 = torch.constant.int -1
    %int12_1100 = torch.constant.int 12
    %int64_1101 = torch.constant.int 64
    %1039 = torch.prim.ListConstruct %int1_1098, %int-1_1099, %int12_1100, %int64_1101 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1040 = torch.aten.view %1038, %1039 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1102 = torch.constant.int 1
    %int2_1103 = torch.constant.int 2
    %1041 = torch.aten.transpose.int %1040, %int1_1102, %int2_1103 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1104 = torch.constant.int 0
    %1042 = torch.aten.clone %1041, %int0_1104 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1105 = torch.constant.int 1
    %int64_1106 = torch.constant.int 64
    %int12_1107 = torch.constant.int 12
    %int64_1108 = torch.constant.int 64
    %1043 = torch.prim.ListConstruct %int1_1105, %int64_1106, %int12_1107, %int64_1108 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1044 = torch.aten.view %1004, %1043 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1109 = torch.constant.int 1
    %int2_1110 = torch.constant.int 2
    %1045 = torch.aten.transpose.int %1044, %int1_1109, %int2_1110 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1111 = torch.constant.int 0
    %1046 = torch.aten.clone %1045, %int0_1111 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1112 = torch.constant.int 12
    %int-1_1113 = torch.constant.int -1
    %int64_1114 = torch.constant.int 64
    %1047 = torch.prim.ListConstruct %int12_1112, %int-1_1113, %int64_1114 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1048 = torch.aten.view %1046, %1047 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1115 = torch.constant.int 12
    %int-1_1116 = torch.constant.int -1
    %int64_1117 = torch.constant.int 64
    %1049 = torch.prim.ListConstruct %int12_1115, %int-1_1116, %int64_1117 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1050 = torch.aten.view %1023, %1049 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1118 = torch.constant.int 12
    %int-1_1119 = torch.constant.int -1
    %int64_1120 = torch.constant.int 64
    %1051 = torch.prim.ListConstruct %int12_1118, %int-1_1119, %int64_1120 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1052 = torch.aten.view %1042, %1051 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_1121 = torch.constant.int 1
    %int2_1122 = torch.constant.int 2
    %1053 = torch.aten.transpose.int %1050, %int1_1121, %int2_1122 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %1054 = torch.aten.bmm %1048, %1053 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1123 = torch.constant.int 1
    %int12_1124 = torch.constant.int 12
    %int64_1125 = torch.constant.int 64
    %int64_1126 = torch.constant.int 64
    %1055 = torch.prim.ListConstruct %int1_1123, %int12_1124, %int64_1125, %int64_1126 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1056 = torch.aten.view %1054, %1055 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1127 = torch.constant.int 1
    %1057 = torch.aten.add.Tensor %1056, %27, %int1_1127 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1128 = torch.constant.int 12
    %int64_1129 = torch.constant.int 64
    %int64_1130 = torch.constant.int 64
    %1058 = torch.prim.ListConstruct %int12_1128, %int64_1129, %int64_1130 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1059 = torch.aten.view %1057, %1058 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_1131 = torch.constant.int -1
    %false_1132 = torch.constant.bool false
    %1060 = torch.aten._softmax %1059, %int-1_1131, %false_1132 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %1061 = torch.aten.detach %1060 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_1133 = torch.constant.none
    %1062 = torch.aten.clone %1060, %none_1133 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %1063 = torch.aten.bmm %1062, %1052 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1134 = torch.constant.int 1
    %int12_1135 = torch.constant.int 12
    %int64_1136 = torch.constant.int 64
    %int64_1137 = torch.constant.int 64
    %1064 = torch.prim.ListConstruct %int1_1134, %int12_1135, %int64_1136, %int64_1137 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1065 = torch.aten.view %1063, %1064 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1138 = torch.constant.int 1
    %int2_1139 = torch.constant.int 2
    %1066 = torch.aten.transpose.int %1065, %int1_1138, %int2_1139 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_1140 = torch.constant.int 0
    %1067 = torch.aten.clone %1066, %int0_1140 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1141 = torch.constant.int 1
    %int64_1142 = torch.constant.int 64
    %int768_1143 = torch.constant.int 768
    %1068 = torch.prim.ListConstruct %int1_1141, %int64_1142, %int768_1143 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1069 = torch.aten._unsafe_view %1067, %1068 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_1144 = torch.constant.int 64
    %int768_1145 = torch.constant.int 768
    %1070 = torch.prim.ListConstruct %int64_1144, %int768_1145 : (!torch.int, !torch.int) -> !torch.list<int>
    %1071 = torch.aten.view %1069, %1070 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.out_proj.weight : tensor<768x768xf16>
    %1072 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1146 = torch.constant.int 0
    %int1_1147 = torch.constant.int 1
    %1073 = torch.aten.transpose.int %1072, %int0_1146, %int1_1147 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.self_attn.out_proj.bias : tensor<768xf16>
    %1074 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1148 = torch.constant.int 6
    %1075 = torch.prims.convert_element_type %1074, %int6_1148 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1149 = torch.constant.int 6
    %1076 = torch.prims.convert_element_type %1071, %int6_1149 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1150 = torch.constant.int 6
    %1077 = torch.prims.convert_element_type %1073, %int6_1150 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1078 = torch.aten.mm %1076, %1077 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1151 = torch.constant.int 1
    %1079 = torch.aten.mul.Scalar %1078, %int1_1151 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1152 = torch.constant.int 1
    %1080 = torch.aten.mul.Scalar %1075, %int1_1152 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1153 = torch.constant.int 1
    %1081 = torch.aten.add.Tensor %1079, %1080, %int1_1153 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1154 = torch.constant.int 5
    %1082 = torch.prims.convert_element_type %1081, %int5_1154 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1155 = torch.constant.int 1
    %int64_1156 = torch.constant.int 64
    %int768_1157 = torch.constant.int 768
    %1083 = torch.prim.ListConstruct %int1_1155, %int64_1156, %int768_1157 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1084 = torch.aten.view %1082, %1083 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1158 = torch.constant.int 1
    %1085 = torch.aten.add.Tensor %975, %1084, %int1_1158 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1159 = torch.constant.int 6
    %1086 = torch.prims.convert_element_type %1085, %int6_1159 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1160 = torch.constant.int 2
    %1087 = torch.prim.ListConstruct %int2_1160 : (!torch.int) -> !torch.list<int>
    %int0_1161 = torch.constant.int 0
    %true_1162 = torch.constant.bool true
    %result0_1163, %result1_1164 = torch.aten.var_mean.correction %1086, %1087, %int0_1161, %true_1162 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_1165 = torch.constant.float 1.000000e-05
    %int1_1166 = torch.constant.int 1
    %1088 = torch.aten.add.Scalar %result0_1163, %float1.000000e-05_1165, %int1_1166 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1089 = torch.aten.rsqrt %1088 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1167 = torch.constant.int 1
    %1090 = torch.aten.sub.Tensor %1085, %result1_1164, %int1_1167 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1091 = torch.aten.mul.Tensor %1090, %1089 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.6.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.layer_norm2.weight : tensor<768xf16>
    %1092 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1093 = torch.aten.mul.Tensor %1091, %1092 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.6.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.layer_norm2.bias : tensor<768xf16>
    %1094 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1168 = torch.constant.int 1
    %1095 = torch.aten.add.Tensor %1093, %1094, %int1_1168 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1169 = torch.constant.int 5
    %1096 = torch.prims.convert_element_type %1095, %int5_1169 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1170 = torch.constant.int 5
    %1097 = torch.prims.convert_element_type %result1_1164, %int5_1170 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1171 = torch.constant.int 5
    %1098 = torch.prims.convert_element_type %1089, %int5_1171 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1172 = torch.constant.int 64
    %int768_1173 = torch.constant.int 768
    %1099 = torch.prim.ListConstruct %int64_1172, %int768_1173 : (!torch.int, !torch.int) -> !torch.list<int>
    %1100 = torch.aten.view %1096, %1099 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc1.weight : tensor<3072x768xf16>
    %1101 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_1174 = torch.constant.int 0
    %int1_1175 = torch.constant.int 1
    %1102 = torch.aten.transpose.int %1101, %int0_1174, %int1_1175 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc1.bias : tensor<3072xf16>
    %1103 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_1176 = torch.constant.int 6
    %1104 = torch.prims.convert_element_type %1103, %int6_1176 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_1177 = torch.constant.int 6
    %1105 = torch.prims.convert_element_type %1100, %int6_1177 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1178 = torch.constant.int 6
    %1106 = torch.prims.convert_element_type %1102, %int6_1178 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %1107 = torch.aten.mm %1105, %1106 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_1179 = torch.constant.int 1
    %1108 = torch.aten.mul.Scalar %1107, %int1_1179 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_1180 = torch.constant.int 1
    %1109 = torch.aten.mul.Scalar %1104, %int1_1180 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_1181 = torch.constant.int 1
    %1110 = torch.aten.add.Tensor %1108, %1109, %int1_1181 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_1182 = torch.constant.int 5
    %1111 = torch.prims.convert_element_type %1110, %int5_1182 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_1183 = torch.constant.int 1
    %int64_1184 = torch.constant.int 64
    %int3072_1185 = torch.constant.int 3072
    %1112 = torch.prim.ListConstruct %int1_1183, %int64_1184, %int3072_1185 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1113 = torch.aten.view %1111, %1112 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00_1186 = torch.constant.float 1.702000e+00
    %1114 = torch.aten.mul.Scalar %1113, %float1.702000e00_1186 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %1115 = torch.aten.sigmoid %1114 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1116 = torch.aten.detach %1115 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1117 = torch.aten.mul.Tensor %1113, %1115 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_1187 = torch.constant.int 64
    %int3072_1188 = torch.constant.int 3072
    %1118 = torch.prim.ListConstruct %int64_1187, %int3072_1188 : (!torch.int, !torch.int) -> !torch.list<int>
    %1119 = torch.aten.view %1117, %1118 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc2.weight : tensor<768x3072xf16>
    %1120 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_1189 = torch.constant.int 0
    %int1_1190 = torch.constant.int 1
    %1121 = torch.aten.transpose.int %1120, %int0_1189, %int1_1190 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc2.bias : tensor<768xf16>
    %1122 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.6.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1191 = torch.constant.int 6
    %1123 = torch.prims.convert_element_type %1122, %int6_1191 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1192 = torch.constant.int 6
    %1124 = torch.prims.convert_element_type %1119, %int6_1192 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_1193 = torch.constant.int 6
    %1125 = torch.prims.convert_element_type %1121, %int6_1193 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %1126 = torch.aten.mm %1124, %1125 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1194 = torch.constant.int 1
    %1127 = torch.aten.mul.Scalar %1126, %int1_1194 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1195 = torch.constant.int 1
    %1128 = torch.aten.mul.Scalar %1123, %int1_1195 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1196 = torch.constant.int 1
    %1129 = torch.aten.add.Tensor %1127, %1128, %int1_1196 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1197 = torch.constant.int 5
    %1130 = torch.prims.convert_element_type %1129, %int5_1197 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1198 = torch.constant.int 1
    %int64_1199 = torch.constant.int 64
    %int768_1200 = torch.constant.int 768
    %1131 = torch.prim.ListConstruct %int1_1198, %int64_1199, %int768_1200 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1132 = torch.aten.view %1130, %1131 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1201 = torch.constant.int 1
    %1133 = torch.aten.add.Tensor %1085, %1132, %int1_1201 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1202 = torch.constant.int 6
    %1134 = torch.prims.convert_element_type %1133, %int6_1202 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1203 = torch.constant.int 2
    %1135 = torch.prim.ListConstruct %int2_1203 : (!torch.int) -> !torch.list<int>
    %int0_1204 = torch.constant.int 0
    %true_1205 = torch.constant.bool true
    %result0_1206, %result1_1207 = torch.aten.var_mean.correction %1134, %1135, %int0_1204, %true_1205 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_1208 = torch.constant.float 1.000000e-05
    %int1_1209 = torch.constant.int 1
    %1136 = torch.aten.add.Scalar %result0_1206, %float1.000000e-05_1208, %int1_1209 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1137 = torch.aten.rsqrt %1136 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1210 = torch.constant.int 1
    %1138 = torch.aten.sub.Tensor %1133, %result1_1207, %int1_1210 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1139 = torch.aten.mul.Tensor %1138, %1137 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.7.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.layer_norm1.weight : tensor<768xf16>
    %1140 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1141 = torch.aten.mul.Tensor %1139, %1140 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.7.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.layer_norm1.bias : tensor<768xf16>
    %1142 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1211 = torch.constant.int 1
    %1143 = torch.aten.add.Tensor %1141, %1142, %int1_1211 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1212 = torch.constant.int 5
    %1144 = torch.prims.convert_element_type %1143, %int5_1212 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1213 = torch.constant.int 5
    %1145 = torch.prims.convert_element_type %result1_1207, %int5_1213 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1214 = torch.constant.int 5
    %1146 = torch.prims.convert_element_type %1137, %int5_1214 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1215 = torch.constant.int 64
    %int768_1216 = torch.constant.int 768
    %1147 = torch.prim.ListConstruct %int64_1215, %int768_1216 : (!torch.int, !torch.int) -> !torch.list<int>
    %1148 = torch.aten.view %1144, %1147 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.q_proj.weight : tensor<768x768xf16>
    %1149 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1217 = torch.constant.int 0
    %int1_1218 = torch.constant.int 1
    %1150 = torch.aten.transpose.int %1149, %int0_1217, %int1_1218 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.q_proj.bias : tensor<768xf16>
    %1151 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1219 = torch.constant.int 6
    %1152 = torch.prims.convert_element_type %1151, %int6_1219 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1220 = torch.constant.int 6
    %1153 = torch.prims.convert_element_type %1148, %int6_1220 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1221 = torch.constant.int 6
    %1154 = torch.prims.convert_element_type %1150, %int6_1221 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1155 = torch.aten.mm %1153, %1154 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1222 = torch.constant.int 1
    %1156 = torch.aten.mul.Scalar %1155, %int1_1222 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1223 = torch.constant.int 1
    %1157 = torch.aten.mul.Scalar %1152, %int1_1223 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1224 = torch.constant.int 1
    %1158 = torch.aten.add.Tensor %1156, %1157, %int1_1224 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1225 = torch.constant.int 5
    %1159 = torch.prims.convert_element_type %1158, %int5_1225 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1226 = torch.constant.int 1
    %int64_1227 = torch.constant.int 64
    %int768_1228 = torch.constant.int 768
    %1160 = torch.prim.ListConstruct %int1_1226, %int64_1227, %int768_1228 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1161 = torch.aten.view %1159, %1160 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01_1229 = torch.constant.float 1.250000e-01
    %1162 = torch.aten.mul.Scalar %1161, %float1.250000e-01_1229 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_1230 = torch.constant.int 64
    %int768_1231 = torch.constant.int 768
    %1163 = torch.prim.ListConstruct %int64_1230, %int768_1231 : (!torch.int, !torch.int) -> !torch.list<int>
    %1164 = torch.aten.view %1144, %1163 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.k_proj.weight : tensor<768x768xf16>
    %1165 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1232 = torch.constant.int 0
    %int1_1233 = torch.constant.int 1
    %1166 = torch.aten.transpose.int %1165, %int0_1232, %int1_1233 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.k_proj.bias : tensor<768xf16>
    %1167 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1234 = torch.constant.int 6
    %1168 = torch.prims.convert_element_type %1167, %int6_1234 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1235 = torch.constant.int 6
    %1169 = torch.prims.convert_element_type %1164, %int6_1235 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1236 = torch.constant.int 6
    %1170 = torch.prims.convert_element_type %1166, %int6_1236 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1171 = torch.aten.mm %1169, %1170 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1237 = torch.constant.int 1
    %1172 = torch.aten.mul.Scalar %1171, %int1_1237 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1238 = torch.constant.int 1
    %1173 = torch.aten.mul.Scalar %1168, %int1_1238 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1239 = torch.constant.int 1
    %1174 = torch.aten.add.Tensor %1172, %1173, %int1_1239 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1240 = torch.constant.int 5
    %1175 = torch.prims.convert_element_type %1174, %int5_1240 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1241 = torch.constant.int 1
    %int64_1242 = torch.constant.int 64
    %int768_1243 = torch.constant.int 768
    %1176 = torch.prim.ListConstruct %int1_1241, %int64_1242, %int768_1243 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1177 = torch.aten.view %1175, %1176 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1244 = torch.constant.int 1
    %int-1_1245 = torch.constant.int -1
    %int12_1246 = torch.constant.int 12
    %int64_1247 = torch.constant.int 64
    %1178 = torch.prim.ListConstruct %int1_1244, %int-1_1245, %int12_1246, %int64_1247 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1179 = torch.aten.view %1177, %1178 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1248 = torch.constant.int 1
    %int2_1249 = torch.constant.int 2
    %1180 = torch.aten.transpose.int %1179, %int1_1248, %int2_1249 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1250 = torch.constant.int 0
    %1181 = torch.aten.clone %1180, %int0_1250 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_1251 = torch.constant.int 64
    %int768_1252 = torch.constant.int 768
    %1182 = torch.prim.ListConstruct %int64_1251, %int768_1252 : (!torch.int, !torch.int) -> !torch.list<int>
    %1183 = torch.aten.view %1144, %1182 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.v_proj.weight : tensor<768x768xf16>
    %1184 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1253 = torch.constant.int 0
    %int1_1254 = torch.constant.int 1
    %1185 = torch.aten.transpose.int %1184, %int0_1253, %int1_1254 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.v_proj.bias : tensor<768xf16>
    %1186 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1255 = torch.constant.int 6
    %1187 = torch.prims.convert_element_type %1186, %int6_1255 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1256 = torch.constant.int 6
    %1188 = torch.prims.convert_element_type %1183, %int6_1256 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1257 = torch.constant.int 6
    %1189 = torch.prims.convert_element_type %1185, %int6_1257 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1190 = torch.aten.mm %1188, %1189 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1258 = torch.constant.int 1
    %1191 = torch.aten.mul.Scalar %1190, %int1_1258 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1259 = torch.constant.int 1
    %1192 = torch.aten.mul.Scalar %1187, %int1_1259 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1260 = torch.constant.int 1
    %1193 = torch.aten.add.Tensor %1191, %1192, %int1_1260 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1261 = torch.constant.int 5
    %1194 = torch.prims.convert_element_type %1193, %int5_1261 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1262 = torch.constant.int 1
    %int64_1263 = torch.constant.int 64
    %int768_1264 = torch.constant.int 768
    %1195 = torch.prim.ListConstruct %int1_1262, %int64_1263, %int768_1264 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1196 = torch.aten.view %1194, %1195 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1265 = torch.constant.int 1
    %int-1_1266 = torch.constant.int -1
    %int12_1267 = torch.constant.int 12
    %int64_1268 = torch.constant.int 64
    %1197 = torch.prim.ListConstruct %int1_1265, %int-1_1266, %int12_1267, %int64_1268 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1198 = torch.aten.view %1196, %1197 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1269 = torch.constant.int 1
    %int2_1270 = torch.constant.int 2
    %1199 = torch.aten.transpose.int %1198, %int1_1269, %int2_1270 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1271 = torch.constant.int 0
    %1200 = torch.aten.clone %1199, %int0_1271 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1272 = torch.constant.int 1
    %int64_1273 = torch.constant.int 64
    %int12_1274 = torch.constant.int 12
    %int64_1275 = torch.constant.int 64
    %1201 = torch.prim.ListConstruct %int1_1272, %int64_1273, %int12_1274, %int64_1275 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1202 = torch.aten.view %1162, %1201 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1276 = torch.constant.int 1
    %int2_1277 = torch.constant.int 2
    %1203 = torch.aten.transpose.int %1202, %int1_1276, %int2_1277 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1278 = torch.constant.int 0
    %1204 = torch.aten.clone %1203, %int0_1278 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1279 = torch.constant.int 12
    %int-1_1280 = torch.constant.int -1
    %int64_1281 = torch.constant.int 64
    %1205 = torch.prim.ListConstruct %int12_1279, %int-1_1280, %int64_1281 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1206 = torch.aten.view %1204, %1205 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1282 = torch.constant.int 12
    %int-1_1283 = torch.constant.int -1
    %int64_1284 = torch.constant.int 64
    %1207 = torch.prim.ListConstruct %int12_1282, %int-1_1283, %int64_1284 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1208 = torch.aten.view %1181, %1207 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1285 = torch.constant.int 12
    %int-1_1286 = torch.constant.int -1
    %int64_1287 = torch.constant.int 64
    %1209 = torch.prim.ListConstruct %int12_1285, %int-1_1286, %int64_1287 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1210 = torch.aten.view %1200, %1209 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_1288 = torch.constant.int 1
    %int2_1289 = torch.constant.int 2
    %1211 = torch.aten.transpose.int %1208, %int1_1288, %int2_1289 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %1212 = torch.aten.bmm %1206, %1211 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1290 = torch.constant.int 1
    %int12_1291 = torch.constant.int 12
    %int64_1292 = torch.constant.int 64
    %int64_1293 = torch.constant.int 64
    %1213 = torch.prim.ListConstruct %int1_1290, %int12_1291, %int64_1292, %int64_1293 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1214 = torch.aten.view %1212, %1213 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1294 = torch.constant.int 1
    %1215 = torch.aten.add.Tensor %1214, %27, %int1_1294 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1295 = torch.constant.int 12
    %int64_1296 = torch.constant.int 64
    %int64_1297 = torch.constant.int 64
    %1216 = torch.prim.ListConstruct %int12_1295, %int64_1296, %int64_1297 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1217 = torch.aten.view %1215, %1216 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_1298 = torch.constant.int -1
    %false_1299 = torch.constant.bool false
    %1218 = torch.aten._softmax %1217, %int-1_1298, %false_1299 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %1219 = torch.aten.detach %1218 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_1300 = torch.constant.none
    %1220 = torch.aten.clone %1218, %none_1300 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %1221 = torch.aten.bmm %1220, %1210 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1301 = torch.constant.int 1
    %int12_1302 = torch.constant.int 12
    %int64_1303 = torch.constant.int 64
    %int64_1304 = torch.constant.int 64
    %1222 = torch.prim.ListConstruct %int1_1301, %int12_1302, %int64_1303, %int64_1304 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1223 = torch.aten.view %1221, %1222 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1305 = torch.constant.int 1
    %int2_1306 = torch.constant.int 2
    %1224 = torch.aten.transpose.int %1223, %int1_1305, %int2_1306 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_1307 = torch.constant.int 0
    %1225 = torch.aten.clone %1224, %int0_1307 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1308 = torch.constant.int 1
    %int64_1309 = torch.constant.int 64
    %int768_1310 = torch.constant.int 768
    %1226 = torch.prim.ListConstruct %int1_1308, %int64_1309, %int768_1310 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1227 = torch.aten._unsafe_view %1225, %1226 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_1311 = torch.constant.int 64
    %int768_1312 = torch.constant.int 768
    %1228 = torch.prim.ListConstruct %int64_1311, %int768_1312 : (!torch.int, !torch.int) -> !torch.list<int>
    %1229 = torch.aten.view %1227, %1228 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.out_proj.weight : tensor<768x768xf16>
    %1230 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1313 = torch.constant.int 0
    %int1_1314 = torch.constant.int 1
    %1231 = torch.aten.transpose.int %1230, %int0_1313, %int1_1314 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.self_attn.out_proj.bias : tensor<768xf16>
    %1232 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1315 = torch.constant.int 6
    %1233 = torch.prims.convert_element_type %1232, %int6_1315 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1316 = torch.constant.int 6
    %1234 = torch.prims.convert_element_type %1229, %int6_1316 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1317 = torch.constant.int 6
    %1235 = torch.prims.convert_element_type %1231, %int6_1317 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1236 = torch.aten.mm %1234, %1235 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1318 = torch.constant.int 1
    %1237 = torch.aten.mul.Scalar %1236, %int1_1318 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1319 = torch.constant.int 1
    %1238 = torch.aten.mul.Scalar %1233, %int1_1319 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1320 = torch.constant.int 1
    %1239 = torch.aten.add.Tensor %1237, %1238, %int1_1320 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1321 = torch.constant.int 5
    %1240 = torch.prims.convert_element_type %1239, %int5_1321 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1322 = torch.constant.int 1
    %int64_1323 = torch.constant.int 64
    %int768_1324 = torch.constant.int 768
    %1241 = torch.prim.ListConstruct %int1_1322, %int64_1323, %int768_1324 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1242 = torch.aten.view %1240, %1241 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1325 = torch.constant.int 1
    %1243 = torch.aten.add.Tensor %1133, %1242, %int1_1325 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1326 = torch.constant.int 6
    %1244 = torch.prims.convert_element_type %1243, %int6_1326 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1327 = torch.constant.int 2
    %1245 = torch.prim.ListConstruct %int2_1327 : (!torch.int) -> !torch.list<int>
    %int0_1328 = torch.constant.int 0
    %true_1329 = torch.constant.bool true
    %result0_1330, %result1_1331 = torch.aten.var_mean.correction %1244, %1245, %int0_1328, %true_1329 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_1332 = torch.constant.float 1.000000e-05
    %int1_1333 = torch.constant.int 1
    %1246 = torch.aten.add.Scalar %result0_1330, %float1.000000e-05_1332, %int1_1333 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1247 = torch.aten.rsqrt %1246 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1334 = torch.constant.int 1
    %1248 = torch.aten.sub.Tensor %1243, %result1_1331, %int1_1334 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1249 = torch.aten.mul.Tensor %1248, %1247 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.7.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.layer_norm2.weight : tensor<768xf16>
    %1250 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1251 = torch.aten.mul.Tensor %1249, %1250 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.7.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.layer_norm2.bias : tensor<768xf16>
    %1252 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1335 = torch.constant.int 1
    %1253 = torch.aten.add.Tensor %1251, %1252, %int1_1335 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1336 = torch.constant.int 5
    %1254 = torch.prims.convert_element_type %1253, %int5_1336 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1337 = torch.constant.int 5
    %1255 = torch.prims.convert_element_type %result1_1331, %int5_1337 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1338 = torch.constant.int 5
    %1256 = torch.prims.convert_element_type %1247, %int5_1338 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1339 = torch.constant.int 64
    %int768_1340 = torch.constant.int 768
    %1257 = torch.prim.ListConstruct %int64_1339, %int768_1340 : (!torch.int, !torch.int) -> !torch.list<int>
    %1258 = torch.aten.view %1254, %1257 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc1.weight : tensor<3072x768xf16>
    %1259 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_1341 = torch.constant.int 0
    %int1_1342 = torch.constant.int 1
    %1260 = torch.aten.transpose.int %1259, %int0_1341, %int1_1342 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc1.bias : tensor<3072xf16>
    %1261 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_1343 = torch.constant.int 6
    %1262 = torch.prims.convert_element_type %1261, %int6_1343 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_1344 = torch.constant.int 6
    %1263 = torch.prims.convert_element_type %1258, %int6_1344 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1345 = torch.constant.int 6
    %1264 = torch.prims.convert_element_type %1260, %int6_1345 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %1265 = torch.aten.mm %1263, %1264 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_1346 = torch.constant.int 1
    %1266 = torch.aten.mul.Scalar %1265, %int1_1346 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_1347 = torch.constant.int 1
    %1267 = torch.aten.mul.Scalar %1262, %int1_1347 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_1348 = torch.constant.int 1
    %1268 = torch.aten.add.Tensor %1266, %1267, %int1_1348 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_1349 = torch.constant.int 5
    %1269 = torch.prims.convert_element_type %1268, %int5_1349 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_1350 = torch.constant.int 1
    %int64_1351 = torch.constant.int 64
    %int3072_1352 = torch.constant.int 3072
    %1270 = torch.prim.ListConstruct %int1_1350, %int64_1351, %int3072_1352 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1271 = torch.aten.view %1269, %1270 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00_1353 = torch.constant.float 1.702000e+00
    %1272 = torch.aten.mul.Scalar %1271, %float1.702000e00_1353 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %1273 = torch.aten.sigmoid %1272 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1274 = torch.aten.detach %1273 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1275 = torch.aten.mul.Tensor %1271, %1273 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_1354 = torch.constant.int 64
    %int3072_1355 = torch.constant.int 3072
    %1276 = torch.prim.ListConstruct %int64_1354, %int3072_1355 : (!torch.int, !torch.int) -> !torch.list<int>
    %1277 = torch.aten.view %1275, %1276 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc2.weight : tensor<768x3072xf16>
    %1278 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_1356 = torch.constant.int 0
    %int1_1357 = torch.constant.int 1
    %1279 = torch.aten.transpose.int %1278, %int0_1356, %int1_1357 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc2.bias : tensor<768xf16>
    %1280 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.7.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1358 = torch.constant.int 6
    %1281 = torch.prims.convert_element_type %1280, %int6_1358 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1359 = torch.constant.int 6
    %1282 = torch.prims.convert_element_type %1277, %int6_1359 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_1360 = torch.constant.int 6
    %1283 = torch.prims.convert_element_type %1279, %int6_1360 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %1284 = torch.aten.mm %1282, %1283 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1361 = torch.constant.int 1
    %1285 = torch.aten.mul.Scalar %1284, %int1_1361 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1362 = torch.constant.int 1
    %1286 = torch.aten.mul.Scalar %1281, %int1_1362 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1363 = torch.constant.int 1
    %1287 = torch.aten.add.Tensor %1285, %1286, %int1_1363 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1364 = torch.constant.int 5
    %1288 = torch.prims.convert_element_type %1287, %int5_1364 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1365 = torch.constant.int 1
    %int64_1366 = torch.constant.int 64
    %int768_1367 = torch.constant.int 768
    %1289 = torch.prim.ListConstruct %int1_1365, %int64_1366, %int768_1367 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1290 = torch.aten.view %1288, %1289 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1368 = torch.constant.int 1
    %1291 = torch.aten.add.Tensor %1243, %1290, %int1_1368 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1369 = torch.constant.int 6
    %1292 = torch.prims.convert_element_type %1291, %int6_1369 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1370 = torch.constant.int 2
    %1293 = torch.prim.ListConstruct %int2_1370 : (!torch.int) -> !torch.list<int>
    %int0_1371 = torch.constant.int 0
    %true_1372 = torch.constant.bool true
    %result0_1373, %result1_1374 = torch.aten.var_mean.correction %1292, %1293, %int0_1371, %true_1372 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_1375 = torch.constant.float 1.000000e-05
    %int1_1376 = torch.constant.int 1
    %1294 = torch.aten.add.Scalar %result0_1373, %float1.000000e-05_1375, %int1_1376 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1295 = torch.aten.rsqrt %1294 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1377 = torch.constant.int 1
    %1296 = torch.aten.sub.Tensor %1291, %result1_1374, %int1_1377 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1297 = torch.aten.mul.Tensor %1296, %1295 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.8.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.layer_norm1.weight : tensor<768xf16>
    %1298 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1299 = torch.aten.mul.Tensor %1297, %1298 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.8.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.layer_norm1.bias : tensor<768xf16>
    %1300 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1378 = torch.constant.int 1
    %1301 = torch.aten.add.Tensor %1299, %1300, %int1_1378 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1379 = torch.constant.int 5
    %1302 = torch.prims.convert_element_type %1301, %int5_1379 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1380 = torch.constant.int 5
    %1303 = torch.prims.convert_element_type %result1_1374, %int5_1380 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1381 = torch.constant.int 5
    %1304 = torch.prims.convert_element_type %1295, %int5_1381 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1382 = torch.constant.int 64
    %int768_1383 = torch.constant.int 768
    %1305 = torch.prim.ListConstruct %int64_1382, %int768_1383 : (!torch.int, !torch.int) -> !torch.list<int>
    %1306 = torch.aten.view %1302, %1305 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.q_proj.weight : tensor<768x768xf16>
    %1307 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1384 = torch.constant.int 0
    %int1_1385 = torch.constant.int 1
    %1308 = torch.aten.transpose.int %1307, %int0_1384, %int1_1385 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.q_proj.bias : tensor<768xf16>
    %1309 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1386 = torch.constant.int 6
    %1310 = torch.prims.convert_element_type %1309, %int6_1386 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1387 = torch.constant.int 6
    %1311 = torch.prims.convert_element_type %1306, %int6_1387 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1388 = torch.constant.int 6
    %1312 = torch.prims.convert_element_type %1308, %int6_1388 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1313 = torch.aten.mm %1311, %1312 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1389 = torch.constant.int 1
    %1314 = torch.aten.mul.Scalar %1313, %int1_1389 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1390 = torch.constant.int 1
    %1315 = torch.aten.mul.Scalar %1310, %int1_1390 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1391 = torch.constant.int 1
    %1316 = torch.aten.add.Tensor %1314, %1315, %int1_1391 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1392 = torch.constant.int 5
    %1317 = torch.prims.convert_element_type %1316, %int5_1392 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1393 = torch.constant.int 1
    %int64_1394 = torch.constant.int 64
    %int768_1395 = torch.constant.int 768
    %1318 = torch.prim.ListConstruct %int1_1393, %int64_1394, %int768_1395 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1319 = torch.aten.view %1317, %1318 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01_1396 = torch.constant.float 1.250000e-01
    %1320 = torch.aten.mul.Scalar %1319, %float1.250000e-01_1396 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_1397 = torch.constant.int 64
    %int768_1398 = torch.constant.int 768
    %1321 = torch.prim.ListConstruct %int64_1397, %int768_1398 : (!torch.int, !torch.int) -> !torch.list<int>
    %1322 = torch.aten.view %1302, %1321 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.k_proj.weight : tensor<768x768xf16>
    %1323 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1399 = torch.constant.int 0
    %int1_1400 = torch.constant.int 1
    %1324 = torch.aten.transpose.int %1323, %int0_1399, %int1_1400 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.k_proj.bias : tensor<768xf16>
    %1325 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1401 = torch.constant.int 6
    %1326 = torch.prims.convert_element_type %1325, %int6_1401 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1402 = torch.constant.int 6
    %1327 = torch.prims.convert_element_type %1322, %int6_1402 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1403 = torch.constant.int 6
    %1328 = torch.prims.convert_element_type %1324, %int6_1403 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1329 = torch.aten.mm %1327, %1328 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1404 = torch.constant.int 1
    %1330 = torch.aten.mul.Scalar %1329, %int1_1404 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1405 = torch.constant.int 1
    %1331 = torch.aten.mul.Scalar %1326, %int1_1405 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1406 = torch.constant.int 1
    %1332 = torch.aten.add.Tensor %1330, %1331, %int1_1406 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1407 = torch.constant.int 5
    %1333 = torch.prims.convert_element_type %1332, %int5_1407 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1408 = torch.constant.int 1
    %int64_1409 = torch.constant.int 64
    %int768_1410 = torch.constant.int 768
    %1334 = torch.prim.ListConstruct %int1_1408, %int64_1409, %int768_1410 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1335 = torch.aten.view %1333, %1334 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1411 = torch.constant.int 1
    %int-1_1412 = torch.constant.int -1
    %int12_1413 = torch.constant.int 12
    %int64_1414 = torch.constant.int 64
    %1336 = torch.prim.ListConstruct %int1_1411, %int-1_1412, %int12_1413, %int64_1414 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1337 = torch.aten.view %1335, %1336 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1415 = torch.constant.int 1
    %int2_1416 = torch.constant.int 2
    %1338 = torch.aten.transpose.int %1337, %int1_1415, %int2_1416 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1417 = torch.constant.int 0
    %1339 = torch.aten.clone %1338, %int0_1417 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_1418 = torch.constant.int 64
    %int768_1419 = torch.constant.int 768
    %1340 = torch.prim.ListConstruct %int64_1418, %int768_1419 : (!torch.int, !torch.int) -> !torch.list<int>
    %1341 = torch.aten.view %1302, %1340 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.v_proj.weight : tensor<768x768xf16>
    %1342 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1420 = torch.constant.int 0
    %int1_1421 = torch.constant.int 1
    %1343 = torch.aten.transpose.int %1342, %int0_1420, %int1_1421 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.v_proj.bias : tensor<768xf16>
    %1344 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1422 = torch.constant.int 6
    %1345 = torch.prims.convert_element_type %1344, %int6_1422 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1423 = torch.constant.int 6
    %1346 = torch.prims.convert_element_type %1341, %int6_1423 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1424 = torch.constant.int 6
    %1347 = torch.prims.convert_element_type %1343, %int6_1424 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1348 = torch.aten.mm %1346, %1347 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1425 = torch.constant.int 1
    %1349 = torch.aten.mul.Scalar %1348, %int1_1425 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1426 = torch.constant.int 1
    %1350 = torch.aten.mul.Scalar %1345, %int1_1426 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1427 = torch.constant.int 1
    %1351 = torch.aten.add.Tensor %1349, %1350, %int1_1427 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1428 = torch.constant.int 5
    %1352 = torch.prims.convert_element_type %1351, %int5_1428 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1429 = torch.constant.int 1
    %int64_1430 = torch.constant.int 64
    %int768_1431 = torch.constant.int 768
    %1353 = torch.prim.ListConstruct %int1_1429, %int64_1430, %int768_1431 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1354 = torch.aten.view %1352, %1353 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1432 = torch.constant.int 1
    %int-1_1433 = torch.constant.int -1
    %int12_1434 = torch.constant.int 12
    %int64_1435 = torch.constant.int 64
    %1355 = torch.prim.ListConstruct %int1_1432, %int-1_1433, %int12_1434, %int64_1435 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1356 = torch.aten.view %1354, %1355 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1436 = torch.constant.int 1
    %int2_1437 = torch.constant.int 2
    %1357 = torch.aten.transpose.int %1356, %int1_1436, %int2_1437 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1438 = torch.constant.int 0
    %1358 = torch.aten.clone %1357, %int0_1438 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1439 = torch.constant.int 1
    %int64_1440 = torch.constant.int 64
    %int12_1441 = torch.constant.int 12
    %int64_1442 = torch.constant.int 64
    %1359 = torch.prim.ListConstruct %int1_1439, %int64_1440, %int12_1441, %int64_1442 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1360 = torch.aten.view %1320, %1359 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1443 = torch.constant.int 1
    %int2_1444 = torch.constant.int 2
    %1361 = torch.aten.transpose.int %1360, %int1_1443, %int2_1444 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1445 = torch.constant.int 0
    %1362 = torch.aten.clone %1361, %int0_1445 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1446 = torch.constant.int 12
    %int-1_1447 = torch.constant.int -1
    %int64_1448 = torch.constant.int 64
    %1363 = torch.prim.ListConstruct %int12_1446, %int-1_1447, %int64_1448 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1364 = torch.aten.view %1362, %1363 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1449 = torch.constant.int 12
    %int-1_1450 = torch.constant.int -1
    %int64_1451 = torch.constant.int 64
    %1365 = torch.prim.ListConstruct %int12_1449, %int-1_1450, %int64_1451 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1366 = torch.aten.view %1339, %1365 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1452 = torch.constant.int 12
    %int-1_1453 = torch.constant.int -1
    %int64_1454 = torch.constant.int 64
    %1367 = torch.prim.ListConstruct %int12_1452, %int-1_1453, %int64_1454 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1368 = torch.aten.view %1358, %1367 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_1455 = torch.constant.int 1
    %int2_1456 = torch.constant.int 2
    %1369 = torch.aten.transpose.int %1366, %int1_1455, %int2_1456 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %1370 = torch.aten.bmm %1364, %1369 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1457 = torch.constant.int 1
    %int12_1458 = torch.constant.int 12
    %int64_1459 = torch.constant.int 64
    %int64_1460 = torch.constant.int 64
    %1371 = torch.prim.ListConstruct %int1_1457, %int12_1458, %int64_1459, %int64_1460 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1372 = torch.aten.view %1370, %1371 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1461 = torch.constant.int 1
    %1373 = torch.aten.add.Tensor %1372, %27, %int1_1461 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1462 = torch.constant.int 12
    %int64_1463 = torch.constant.int 64
    %int64_1464 = torch.constant.int 64
    %1374 = torch.prim.ListConstruct %int12_1462, %int64_1463, %int64_1464 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1375 = torch.aten.view %1373, %1374 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_1465 = torch.constant.int -1
    %false_1466 = torch.constant.bool false
    %1376 = torch.aten._softmax %1375, %int-1_1465, %false_1466 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %1377 = torch.aten.detach %1376 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_1467 = torch.constant.none
    %1378 = torch.aten.clone %1376, %none_1467 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %1379 = torch.aten.bmm %1378, %1368 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1468 = torch.constant.int 1
    %int12_1469 = torch.constant.int 12
    %int64_1470 = torch.constant.int 64
    %int64_1471 = torch.constant.int 64
    %1380 = torch.prim.ListConstruct %int1_1468, %int12_1469, %int64_1470, %int64_1471 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1381 = torch.aten.view %1379, %1380 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1472 = torch.constant.int 1
    %int2_1473 = torch.constant.int 2
    %1382 = torch.aten.transpose.int %1381, %int1_1472, %int2_1473 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_1474 = torch.constant.int 0
    %1383 = torch.aten.clone %1382, %int0_1474 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1475 = torch.constant.int 1
    %int64_1476 = torch.constant.int 64
    %int768_1477 = torch.constant.int 768
    %1384 = torch.prim.ListConstruct %int1_1475, %int64_1476, %int768_1477 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1385 = torch.aten._unsafe_view %1383, %1384 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_1478 = torch.constant.int 64
    %int768_1479 = torch.constant.int 768
    %1386 = torch.prim.ListConstruct %int64_1478, %int768_1479 : (!torch.int, !torch.int) -> !torch.list<int>
    %1387 = torch.aten.view %1385, %1386 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.out_proj.weight : tensor<768x768xf16>
    %1388 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1480 = torch.constant.int 0
    %int1_1481 = torch.constant.int 1
    %1389 = torch.aten.transpose.int %1388, %int0_1480, %int1_1481 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.self_attn.out_proj.bias : tensor<768xf16>
    %1390 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1482 = torch.constant.int 6
    %1391 = torch.prims.convert_element_type %1390, %int6_1482 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1483 = torch.constant.int 6
    %1392 = torch.prims.convert_element_type %1387, %int6_1483 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1484 = torch.constant.int 6
    %1393 = torch.prims.convert_element_type %1389, %int6_1484 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1394 = torch.aten.mm %1392, %1393 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1485 = torch.constant.int 1
    %1395 = torch.aten.mul.Scalar %1394, %int1_1485 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1486 = torch.constant.int 1
    %1396 = torch.aten.mul.Scalar %1391, %int1_1486 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1487 = torch.constant.int 1
    %1397 = torch.aten.add.Tensor %1395, %1396, %int1_1487 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1488 = torch.constant.int 5
    %1398 = torch.prims.convert_element_type %1397, %int5_1488 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1489 = torch.constant.int 1
    %int64_1490 = torch.constant.int 64
    %int768_1491 = torch.constant.int 768
    %1399 = torch.prim.ListConstruct %int1_1489, %int64_1490, %int768_1491 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1400 = torch.aten.view %1398, %1399 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1492 = torch.constant.int 1
    %1401 = torch.aten.add.Tensor %1291, %1400, %int1_1492 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1493 = torch.constant.int 6
    %1402 = torch.prims.convert_element_type %1401, %int6_1493 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1494 = torch.constant.int 2
    %1403 = torch.prim.ListConstruct %int2_1494 : (!torch.int) -> !torch.list<int>
    %int0_1495 = torch.constant.int 0
    %true_1496 = torch.constant.bool true
    %result0_1497, %result1_1498 = torch.aten.var_mean.correction %1402, %1403, %int0_1495, %true_1496 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_1499 = torch.constant.float 1.000000e-05
    %int1_1500 = torch.constant.int 1
    %1404 = torch.aten.add.Scalar %result0_1497, %float1.000000e-05_1499, %int1_1500 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1405 = torch.aten.rsqrt %1404 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1501 = torch.constant.int 1
    %1406 = torch.aten.sub.Tensor %1401, %result1_1498, %int1_1501 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1407 = torch.aten.mul.Tensor %1406, %1405 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.8.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.layer_norm2.weight : tensor<768xf16>
    %1408 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1409 = torch.aten.mul.Tensor %1407, %1408 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.8.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.layer_norm2.bias : tensor<768xf16>
    %1410 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1502 = torch.constant.int 1
    %1411 = torch.aten.add.Tensor %1409, %1410, %int1_1502 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1503 = torch.constant.int 5
    %1412 = torch.prims.convert_element_type %1411, %int5_1503 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1504 = torch.constant.int 5
    %1413 = torch.prims.convert_element_type %result1_1498, %int5_1504 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1505 = torch.constant.int 5
    %1414 = torch.prims.convert_element_type %1405, %int5_1505 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1506 = torch.constant.int 64
    %int768_1507 = torch.constant.int 768
    %1415 = torch.prim.ListConstruct %int64_1506, %int768_1507 : (!torch.int, !torch.int) -> !torch.list<int>
    %1416 = torch.aten.view %1412, %1415 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc1.weight : tensor<3072x768xf16>
    %1417 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_1508 = torch.constant.int 0
    %int1_1509 = torch.constant.int 1
    %1418 = torch.aten.transpose.int %1417, %int0_1508, %int1_1509 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc1.bias : tensor<3072xf16>
    %1419 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_1510 = torch.constant.int 6
    %1420 = torch.prims.convert_element_type %1419, %int6_1510 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_1511 = torch.constant.int 6
    %1421 = torch.prims.convert_element_type %1416, %int6_1511 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1512 = torch.constant.int 6
    %1422 = torch.prims.convert_element_type %1418, %int6_1512 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %1423 = torch.aten.mm %1421, %1422 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_1513 = torch.constant.int 1
    %1424 = torch.aten.mul.Scalar %1423, %int1_1513 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_1514 = torch.constant.int 1
    %1425 = torch.aten.mul.Scalar %1420, %int1_1514 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_1515 = torch.constant.int 1
    %1426 = torch.aten.add.Tensor %1424, %1425, %int1_1515 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_1516 = torch.constant.int 5
    %1427 = torch.prims.convert_element_type %1426, %int5_1516 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_1517 = torch.constant.int 1
    %int64_1518 = torch.constant.int 64
    %int3072_1519 = torch.constant.int 3072
    %1428 = torch.prim.ListConstruct %int1_1517, %int64_1518, %int3072_1519 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1429 = torch.aten.view %1427, %1428 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00_1520 = torch.constant.float 1.702000e+00
    %1430 = torch.aten.mul.Scalar %1429, %float1.702000e00_1520 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %1431 = torch.aten.sigmoid %1430 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1432 = torch.aten.detach %1431 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1433 = torch.aten.mul.Tensor %1429, %1431 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_1521 = torch.constant.int 64
    %int3072_1522 = torch.constant.int 3072
    %1434 = torch.prim.ListConstruct %int64_1521, %int3072_1522 : (!torch.int, !torch.int) -> !torch.list<int>
    %1435 = torch.aten.view %1433, %1434 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc2.weight : tensor<768x3072xf16>
    %1436 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_1523 = torch.constant.int 0
    %int1_1524 = torch.constant.int 1
    %1437 = torch.aten.transpose.int %1436, %int0_1523, %int1_1524 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc2.bias : tensor<768xf16>
    %1438 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.8.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1525 = torch.constant.int 6
    %1439 = torch.prims.convert_element_type %1438, %int6_1525 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1526 = torch.constant.int 6
    %1440 = torch.prims.convert_element_type %1435, %int6_1526 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_1527 = torch.constant.int 6
    %1441 = torch.prims.convert_element_type %1437, %int6_1527 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %1442 = torch.aten.mm %1440, %1441 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1528 = torch.constant.int 1
    %1443 = torch.aten.mul.Scalar %1442, %int1_1528 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1529 = torch.constant.int 1
    %1444 = torch.aten.mul.Scalar %1439, %int1_1529 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1530 = torch.constant.int 1
    %1445 = torch.aten.add.Tensor %1443, %1444, %int1_1530 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1531 = torch.constant.int 5
    %1446 = torch.prims.convert_element_type %1445, %int5_1531 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1532 = torch.constant.int 1
    %int64_1533 = torch.constant.int 64
    %int768_1534 = torch.constant.int 768
    %1447 = torch.prim.ListConstruct %int1_1532, %int64_1533, %int768_1534 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1448 = torch.aten.view %1446, %1447 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1535 = torch.constant.int 1
    %1449 = torch.aten.add.Tensor %1401, %1448, %int1_1535 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1536 = torch.constant.int 6
    %1450 = torch.prims.convert_element_type %1449, %int6_1536 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1537 = torch.constant.int 2
    %1451 = torch.prim.ListConstruct %int2_1537 : (!torch.int) -> !torch.list<int>
    %int0_1538 = torch.constant.int 0
    %true_1539 = torch.constant.bool true
    %result0_1540, %result1_1541 = torch.aten.var_mean.correction %1450, %1451, %int0_1538, %true_1539 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_1542 = torch.constant.float 1.000000e-05
    %int1_1543 = torch.constant.int 1
    %1452 = torch.aten.add.Scalar %result0_1540, %float1.000000e-05_1542, %int1_1543 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1453 = torch.aten.rsqrt %1452 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1544 = torch.constant.int 1
    %1454 = torch.aten.sub.Tensor %1449, %result1_1541, %int1_1544 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1455 = torch.aten.mul.Tensor %1454, %1453 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.9.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.layer_norm1.weight : tensor<768xf16>
    %1456 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1457 = torch.aten.mul.Tensor %1455, %1456 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.9.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.layer_norm1.bias : tensor<768xf16>
    %1458 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1545 = torch.constant.int 1
    %1459 = torch.aten.add.Tensor %1457, %1458, %int1_1545 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1546 = torch.constant.int 5
    %1460 = torch.prims.convert_element_type %1459, %int5_1546 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1547 = torch.constant.int 5
    %1461 = torch.prims.convert_element_type %result1_1541, %int5_1547 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1548 = torch.constant.int 5
    %1462 = torch.prims.convert_element_type %1453, %int5_1548 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1549 = torch.constant.int 64
    %int768_1550 = torch.constant.int 768
    %1463 = torch.prim.ListConstruct %int64_1549, %int768_1550 : (!torch.int, !torch.int) -> !torch.list<int>
    %1464 = torch.aten.view %1460, %1463 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.q_proj.weight : tensor<768x768xf16>
    %1465 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1551 = torch.constant.int 0
    %int1_1552 = torch.constant.int 1
    %1466 = torch.aten.transpose.int %1465, %int0_1551, %int1_1552 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.q_proj.bias : tensor<768xf16>
    %1467 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1553 = torch.constant.int 6
    %1468 = torch.prims.convert_element_type %1467, %int6_1553 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1554 = torch.constant.int 6
    %1469 = torch.prims.convert_element_type %1464, %int6_1554 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1555 = torch.constant.int 6
    %1470 = torch.prims.convert_element_type %1466, %int6_1555 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1471 = torch.aten.mm %1469, %1470 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1556 = torch.constant.int 1
    %1472 = torch.aten.mul.Scalar %1471, %int1_1556 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1557 = torch.constant.int 1
    %1473 = torch.aten.mul.Scalar %1468, %int1_1557 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1558 = torch.constant.int 1
    %1474 = torch.aten.add.Tensor %1472, %1473, %int1_1558 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1559 = torch.constant.int 5
    %1475 = torch.prims.convert_element_type %1474, %int5_1559 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1560 = torch.constant.int 1
    %int64_1561 = torch.constant.int 64
    %int768_1562 = torch.constant.int 768
    %1476 = torch.prim.ListConstruct %int1_1560, %int64_1561, %int768_1562 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1477 = torch.aten.view %1475, %1476 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01_1563 = torch.constant.float 1.250000e-01
    %1478 = torch.aten.mul.Scalar %1477, %float1.250000e-01_1563 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_1564 = torch.constant.int 64
    %int768_1565 = torch.constant.int 768
    %1479 = torch.prim.ListConstruct %int64_1564, %int768_1565 : (!torch.int, !torch.int) -> !torch.list<int>
    %1480 = torch.aten.view %1460, %1479 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.k_proj.weight : tensor<768x768xf16>
    %1481 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1566 = torch.constant.int 0
    %int1_1567 = torch.constant.int 1
    %1482 = torch.aten.transpose.int %1481, %int0_1566, %int1_1567 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.k_proj.bias : tensor<768xf16>
    %1483 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1568 = torch.constant.int 6
    %1484 = torch.prims.convert_element_type %1483, %int6_1568 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1569 = torch.constant.int 6
    %1485 = torch.prims.convert_element_type %1480, %int6_1569 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1570 = torch.constant.int 6
    %1486 = torch.prims.convert_element_type %1482, %int6_1570 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1487 = torch.aten.mm %1485, %1486 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1571 = torch.constant.int 1
    %1488 = torch.aten.mul.Scalar %1487, %int1_1571 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1572 = torch.constant.int 1
    %1489 = torch.aten.mul.Scalar %1484, %int1_1572 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1573 = torch.constant.int 1
    %1490 = torch.aten.add.Tensor %1488, %1489, %int1_1573 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1574 = torch.constant.int 5
    %1491 = torch.prims.convert_element_type %1490, %int5_1574 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1575 = torch.constant.int 1
    %int64_1576 = torch.constant.int 64
    %int768_1577 = torch.constant.int 768
    %1492 = torch.prim.ListConstruct %int1_1575, %int64_1576, %int768_1577 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1493 = torch.aten.view %1491, %1492 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1578 = torch.constant.int 1
    %int-1_1579 = torch.constant.int -1
    %int12_1580 = torch.constant.int 12
    %int64_1581 = torch.constant.int 64
    %1494 = torch.prim.ListConstruct %int1_1578, %int-1_1579, %int12_1580, %int64_1581 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1495 = torch.aten.view %1493, %1494 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1582 = torch.constant.int 1
    %int2_1583 = torch.constant.int 2
    %1496 = torch.aten.transpose.int %1495, %int1_1582, %int2_1583 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1584 = torch.constant.int 0
    %1497 = torch.aten.clone %1496, %int0_1584 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_1585 = torch.constant.int 64
    %int768_1586 = torch.constant.int 768
    %1498 = torch.prim.ListConstruct %int64_1585, %int768_1586 : (!torch.int, !torch.int) -> !torch.list<int>
    %1499 = torch.aten.view %1460, %1498 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.v_proj.weight : tensor<768x768xf16>
    %1500 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1587 = torch.constant.int 0
    %int1_1588 = torch.constant.int 1
    %1501 = torch.aten.transpose.int %1500, %int0_1587, %int1_1588 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.v_proj.bias : tensor<768xf16>
    %1502 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1589 = torch.constant.int 6
    %1503 = torch.prims.convert_element_type %1502, %int6_1589 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1590 = torch.constant.int 6
    %1504 = torch.prims.convert_element_type %1499, %int6_1590 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1591 = torch.constant.int 6
    %1505 = torch.prims.convert_element_type %1501, %int6_1591 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1506 = torch.aten.mm %1504, %1505 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1592 = torch.constant.int 1
    %1507 = torch.aten.mul.Scalar %1506, %int1_1592 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1593 = torch.constant.int 1
    %1508 = torch.aten.mul.Scalar %1503, %int1_1593 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1594 = torch.constant.int 1
    %1509 = torch.aten.add.Tensor %1507, %1508, %int1_1594 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1595 = torch.constant.int 5
    %1510 = torch.prims.convert_element_type %1509, %int5_1595 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1596 = torch.constant.int 1
    %int64_1597 = torch.constant.int 64
    %int768_1598 = torch.constant.int 768
    %1511 = torch.prim.ListConstruct %int1_1596, %int64_1597, %int768_1598 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1512 = torch.aten.view %1510, %1511 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1599 = torch.constant.int 1
    %int-1_1600 = torch.constant.int -1
    %int12_1601 = torch.constant.int 12
    %int64_1602 = torch.constant.int 64
    %1513 = torch.prim.ListConstruct %int1_1599, %int-1_1600, %int12_1601, %int64_1602 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1514 = torch.aten.view %1512, %1513 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1603 = torch.constant.int 1
    %int2_1604 = torch.constant.int 2
    %1515 = torch.aten.transpose.int %1514, %int1_1603, %int2_1604 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1605 = torch.constant.int 0
    %1516 = torch.aten.clone %1515, %int0_1605 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1606 = torch.constant.int 1
    %int64_1607 = torch.constant.int 64
    %int12_1608 = torch.constant.int 12
    %int64_1609 = torch.constant.int 64
    %1517 = torch.prim.ListConstruct %int1_1606, %int64_1607, %int12_1608, %int64_1609 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1518 = torch.aten.view %1478, %1517 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1610 = torch.constant.int 1
    %int2_1611 = torch.constant.int 2
    %1519 = torch.aten.transpose.int %1518, %int1_1610, %int2_1611 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1612 = torch.constant.int 0
    %1520 = torch.aten.clone %1519, %int0_1612 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1613 = torch.constant.int 12
    %int-1_1614 = torch.constant.int -1
    %int64_1615 = torch.constant.int 64
    %1521 = torch.prim.ListConstruct %int12_1613, %int-1_1614, %int64_1615 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1522 = torch.aten.view %1520, %1521 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1616 = torch.constant.int 12
    %int-1_1617 = torch.constant.int -1
    %int64_1618 = torch.constant.int 64
    %1523 = torch.prim.ListConstruct %int12_1616, %int-1_1617, %int64_1618 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1524 = torch.aten.view %1497, %1523 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1619 = torch.constant.int 12
    %int-1_1620 = torch.constant.int -1
    %int64_1621 = torch.constant.int 64
    %1525 = torch.prim.ListConstruct %int12_1619, %int-1_1620, %int64_1621 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1526 = torch.aten.view %1516, %1525 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_1622 = torch.constant.int 1
    %int2_1623 = torch.constant.int 2
    %1527 = torch.aten.transpose.int %1524, %int1_1622, %int2_1623 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %1528 = torch.aten.bmm %1522, %1527 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1624 = torch.constant.int 1
    %int12_1625 = torch.constant.int 12
    %int64_1626 = torch.constant.int 64
    %int64_1627 = torch.constant.int 64
    %1529 = torch.prim.ListConstruct %int1_1624, %int12_1625, %int64_1626, %int64_1627 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1530 = torch.aten.view %1528, %1529 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1628 = torch.constant.int 1
    %1531 = torch.aten.add.Tensor %1530, %27, %int1_1628 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1629 = torch.constant.int 12
    %int64_1630 = torch.constant.int 64
    %int64_1631 = torch.constant.int 64
    %1532 = torch.prim.ListConstruct %int12_1629, %int64_1630, %int64_1631 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1533 = torch.aten.view %1531, %1532 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_1632 = torch.constant.int -1
    %false_1633 = torch.constant.bool false
    %1534 = torch.aten._softmax %1533, %int-1_1632, %false_1633 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %1535 = torch.aten.detach %1534 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_1634 = torch.constant.none
    %1536 = torch.aten.clone %1534, %none_1634 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %1537 = torch.aten.bmm %1536, %1526 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1635 = torch.constant.int 1
    %int12_1636 = torch.constant.int 12
    %int64_1637 = torch.constant.int 64
    %int64_1638 = torch.constant.int 64
    %1538 = torch.prim.ListConstruct %int1_1635, %int12_1636, %int64_1637, %int64_1638 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1539 = torch.aten.view %1537, %1538 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1639 = torch.constant.int 1
    %int2_1640 = torch.constant.int 2
    %1540 = torch.aten.transpose.int %1539, %int1_1639, %int2_1640 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_1641 = torch.constant.int 0
    %1541 = torch.aten.clone %1540, %int0_1641 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1642 = torch.constant.int 1
    %int64_1643 = torch.constant.int 64
    %int768_1644 = torch.constant.int 768
    %1542 = torch.prim.ListConstruct %int1_1642, %int64_1643, %int768_1644 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1543 = torch.aten._unsafe_view %1541, %1542 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_1645 = torch.constant.int 64
    %int768_1646 = torch.constant.int 768
    %1544 = torch.prim.ListConstruct %int64_1645, %int768_1646 : (!torch.int, !torch.int) -> !torch.list<int>
    %1545 = torch.aten.view %1543, %1544 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.out_proj.weight : tensor<768x768xf16>
    %1546 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1647 = torch.constant.int 0
    %int1_1648 = torch.constant.int 1
    %1547 = torch.aten.transpose.int %1546, %int0_1647, %int1_1648 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.self_attn.out_proj.bias : tensor<768xf16>
    %1548 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1649 = torch.constant.int 6
    %1549 = torch.prims.convert_element_type %1548, %int6_1649 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1650 = torch.constant.int 6
    %1550 = torch.prims.convert_element_type %1545, %int6_1650 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1651 = torch.constant.int 6
    %1551 = torch.prims.convert_element_type %1547, %int6_1651 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1552 = torch.aten.mm %1550, %1551 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1652 = torch.constant.int 1
    %1553 = torch.aten.mul.Scalar %1552, %int1_1652 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1653 = torch.constant.int 1
    %1554 = torch.aten.mul.Scalar %1549, %int1_1653 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1654 = torch.constant.int 1
    %1555 = torch.aten.add.Tensor %1553, %1554, %int1_1654 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1655 = torch.constant.int 5
    %1556 = torch.prims.convert_element_type %1555, %int5_1655 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1656 = torch.constant.int 1
    %int64_1657 = torch.constant.int 64
    %int768_1658 = torch.constant.int 768
    %1557 = torch.prim.ListConstruct %int1_1656, %int64_1657, %int768_1658 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1558 = torch.aten.view %1556, %1557 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1659 = torch.constant.int 1
    %1559 = torch.aten.add.Tensor %1449, %1558, %int1_1659 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1660 = torch.constant.int 6
    %1560 = torch.prims.convert_element_type %1559, %int6_1660 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1661 = torch.constant.int 2
    %1561 = torch.prim.ListConstruct %int2_1661 : (!torch.int) -> !torch.list<int>
    %int0_1662 = torch.constant.int 0
    %true_1663 = torch.constant.bool true
    %result0_1664, %result1_1665 = torch.aten.var_mean.correction %1560, %1561, %int0_1662, %true_1663 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_1666 = torch.constant.float 1.000000e-05
    %int1_1667 = torch.constant.int 1
    %1562 = torch.aten.add.Scalar %result0_1664, %float1.000000e-05_1666, %int1_1667 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1563 = torch.aten.rsqrt %1562 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1668 = torch.constant.int 1
    %1564 = torch.aten.sub.Tensor %1559, %result1_1665, %int1_1668 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1565 = torch.aten.mul.Tensor %1564, %1563 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.9.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.layer_norm2.weight : tensor<768xf16>
    %1566 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1567 = torch.aten.mul.Tensor %1565, %1566 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.9.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.layer_norm2.bias : tensor<768xf16>
    %1568 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1669 = torch.constant.int 1
    %1569 = torch.aten.add.Tensor %1567, %1568, %int1_1669 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1670 = torch.constant.int 5
    %1570 = torch.prims.convert_element_type %1569, %int5_1670 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1671 = torch.constant.int 5
    %1571 = torch.prims.convert_element_type %result1_1665, %int5_1671 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1672 = torch.constant.int 5
    %1572 = torch.prims.convert_element_type %1563, %int5_1672 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1673 = torch.constant.int 64
    %int768_1674 = torch.constant.int 768
    %1573 = torch.prim.ListConstruct %int64_1673, %int768_1674 : (!torch.int, !torch.int) -> !torch.list<int>
    %1574 = torch.aten.view %1570, %1573 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc1.weight : tensor<3072x768xf16>
    %1575 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_1675 = torch.constant.int 0
    %int1_1676 = torch.constant.int 1
    %1576 = torch.aten.transpose.int %1575, %int0_1675, %int1_1676 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc1.bias : tensor<3072xf16>
    %1577 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_1677 = torch.constant.int 6
    %1578 = torch.prims.convert_element_type %1577, %int6_1677 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_1678 = torch.constant.int 6
    %1579 = torch.prims.convert_element_type %1574, %int6_1678 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1679 = torch.constant.int 6
    %1580 = torch.prims.convert_element_type %1576, %int6_1679 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %1581 = torch.aten.mm %1579, %1580 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_1680 = torch.constant.int 1
    %1582 = torch.aten.mul.Scalar %1581, %int1_1680 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_1681 = torch.constant.int 1
    %1583 = torch.aten.mul.Scalar %1578, %int1_1681 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_1682 = torch.constant.int 1
    %1584 = torch.aten.add.Tensor %1582, %1583, %int1_1682 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_1683 = torch.constant.int 5
    %1585 = torch.prims.convert_element_type %1584, %int5_1683 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_1684 = torch.constant.int 1
    %int64_1685 = torch.constant.int 64
    %int3072_1686 = torch.constant.int 3072
    %1586 = torch.prim.ListConstruct %int1_1684, %int64_1685, %int3072_1686 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1587 = torch.aten.view %1585, %1586 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00_1687 = torch.constant.float 1.702000e+00
    %1588 = torch.aten.mul.Scalar %1587, %float1.702000e00_1687 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %1589 = torch.aten.sigmoid %1588 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1590 = torch.aten.detach %1589 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1591 = torch.aten.mul.Tensor %1587, %1589 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_1688 = torch.constant.int 64
    %int3072_1689 = torch.constant.int 3072
    %1592 = torch.prim.ListConstruct %int64_1688, %int3072_1689 : (!torch.int, !torch.int) -> !torch.list<int>
    %1593 = torch.aten.view %1591, %1592 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc2.weight : tensor<768x3072xf16>
    %1594 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_1690 = torch.constant.int 0
    %int1_1691 = torch.constant.int 1
    %1595 = torch.aten.transpose.int %1594, %int0_1690, %int1_1691 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc2.bias : tensor<768xf16>
    %1596 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.9.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1692 = torch.constant.int 6
    %1597 = torch.prims.convert_element_type %1596, %int6_1692 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1693 = torch.constant.int 6
    %1598 = torch.prims.convert_element_type %1593, %int6_1693 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_1694 = torch.constant.int 6
    %1599 = torch.prims.convert_element_type %1595, %int6_1694 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %1600 = torch.aten.mm %1598, %1599 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1695 = torch.constant.int 1
    %1601 = torch.aten.mul.Scalar %1600, %int1_1695 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1696 = torch.constant.int 1
    %1602 = torch.aten.mul.Scalar %1597, %int1_1696 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1697 = torch.constant.int 1
    %1603 = torch.aten.add.Tensor %1601, %1602, %int1_1697 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1698 = torch.constant.int 5
    %1604 = torch.prims.convert_element_type %1603, %int5_1698 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1699 = torch.constant.int 1
    %int64_1700 = torch.constant.int 64
    %int768_1701 = torch.constant.int 768
    %1605 = torch.prim.ListConstruct %int1_1699, %int64_1700, %int768_1701 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1606 = torch.aten.view %1604, %1605 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1702 = torch.constant.int 1
    %1607 = torch.aten.add.Tensor %1559, %1606, %int1_1702 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1703 = torch.constant.int 6
    %1608 = torch.prims.convert_element_type %1607, %int6_1703 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1704 = torch.constant.int 2
    %1609 = torch.prim.ListConstruct %int2_1704 : (!torch.int) -> !torch.list<int>
    %int0_1705 = torch.constant.int 0
    %true_1706 = torch.constant.bool true
    %result0_1707, %result1_1708 = torch.aten.var_mean.correction %1608, %1609, %int0_1705, %true_1706 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_1709 = torch.constant.float 1.000000e-05
    %int1_1710 = torch.constant.int 1
    %1610 = torch.aten.add.Scalar %result0_1707, %float1.000000e-05_1709, %int1_1710 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1611 = torch.aten.rsqrt %1610 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1711 = torch.constant.int 1
    %1612 = torch.aten.sub.Tensor %1607, %result1_1708, %int1_1711 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1613 = torch.aten.mul.Tensor %1612, %1611 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.10.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.layer_norm1.weight : tensor<768xf16>
    %1614 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1615 = torch.aten.mul.Tensor %1613, %1614 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.10.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.layer_norm1.bias : tensor<768xf16>
    %1616 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1712 = torch.constant.int 1
    %1617 = torch.aten.add.Tensor %1615, %1616, %int1_1712 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1713 = torch.constant.int 5
    %1618 = torch.prims.convert_element_type %1617, %int5_1713 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1714 = torch.constant.int 5
    %1619 = torch.prims.convert_element_type %result1_1708, %int5_1714 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1715 = torch.constant.int 5
    %1620 = torch.prims.convert_element_type %1611, %int5_1715 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1716 = torch.constant.int 64
    %int768_1717 = torch.constant.int 768
    %1621 = torch.prim.ListConstruct %int64_1716, %int768_1717 : (!torch.int, !torch.int) -> !torch.list<int>
    %1622 = torch.aten.view %1618, %1621 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.q_proj.weight : tensor<768x768xf16>
    %1623 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1718 = torch.constant.int 0
    %int1_1719 = torch.constant.int 1
    %1624 = torch.aten.transpose.int %1623, %int0_1718, %int1_1719 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.q_proj.bias : tensor<768xf16>
    %1625 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1720 = torch.constant.int 6
    %1626 = torch.prims.convert_element_type %1625, %int6_1720 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1721 = torch.constant.int 6
    %1627 = torch.prims.convert_element_type %1622, %int6_1721 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1722 = torch.constant.int 6
    %1628 = torch.prims.convert_element_type %1624, %int6_1722 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1629 = torch.aten.mm %1627, %1628 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1723 = torch.constant.int 1
    %1630 = torch.aten.mul.Scalar %1629, %int1_1723 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1724 = torch.constant.int 1
    %1631 = torch.aten.mul.Scalar %1626, %int1_1724 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1725 = torch.constant.int 1
    %1632 = torch.aten.add.Tensor %1630, %1631, %int1_1725 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1726 = torch.constant.int 5
    %1633 = torch.prims.convert_element_type %1632, %int5_1726 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1727 = torch.constant.int 1
    %int64_1728 = torch.constant.int 64
    %int768_1729 = torch.constant.int 768
    %1634 = torch.prim.ListConstruct %int1_1727, %int64_1728, %int768_1729 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1635 = torch.aten.view %1633, %1634 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01_1730 = torch.constant.float 1.250000e-01
    %1636 = torch.aten.mul.Scalar %1635, %float1.250000e-01_1730 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_1731 = torch.constant.int 64
    %int768_1732 = torch.constant.int 768
    %1637 = torch.prim.ListConstruct %int64_1731, %int768_1732 : (!torch.int, !torch.int) -> !torch.list<int>
    %1638 = torch.aten.view %1618, %1637 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.k_proj.weight : tensor<768x768xf16>
    %1639 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1733 = torch.constant.int 0
    %int1_1734 = torch.constant.int 1
    %1640 = torch.aten.transpose.int %1639, %int0_1733, %int1_1734 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.k_proj.bias : tensor<768xf16>
    %1641 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1735 = torch.constant.int 6
    %1642 = torch.prims.convert_element_type %1641, %int6_1735 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1736 = torch.constant.int 6
    %1643 = torch.prims.convert_element_type %1638, %int6_1736 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1737 = torch.constant.int 6
    %1644 = torch.prims.convert_element_type %1640, %int6_1737 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1645 = torch.aten.mm %1643, %1644 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1738 = torch.constant.int 1
    %1646 = torch.aten.mul.Scalar %1645, %int1_1738 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1739 = torch.constant.int 1
    %1647 = torch.aten.mul.Scalar %1642, %int1_1739 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1740 = torch.constant.int 1
    %1648 = torch.aten.add.Tensor %1646, %1647, %int1_1740 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1741 = torch.constant.int 5
    %1649 = torch.prims.convert_element_type %1648, %int5_1741 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1742 = torch.constant.int 1
    %int64_1743 = torch.constant.int 64
    %int768_1744 = torch.constant.int 768
    %1650 = torch.prim.ListConstruct %int1_1742, %int64_1743, %int768_1744 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1651 = torch.aten.view %1649, %1650 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1745 = torch.constant.int 1
    %int-1_1746 = torch.constant.int -1
    %int12_1747 = torch.constant.int 12
    %int64_1748 = torch.constant.int 64
    %1652 = torch.prim.ListConstruct %int1_1745, %int-1_1746, %int12_1747, %int64_1748 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1653 = torch.aten.view %1651, %1652 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1749 = torch.constant.int 1
    %int2_1750 = torch.constant.int 2
    %1654 = torch.aten.transpose.int %1653, %int1_1749, %int2_1750 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1751 = torch.constant.int 0
    %1655 = torch.aten.clone %1654, %int0_1751 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_1752 = torch.constant.int 64
    %int768_1753 = torch.constant.int 768
    %1656 = torch.prim.ListConstruct %int64_1752, %int768_1753 : (!torch.int, !torch.int) -> !torch.list<int>
    %1657 = torch.aten.view %1618, %1656 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.v_proj.weight : tensor<768x768xf16>
    %1658 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1754 = torch.constant.int 0
    %int1_1755 = torch.constant.int 1
    %1659 = torch.aten.transpose.int %1658, %int0_1754, %int1_1755 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.v_proj.bias : tensor<768xf16>
    %1660 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1756 = torch.constant.int 6
    %1661 = torch.prims.convert_element_type %1660, %int6_1756 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1757 = torch.constant.int 6
    %1662 = torch.prims.convert_element_type %1657, %int6_1757 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1758 = torch.constant.int 6
    %1663 = torch.prims.convert_element_type %1659, %int6_1758 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1664 = torch.aten.mm %1662, %1663 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1759 = torch.constant.int 1
    %1665 = torch.aten.mul.Scalar %1664, %int1_1759 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1760 = torch.constant.int 1
    %1666 = torch.aten.mul.Scalar %1661, %int1_1760 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1761 = torch.constant.int 1
    %1667 = torch.aten.add.Tensor %1665, %1666, %int1_1761 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1762 = torch.constant.int 5
    %1668 = torch.prims.convert_element_type %1667, %int5_1762 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1763 = torch.constant.int 1
    %int64_1764 = torch.constant.int 64
    %int768_1765 = torch.constant.int 768
    %1669 = torch.prim.ListConstruct %int1_1763, %int64_1764, %int768_1765 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1670 = torch.aten.view %1668, %1669 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1766 = torch.constant.int 1
    %int-1_1767 = torch.constant.int -1
    %int12_1768 = torch.constant.int 12
    %int64_1769 = torch.constant.int 64
    %1671 = torch.prim.ListConstruct %int1_1766, %int-1_1767, %int12_1768, %int64_1769 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1672 = torch.aten.view %1670, %1671 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1770 = torch.constant.int 1
    %int2_1771 = torch.constant.int 2
    %1673 = torch.aten.transpose.int %1672, %int1_1770, %int2_1771 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1772 = torch.constant.int 0
    %1674 = torch.aten.clone %1673, %int0_1772 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1773 = torch.constant.int 1
    %int64_1774 = torch.constant.int 64
    %int12_1775 = torch.constant.int 12
    %int64_1776 = torch.constant.int 64
    %1675 = torch.prim.ListConstruct %int1_1773, %int64_1774, %int12_1775, %int64_1776 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1676 = torch.aten.view %1636, %1675 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1777 = torch.constant.int 1
    %int2_1778 = torch.constant.int 2
    %1677 = torch.aten.transpose.int %1676, %int1_1777, %int2_1778 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1779 = torch.constant.int 0
    %1678 = torch.aten.clone %1677, %int0_1779 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1780 = torch.constant.int 12
    %int-1_1781 = torch.constant.int -1
    %int64_1782 = torch.constant.int 64
    %1679 = torch.prim.ListConstruct %int12_1780, %int-1_1781, %int64_1782 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1680 = torch.aten.view %1678, %1679 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1783 = torch.constant.int 12
    %int-1_1784 = torch.constant.int -1
    %int64_1785 = torch.constant.int 64
    %1681 = torch.prim.ListConstruct %int12_1783, %int-1_1784, %int64_1785 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1682 = torch.aten.view %1655, %1681 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1786 = torch.constant.int 12
    %int-1_1787 = torch.constant.int -1
    %int64_1788 = torch.constant.int 64
    %1683 = torch.prim.ListConstruct %int12_1786, %int-1_1787, %int64_1788 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1684 = torch.aten.view %1674, %1683 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_1789 = torch.constant.int 1
    %int2_1790 = torch.constant.int 2
    %1685 = torch.aten.transpose.int %1682, %int1_1789, %int2_1790 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %1686 = torch.aten.bmm %1680, %1685 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1791 = torch.constant.int 1
    %int12_1792 = torch.constant.int 12
    %int64_1793 = torch.constant.int 64
    %int64_1794 = torch.constant.int 64
    %1687 = torch.prim.ListConstruct %int1_1791, %int12_1792, %int64_1793, %int64_1794 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1688 = torch.aten.view %1686, %1687 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1795 = torch.constant.int 1
    %1689 = torch.aten.add.Tensor %1688, %27, %int1_1795 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1796 = torch.constant.int 12
    %int64_1797 = torch.constant.int 64
    %int64_1798 = torch.constant.int 64
    %1690 = torch.prim.ListConstruct %int12_1796, %int64_1797, %int64_1798 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1691 = torch.aten.view %1689, %1690 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_1799 = torch.constant.int -1
    %false_1800 = torch.constant.bool false
    %1692 = torch.aten._softmax %1691, %int-1_1799, %false_1800 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %1693 = torch.aten.detach %1692 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_1801 = torch.constant.none
    %1694 = torch.aten.clone %1692, %none_1801 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %1695 = torch.aten.bmm %1694, %1684 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1802 = torch.constant.int 1
    %int12_1803 = torch.constant.int 12
    %int64_1804 = torch.constant.int 64
    %int64_1805 = torch.constant.int 64
    %1696 = torch.prim.ListConstruct %int1_1802, %int12_1803, %int64_1804, %int64_1805 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1697 = torch.aten.view %1695, %1696 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1806 = torch.constant.int 1
    %int2_1807 = torch.constant.int 2
    %1698 = torch.aten.transpose.int %1697, %int1_1806, %int2_1807 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_1808 = torch.constant.int 0
    %1699 = torch.aten.clone %1698, %int0_1808 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1809 = torch.constant.int 1
    %int64_1810 = torch.constant.int 64
    %int768_1811 = torch.constant.int 768
    %1700 = torch.prim.ListConstruct %int1_1809, %int64_1810, %int768_1811 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1701 = torch.aten._unsafe_view %1699, %1700 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_1812 = torch.constant.int 64
    %int768_1813 = torch.constant.int 768
    %1702 = torch.prim.ListConstruct %int64_1812, %int768_1813 : (!torch.int, !torch.int) -> !torch.list<int>
    %1703 = torch.aten.view %1701, %1702 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.out_proj.weight : tensor<768x768xf16>
    %1704 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1814 = torch.constant.int 0
    %int1_1815 = torch.constant.int 1
    %1705 = torch.aten.transpose.int %1704, %int0_1814, %int1_1815 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.self_attn.out_proj.bias : tensor<768xf16>
    %1706 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1816 = torch.constant.int 6
    %1707 = torch.prims.convert_element_type %1706, %int6_1816 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1817 = torch.constant.int 6
    %1708 = torch.prims.convert_element_type %1703, %int6_1817 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1818 = torch.constant.int 6
    %1709 = torch.prims.convert_element_type %1705, %int6_1818 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1710 = torch.aten.mm %1708, %1709 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1819 = torch.constant.int 1
    %1711 = torch.aten.mul.Scalar %1710, %int1_1819 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1820 = torch.constant.int 1
    %1712 = torch.aten.mul.Scalar %1707, %int1_1820 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1821 = torch.constant.int 1
    %1713 = torch.aten.add.Tensor %1711, %1712, %int1_1821 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1822 = torch.constant.int 5
    %1714 = torch.prims.convert_element_type %1713, %int5_1822 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1823 = torch.constant.int 1
    %int64_1824 = torch.constant.int 64
    %int768_1825 = torch.constant.int 768
    %1715 = torch.prim.ListConstruct %int1_1823, %int64_1824, %int768_1825 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1716 = torch.aten.view %1714, %1715 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1826 = torch.constant.int 1
    %1717 = torch.aten.add.Tensor %1607, %1716, %int1_1826 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1827 = torch.constant.int 6
    %1718 = torch.prims.convert_element_type %1717, %int6_1827 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1828 = torch.constant.int 2
    %1719 = torch.prim.ListConstruct %int2_1828 : (!torch.int) -> !torch.list<int>
    %int0_1829 = torch.constant.int 0
    %true_1830 = torch.constant.bool true
    %result0_1831, %result1_1832 = torch.aten.var_mean.correction %1718, %1719, %int0_1829, %true_1830 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_1833 = torch.constant.float 1.000000e-05
    %int1_1834 = torch.constant.int 1
    %1720 = torch.aten.add.Scalar %result0_1831, %float1.000000e-05_1833, %int1_1834 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1721 = torch.aten.rsqrt %1720 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1835 = torch.constant.int 1
    %1722 = torch.aten.sub.Tensor %1717, %result1_1832, %int1_1835 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1723 = torch.aten.mul.Tensor %1722, %1721 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.10.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.layer_norm2.weight : tensor<768xf16>
    %1724 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1725 = torch.aten.mul.Tensor %1723, %1724 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.10.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.layer_norm2.bias : tensor<768xf16>
    %1726 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1836 = torch.constant.int 1
    %1727 = torch.aten.add.Tensor %1725, %1726, %int1_1836 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1837 = torch.constant.int 5
    %1728 = torch.prims.convert_element_type %1727, %int5_1837 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1838 = torch.constant.int 5
    %1729 = torch.prims.convert_element_type %result1_1832, %int5_1838 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1839 = torch.constant.int 5
    %1730 = torch.prims.convert_element_type %1721, %int5_1839 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1840 = torch.constant.int 64
    %int768_1841 = torch.constant.int 768
    %1731 = torch.prim.ListConstruct %int64_1840, %int768_1841 : (!torch.int, !torch.int) -> !torch.list<int>
    %1732 = torch.aten.view %1728, %1731 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc1.weight : tensor<3072x768xf16>
    %1733 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_1842 = torch.constant.int 0
    %int1_1843 = torch.constant.int 1
    %1734 = torch.aten.transpose.int %1733, %int0_1842, %int1_1843 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc1.bias : tensor<3072xf16>
    %1735 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_1844 = torch.constant.int 6
    %1736 = torch.prims.convert_element_type %1735, %int6_1844 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_1845 = torch.constant.int 6
    %1737 = torch.prims.convert_element_type %1732, %int6_1845 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1846 = torch.constant.int 6
    %1738 = torch.prims.convert_element_type %1734, %int6_1846 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %1739 = torch.aten.mm %1737, %1738 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_1847 = torch.constant.int 1
    %1740 = torch.aten.mul.Scalar %1739, %int1_1847 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_1848 = torch.constant.int 1
    %1741 = torch.aten.mul.Scalar %1736, %int1_1848 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_1849 = torch.constant.int 1
    %1742 = torch.aten.add.Tensor %1740, %1741, %int1_1849 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_1850 = torch.constant.int 5
    %1743 = torch.prims.convert_element_type %1742, %int5_1850 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_1851 = torch.constant.int 1
    %int64_1852 = torch.constant.int 64
    %int3072_1853 = torch.constant.int 3072
    %1744 = torch.prim.ListConstruct %int1_1851, %int64_1852, %int3072_1853 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1745 = torch.aten.view %1743, %1744 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00_1854 = torch.constant.float 1.702000e+00
    %1746 = torch.aten.mul.Scalar %1745, %float1.702000e00_1854 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %1747 = torch.aten.sigmoid %1746 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1748 = torch.aten.detach %1747 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1749 = torch.aten.mul.Tensor %1745, %1747 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_1855 = torch.constant.int 64
    %int3072_1856 = torch.constant.int 3072
    %1750 = torch.prim.ListConstruct %int64_1855, %int3072_1856 : (!torch.int, !torch.int) -> !torch.list<int>
    %1751 = torch.aten.view %1749, %1750 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc2.weight : tensor<768x3072xf16>
    %1752 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_1857 = torch.constant.int 0
    %int1_1858 = torch.constant.int 1
    %1753 = torch.aten.transpose.int %1752, %int0_1857, %int1_1858 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc2.bias : tensor<768xf16>
    %1754 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.10.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1859 = torch.constant.int 6
    %1755 = torch.prims.convert_element_type %1754, %int6_1859 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1860 = torch.constant.int 6
    %1756 = torch.prims.convert_element_type %1751, %int6_1860 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_1861 = torch.constant.int 6
    %1757 = torch.prims.convert_element_type %1753, %int6_1861 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %1758 = torch.aten.mm %1756, %1757 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1862 = torch.constant.int 1
    %1759 = torch.aten.mul.Scalar %1758, %int1_1862 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1863 = torch.constant.int 1
    %1760 = torch.aten.mul.Scalar %1755, %int1_1863 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1864 = torch.constant.int 1
    %1761 = torch.aten.add.Tensor %1759, %1760, %int1_1864 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1865 = torch.constant.int 5
    %1762 = torch.prims.convert_element_type %1761, %int5_1865 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1866 = torch.constant.int 1
    %int64_1867 = torch.constant.int 64
    %int768_1868 = torch.constant.int 768
    %1763 = torch.prim.ListConstruct %int1_1866, %int64_1867, %int768_1868 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1764 = torch.aten.view %1762, %1763 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1869 = torch.constant.int 1
    %1765 = torch.aten.add.Tensor %1717, %1764, %int1_1869 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1870 = torch.constant.int 6
    %1766 = torch.prims.convert_element_type %1765, %int6_1870 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1871 = torch.constant.int 2
    %1767 = torch.prim.ListConstruct %int2_1871 : (!torch.int) -> !torch.list<int>
    %int0_1872 = torch.constant.int 0
    %true_1873 = torch.constant.bool true
    %result0_1874, %result1_1875 = torch.aten.var_mean.correction %1766, %1767, %int0_1872, %true_1873 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_1876 = torch.constant.float 1.000000e-05
    %int1_1877 = torch.constant.int 1
    %1768 = torch.aten.add.Scalar %result0_1874, %float1.000000e-05_1876, %int1_1877 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1769 = torch.aten.rsqrt %1768 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_1878 = torch.constant.int 1
    %1770 = torch.aten.sub.Tensor %1765, %result1_1875, %int1_1878 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1771 = torch.aten.mul.Tensor %1770, %1769 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.11.layer_norm1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.layer_norm1.weight : tensor<768xf16>
    %1772 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.layer_norm1.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1773 = torch.aten.mul.Tensor %1771, %1772 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.11.layer_norm1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.layer_norm1.bias : tensor<768xf16>
    %1774 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.layer_norm1.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_1879 = torch.constant.int 1
    %1775 = torch.aten.add.Tensor %1773, %1774, %int1_1879 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_1880 = torch.constant.int 5
    %1776 = torch.prims.convert_element_type %1775, %int5_1880 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_1881 = torch.constant.int 5
    %1777 = torch.prims.convert_element_type %result1_1875, %int5_1881 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_1882 = torch.constant.int 5
    %1778 = torch.prims.convert_element_type %1769, %int5_1882 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_1883 = torch.constant.int 64
    %int768_1884 = torch.constant.int 768
    %1779 = torch.prim.ListConstruct %int64_1883, %int768_1884 : (!torch.int, !torch.int) -> !torch.list<int>
    %1780 = torch.aten.view %1776, %1779 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.q_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.q_proj.weight : tensor<768x768xf16>
    %1781 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.q_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1885 = torch.constant.int 0
    %int1_1886 = torch.constant.int 1
    %1782 = torch.aten.transpose.int %1781, %int0_1885, %int1_1886 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.q_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.q_proj.bias : tensor<768xf16>
    %1783 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.q_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1887 = torch.constant.int 6
    %1784 = torch.prims.convert_element_type %1783, %int6_1887 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1888 = torch.constant.int 6
    %1785 = torch.prims.convert_element_type %1780, %int6_1888 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1889 = torch.constant.int 6
    %1786 = torch.prims.convert_element_type %1782, %int6_1889 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1787 = torch.aten.mm %1785, %1786 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1890 = torch.constant.int 1
    %1788 = torch.aten.mul.Scalar %1787, %int1_1890 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1891 = torch.constant.int 1
    %1789 = torch.aten.mul.Scalar %1784, %int1_1891 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1892 = torch.constant.int 1
    %1790 = torch.aten.add.Tensor %1788, %1789, %int1_1892 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1893 = torch.constant.int 5
    %1791 = torch.prims.convert_element_type %1790, %int5_1893 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1894 = torch.constant.int 1
    %int64_1895 = torch.constant.int 64
    %int768_1896 = torch.constant.int 768
    %1792 = torch.prim.ListConstruct %int1_1894, %int64_1895, %int768_1896 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1793 = torch.aten.view %1791, %1792 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %float1.250000e-01_1897 = torch.constant.float 1.250000e-01
    %1794 = torch.aten.mul.Scalar %1793, %float1.250000e-01_1897 : !torch.vtensor<[1,64,768],f16>, !torch.float -> !torch.vtensor<[1,64,768],f16>
    %int64_1898 = torch.constant.int 64
    %int768_1899 = torch.constant.int 768
    %1795 = torch.prim.ListConstruct %int64_1898, %int768_1899 : (!torch.int, !torch.int) -> !torch.list<int>
    %1796 = torch.aten.view %1776, %1795 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.k_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.k_proj.weight : tensor<768x768xf16>
    %1797 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.k_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1900 = torch.constant.int 0
    %int1_1901 = torch.constant.int 1
    %1798 = torch.aten.transpose.int %1797, %int0_1900, %int1_1901 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.k_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.k_proj.bias : tensor<768xf16>
    %1799 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.k_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1902 = torch.constant.int 6
    %1800 = torch.prims.convert_element_type %1799, %int6_1902 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1903 = torch.constant.int 6
    %1801 = torch.prims.convert_element_type %1796, %int6_1903 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1904 = torch.constant.int 6
    %1802 = torch.prims.convert_element_type %1798, %int6_1904 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1803 = torch.aten.mm %1801, %1802 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1905 = torch.constant.int 1
    %1804 = torch.aten.mul.Scalar %1803, %int1_1905 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1906 = torch.constant.int 1
    %1805 = torch.aten.mul.Scalar %1800, %int1_1906 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1907 = torch.constant.int 1
    %1806 = torch.aten.add.Tensor %1804, %1805, %int1_1907 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1908 = torch.constant.int 5
    %1807 = torch.prims.convert_element_type %1806, %int5_1908 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1909 = torch.constant.int 1
    %int64_1910 = torch.constant.int 64
    %int768_1911 = torch.constant.int 768
    %1808 = torch.prim.ListConstruct %int1_1909, %int64_1910, %int768_1911 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1809 = torch.aten.view %1807, %1808 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1912 = torch.constant.int 1
    %int-1_1913 = torch.constant.int -1
    %int12_1914 = torch.constant.int 12
    %int64_1915 = torch.constant.int 64
    %1810 = torch.prim.ListConstruct %int1_1912, %int-1_1913, %int12_1914, %int64_1915 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1811 = torch.aten.view %1809, %1810 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1916 = torch.constant.int 1
    %int2_1917 = torch.constant.int 2
    %1812 = torch.aten.transpose.int %1811, %int1_1916, %int2_1917 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1918 = torch.constant.int 0
    %1813 = torch.aten.clone %1812, %int0_1918 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int64_1919 = torch.constant.int 64
    %int768_1920 = torch.constant.int 768
    %1814 = torch.prim.ListConstruct %int64_1919, %int768_1920 : (!torch.int, !torch.int) -> !torch.list<int>
    %1815 = torch.aten.view %1776, %1814 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.v_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.v_proj.weight : tensor<768x768xf16>
    %1816 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.v_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1921 = torch.constant.int 0
    %int1_1922 = torch.constant.int 1
    %1817 = torch.aten.transpose.int %1816, %int0_1921, %int1_1922 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.v_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.v_proj.bias : tensor<768xf16>
    %1818 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.v_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1923 = torch.constant.int 6
    %1819 = torch.prims.convert_element_type %1818, %int6_1923 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1924 = torch.constant.int 6
    %1820 = torch.prims.convert_element_type %1815, %int6_1924 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1925 = torch.constant.int 6
    %1821 = torch.prims.convert_element_type %1817, %int6_1925 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1822 = torch.aten.mm %1820, %1821 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1926 = torch.constant.int 1
    %1823 = torch.aten.mul.Scalar %1822, %int1_1926 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1927 = torch.constant.int 1
    %1824 = torch.aten.mul.Scalar %1819, %int1_1927 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1928 = torch.constant.int 1
    %1825 = torch.aten.add.Tensor %1823, %1824, %int1_1928 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1929 = torch.constant.int 5
    %1826 = torch.prims.convert_element_type %1825, %int5_1929 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1930 = torch.constant.int 1
    %int64_1931 = torch.constant.int 64
    %int768_1932 = torch.constant.int 768
    %1827 = torch.prim.ListConstruct %int1_1930, %int64_1931, %int768_1932 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1828 = torch.aten.view %1826, %1827 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1933 = torch.constant.int 1
    %int-1_1934 = torch.constant.int -1
    %int12_1935 = torch.constant.int 12
    %int64_1936 = torch.constant.int 64
    %1829 = torch.prim.ListConstruct %int1_1933, %int-1_1934, %int12_1935, %int64_1936 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1830 = torch.aten.view %1828, %1829 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1937 = torch.constant.int 1
    %int2_1938 = torch.constant.int 2
    %1831 = torch.aten.transpose.int %1830, %int1_1937, %int2_1938 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1939 = torch.constant.int 0
    %1832 = torch.aten.clone %1831, %int0_1939 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1940 = torch.constant.int 1
    %int64_1941 = torch.constant.int 64
    %int12_1942 = torch.constant.int 12
    %int64_1943 = torch.constant.int 64
    %1833 = torch.prim.ListConstruct %int1_1940, %int64_1941, %int12_1942, %int64_1943 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1834 = torch.aten.view %1794, %1833 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1944 = torch.constant.int 1
    %int2_1945 = torch.constant.int 2
    %1835 = torch.aten.transpose.int %1834, %int1_1944, %int2_1945 : !torch.vtensor<[1,64,12,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int0_1946 = torch.constant.int 0
    %1836 = torch.aten.clone %1835, %int0_1946 : !torch.vtensor<[1,12,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1947 = torch.constant.int 12
    %int-1_1948 = torch.constant.int -1
    %int64_1949 = torch.constant.int 64
    %1837 = torch.prim.ListConstruct %int12_1947, %int-1_1948, %int64_1949 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1838 = torch.aten.view %1836, %1837 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1950 = torch.constant.int 12
    %int-1_1951 = torch.constant.int -1
    %int64_1952 = torch.constant.int 64
    %1839 = torch.prim.ListConstruct %int12_1950, %int-1_1951, %int64_1952 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1840 = torch.aten.view %1813, %1839 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int12_1953 = torch.constant.int 12
    %int-1_1954 = torch.constant.int -1
    %int64_1955 = torch.constant.int 64
    %1841 = torch.prim.ListConstruct %int12_1953, %int-1_1954, %int64_1955 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1842 = torch.aten.view %1832, %1841 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int1_1956 = torch.constant.int 1
    %int2_1957 = torch.constant.int 2
    %1843 = torch.aten.transpose.int %1840, %int1_1956, %int2_1957 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[12,64,64],f16>
    %1844 = torch.aten.bmm %1838, %1843 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1958 = torch.constant.int 1
    %int12_1959 = torch.constant.int 12
    %int64_1960 = torch.constant.int 64
    %int64_1961 = torch.constant.int 64
    %1845 = torch.prim.ListConstruct %int1_1958, %int12_1959, %int64_1960, %int64_1961 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1846 = torch.aten.view %1844, %1845 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1962 = torch.constant.int 1
    %1847 = torch.aten.add.Tensor %1846, %27, %int1_1962 : !torch.vtensor<[1,12,64,64],f16>, !torch.vtensor<[1,1,64,64],f16>, !torch.int -> !torch.vtensor<[1,12,64,64],f16>
    %int12_1963 = torch.constant.int 12
    %int64_1964 = torch.constant.int 64
    %int64_1965 = torch.constant.int 64
    %1848 = torch.prim.ListConstruct %int12_1963, %int64_1964, %int64_1965 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1849 = torch.aten.view %1847, %1848 : !torch.vtensor<[1,12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[12,64,64],f16>
    %int-1_1966 = torch.constant.int -1
    %false_1967 = torch.constant.bool false
    %1850 = torch.aten._softmax %1849, %int-1_1966, %false_1967 : !torch.vtensor<[12,64,64],f16>, !torch.int, !torch.bool -> !torch.vtensor<[12,64,64],f16>
    %1851 = torch.aten.detach %1850 : !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %none_1968 = torch.constant.none
    %1852 = torch.aten.clone %1850, %none_1968 : !torch.vtensor<[12,64,64],f16>, !torch.none -> !torch.vtensor<[12,64,64],f16>
    %1853 = torch.aten.bmm %1852, %1842 : !torch.vtensor<[12,64,64],f16>, !torch.vtensor<[12,64,64],f16> -> !torch.vtensor<[12,64,64],f16>
    %int1_1969 = torch.constant.int 1
    %int12_1970 = torch.constant.int 12
    %int64_1971 = torch.constant.int 64
    %int64_1972 = torch.constant.int 64
    %1854 = torch.prim.ListConstruct %int1_1969, %int12_1970, %int64_1971, %int64_1972 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1855 = torch.aten.view %1853, %1854 : !torch.vtensor<[12,64,64],f16>, !torch.list<int> -> !torch.vtensor<[1,12,64,64],f16>
    %int1_1973 = torch.constant.int 1
    %int2_1974 = torch.constant.int 2
    %1856 = torch.aten.transpose.int %1855, %int1_1973, %int2_1974 : !torch.vtensor<[1,12,64,64],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int0_1975 = torch.constant.int 0
    %1857 = torch.aten.clone %1856, %int0_1975 : !torch.vtensor<[1,64,12,64],f16>, !torch.int -> !torch.vtensor<[1,64,12,64],f16>
    %int1_1976 = torch.constant.int 1
    %int64_1977 = torch.constant.int 64
    %int768_1978 = torch.constant.int 768
    %1858 = torch.prim.ListConstruct %int1_1976, %int64_1977, %int768_1978 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1859 = torch.aten._unsafe_view %1857, %1858 : !torch.vtensor<[1,64,12,64],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int64_1979 = torch.constant.int 64
    %int768_1980 = torch.constant.int 768
    %1860 = torch.prim.ListConstruct %int64_1979, %int768_1980 : (!torch.int, !torch.int) -> !torch.list<int>
    %1861 = torch.aten.view %1859, %1860 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.out_proj.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.out_proj.weight : tensor<768x768xf16>
    %1862 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.out_proj.weight : tensor<768x768xf16> -> !torch.vtensor<[768,768],f16>
    %int0_1981 = torch.constant.int 0
    %int1_1982 = torch.constant.int 1
    %1863 = torch.aten.transpose.int %1862, %int0_1981, %int1_1982 : !torch.vtensor<[768,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.out_proj.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.self_attn.out_proj.bias : tensor<768xf16>
    %1864 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.self_attn.out_proj.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_1983 = torch.constant.int 6
    %1865 = torch.prims.convert_element_type %1864, %int6_1983 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_1984 = torch.constant.int 6
    %1866 = torch.prims.convert_element_type %1861, %int6_1984 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_1985 = torch.constant.int 6
    %1867 = torch.prims.convert_element_type %1863, %int6_1985 : !torch.vtensor<[768,768],f16>, !torch.int -> !torch.vtensor<[768,768],f32>
    %1868 = torch.aten.mm %1866, %1867 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_1986 = torch.constant.int 1
    %1869 = torch.aten.mul.Scalar %1868, %int1_1986 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_1987 = torch.constant.int 1
    %1870 = torch.aten.mul.Scalar %1865, %int1_1987 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_1988 = torch.constant.int 1
    %1871 = torch.aten.add.Tensor %1869, %1870, %int1_1988 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_1989 = torch.constant.int 5
    %1872 = torch.prims.convert_element_type %1871, %int5_1989 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_1990 = torch.constant.int 1
    %int64_1991 = torch.constant.int 64
    %int768_1992 = torch.constant.int 768
    %1873 = torch.prim.ListConstruct %int1_1990, %int64_1991, %int768_1992 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1874 = torch.aten.view %1872, %1873 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_1993 = torch.constant.int 1
    %1875 = torch.aten.add.Tensor %1765, %1874, %int1_1993 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_1994 = torch.constant.int 6
    %1876 = torch.prims.convert_element_type %1875, %int6_1994 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_1995 = torch.constant.int 2
    %1877 = torch.prim.ListConstruct %int2_1995 : (!torch.int) -> !torch.list<int>
    %int0_1996 = torch.constant.int 0
    %true_1997 = torch.constant.bool true
    %result0_1998, %result1_1999 = torch.aten.var_mean.correction %1876, %1877, %int0_1996, %true_1997 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_2000 = torch.constant.float 1.000000e-05
    %int1_2001 = torch.constant.int 1
    %1878 = torch.aten.add.Scalar %result0_1998, %float1.000000e-05_2000, %int1_2001 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1879 = torch.aten.rsqrt %1878 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_2002 = torch.constant.int 1
    %1880 = torch.aten.sub.Tensor %1875, %result1_1999, %int1_2002 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1881 = torch.aten.mul.Tensor %1880, %1879 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.11.layer_norm2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.layer_norm2.weight : tensor<768xf16>
    %1882 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.layer_norm2.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1883 = torch.aten.mul.Tensor %1881, %1882 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.encoder.layers.11.layer_norm2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.layer_norm2.bias : tensor<768xf16>
    %1884 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.layer_norm2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_2003 = torch.constant.int 1
    %1885 = torch.aten.add.Tensor %1883, %1884, %int1_2003 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_2004 = torch.constant.int 5
    %1886 = torch.prims.convert_element_type %1885, %int5_2004 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_2005 = torch.constant.int 5
    %1887 = torch.prims.convert_element_type %result1_1999, %int5_2005 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_2006 = torch.constant.int 5
    %1888 = torch.prims.convert_element_type %1879, %int5_2006 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int64_2007 = torch.constant.int 64
    %int768_2008 = torch.constant.int 768
    %1889 = torch.prim.ListConstruct %int64_2007, %int768_2008 : (!torch.int, !torch.int) -> !torch.list<int>
    %1890 = torch.aten.view %1886, %1889 : !torch.vtensor<[1,64,768],f16>, !torch.list<int> -> !torch.vtensor<[64,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc1.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc1.weight : tensor<3072x768xf16>
    %1891 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc1.weight : tensor<3072x768xf16> -> !torch.vtensor<[3072,768],f16>
    %int0_2009 = torch.constant.int 0
    %int1_2010 = torch.constant.int 1
    %1892 = torch.aten.transpose.int %1891, %int0_2009, %int1_2010 : !torch.vtensor<[3072,768],f16>, !torch.int, !torch.int -> !torch.vtensor<[768,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc1.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc1.bias : tensor<3072xf16>
    %1893 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc1.bias : tensor<3072xf16> -> !torch.vtensor<[3072],f16>
    %int6_2011 = torch.constant.int 6
    %1894 = torch.prims.convert_element_type %1893, %int6_2011 : !torch.vtensor<[3072],f16>, !torch.int -> !torch.vtensor<[3072],f32>
    %int6_2012 = torch.constant.int 6
    %1895 = torch.prims.convert_element_type %1890, %int6_2012 : !torch.vtensor<[64,768],f16>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int6_2013 = torch.constant.int 6
    %1896 = torch.prims.convert_element_type %1892, %int6_2013 : !torch.vtensor<[768,3072],f16>, !torch.int -> !torch.vtensor<[768,3072],f32>
    %1897 = torch.aten.mm %1895, %1896 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768,3072],f32> -> !torch.vtensor<[64,3072],f32>
    %int1_2014 = torch.constant.int 1
    %1898 = torch.aten.mul.Scalar %1897, %int1_2014 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int1_2015 = torch.constant.int 1
    %1899 = torch.aten.mul.Scalar %1894, %int1_2015 : !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[3072],f32>
    %int1_2016 = torch.constant.int 1
    %1900 = torch.aten.add.Tensor %1898, %1899, %int1_2016 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int5_2017 = torch.constant.int 5
    %1901 = torch.prims.convert_element_type %1900, %int5_2017 : !torch.vtensor<[64,3072],f32>, !torch.int -> !torch.vtensor<[64,3072],f16>
    %int1_2018 = torch.constant.int 1
    %int64_2019 = torch.constant.int 64
    %int3072_2020 = torch.constant.int 3072
    %1902 = torch.prim.ListConstruct %int1_2018, %int64_2019, %int3072_2020 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1903 = torch.aten.view %1901, %1902 : !torch.vtensor<[64,3072],f16>, !torch.list<int> -> !torch.vtensor<[1,64,3072],f16>
    %float1.702000e00_2021 = torch.constant.float 1.702000e+00
    %1904 = torch.aten.mul.Scalar %1903, %float1.702000e00_2021 : !torch.vtensor<[1,64,3072],f16>, !torch.float -> !torch.vtensor<[1,64,3072],f16>
    %1905 = torch.aten.sigmoid %1904 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1906 = torch.aten.detach %1905 : !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %1907 = torch.aten.mul.Tensor %1903, %1905 : !torch.vtensor<[1,64,3072],f16>, !torch.vtensor<[1,64,3072],f16> -> !torch.vtensor<[1,64,3072],f16>
    %int64_2022 = torch.constant.int 64
    %int3072_2023 = torch.constant.int 3072
    %1908 = torch.prim.ListConstruct %int64_2022, %int3072_2023 : (!torch.int, !torch.int) -> !torch.list<int>
    %1909 = torch.aten.view %1907, %1908 : !torch.vtensor<[1,64,3072],f16>, !torch.list<int> -> !torch.vtensor<[64,3072],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc2.weight = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc2.weight : tensor<768x3072xf16>
    %1910 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc2.weight : tensor<768x3072xf16> -> !torch.vtensor<[768,3072],f16>
    %int0_2024 = torch.constant.int 0
    %int1_2025 = torch.constant.int 1
    %1911 = torch.aten.transpose.int %1910, %int0_2024, %int1_2025 : !torch.vtensor<[768,3072],f16>, !torch.int, !torch.int -> !torch.vtensor<[3072,768],f16>
    %_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc2.bias = util.global.load @_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc2.bias : tensor<768xf16>
    %1912 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.encoder.layers.11.mlp.fc2.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int6_2026 = torch.constant.int 6
    %1913 = torch.prims.convert_element_type %1912, %int6_2026 : !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[768],f32>
    %int6_2027 = torch.constant.int 6
    %1914 = torch.prims.convert_element_type %1909, %int6_2027 : !torch.vtensor<[64,3072],f16>, !torch.int -> !torch.vtensor<[64,3072],f32>
    %int6_2028 = torch.constant.int 6
    %1915 = torch.prims.convert_element_type %1911, %int6_2028 : !torch.vtensor<[3072,768],f16>, !torch.int -> !torch.vtensor<[3072,768],f32>
    %1916 = torch.aten.mm %1914, %1915 : !torch.vtensor<[64,3072],f32>, !torch.vtensor<[3072,768],f32> -> !torch.vtensor<[64,768],f32>
    %int1_2029 = torch.constant.int 1
    %1917 = torch.aten.mul.Scalar %1916, %int1_2029 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int1_2030 = torch.constant.int 1
    %1918 = torch.aten.mul.Scalar %1913, %int1_2030 : !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[768],f32>
    %int1_2031 = torch.constant.int 1
    %1919 = torch.aten.add.Tensor %1917, %1918, %int1_2031 : !torch.vtensor<[64,768],f32>, !torch.vtensor<[768],f32>, !torch.int -> !torch.vtensor<[64,768],f32>
    %int5_2032 = torch.constant.int 5
    %1920 = torch.prims.convert_element_type %1919, %int5_2032 : !torch.vtensor<[64,768],f32>, !torch.int -> !torch.vtensor<[64,768],f16>
    %int1_2033 = torch.constant.int 1
    %int64_2034 = torch.constant.int 64
    %int768_2035 = torch.constant.int 768
    %1921 = torch.prim.ListConstruct %int1_2033, %int64_2034, %int768_2035 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1922 = torch.aten.view %1920, %1921 : !torch.vtensor<[64,768],f16>, !torch.list<int> -> !torch.vtensor<[1,64,768],f16>
    %int1_2036 = torch.constant.int 1
    %1923 = torch.aten.add.Tensor %1875, %1922, %int1_2036 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int6_2037 = torch.constant.int 6
    %1924 = torch.prims.convert_element_type %1923, %int6_2037 : !torch.vtensor<[1,64,768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int2_2038 = torch.constant.int 2
    %1925 = torch.prim.ListConstruct %int2_2038 : (!torch.int) -> !torch.list<int>
    %int0_2039 = torch.constant.int 0
    %true_2040 = torch.constant.bool true
    %result0_2041, %result1_2042 = torch.aten.var_mean.correction %1924, %1925, %int0_2039, %true_2040 : !torch.vtensor<[1,64,768],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,64,1],f32>, !torch.vtensor<[1,64,1],f32>
    %float1.000000e-05_2043 = torch.constant.float 1.000000e-05
    %int1_2044 = torch.constant.int 1
    %1926 = torch.aten.add.Scalar %result0_2041, %float1.000000e-05_2043, %int1_2044 : !torch.vtensor<[1,64,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,64,1],f32>
    %1927 = torch.aten.rsqrt %1926 : !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,1],f32>
    %int1_2045 = torch.constant.int 1
    %1928 = torch.aten.sub.Tensor %1923, %result1_2042, %int1_2045 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %1929 = torch.aten.mul.Tensor %1928, %1927 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[1,64,1],f32> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.final_layer_norm.weight = util.global.load @_params.text_encoder_model.text_model.final_layer_norm.weight : tensor<768xf16>
    %1930 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.final_layer_norm.weight : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %1931 = torch.aten.mul.Tensor %1929, %1930 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16> -> !torch.vtensor<[1,64,768],f32>
    %_params.text_encoder_model.text_model.final_layer_norm.bias = util.global.load @_params.text_encoder_model.text_model.final_layer_norm.bias : tensor<768xf16>
    %1932 = torch_c.from_builtin_tensor %_params.text_encoder_model.text_model.final_layer_norm.bias : tensor<768xf16> -> !torch.vtensor<[768],f16>
    %int1_2046 = torch.constant.int 1
    %1933 = torch.aten.add.Tensor %1931, %1932, %int1_2046 : !torch.vtensor<[1,64,768],f32>, !torch.vtensor<[768],f16>, !torch.int -> !torch.vtensor<[1,64,768],f32>
    %int5_2047 = torch.constant.int 5
    %1934 = torch.prims.convert_element_type %1933, %int5_2047 : !torch.vtensor<[1,64,768],f32>, !torch.int -> !torch.vtensor<[1,64,768],f16>
    %int5_2048 = torch.constant.int 5
    %1935 = torch.prims.convert_element_type %result1_2042, %int5_2048 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int5_2049 = torch.constant.int 5
    %1936 = torch.prims.convert_element_type %1927, %int5_2049 : !torch.vtensor<[1,64,1],f32>, !torch.int -> !torch.vtensor<[1,64,1],f16>
    %int1_2050 = torch.constant.int 1
    %none_2051 = torch.constant.none
    %none_2052 = torch.constant.none
    %cpu_2053 = torch.constant.device "cpu"
    %false_2054 = torch.constant.bool false
    %1937 = torch.aten.arange %int1_2050, %none_2051, %none_2052, %cpu_2053, %false_2054 : !torch.int, !torch.none, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[1],si64>
    %int3_2055 = torch.constant.int 3
    %1938 = torch.prims.convert_element_type %1, %int3_2055 : !torch.vtensor<[1,64],si64>, !torch.int -> !torch.vtensor<[1,64],si32>
    %int-1_2056 = torch.constant.int -1
    %false_2057 = torch.constant.bool false
    %1939 = torch.aten.argmax %1938, %int-1_2056, %false_2057 : !torch.vtensor<[1,64],si32>, !torch.int, !torch.bool -> !torch.vtensor<[1],si64>
    %1940 = torch.prim.ListConstruct %1937, %1939 : (!torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.list<optional<vtensor>>
    %1941 = torch.aten.index.Tensor %1934, %1940 : !torch.vtensor<[1,64,768],f16>, !torch.list<optional<vtensor>> -> !torch.vtensor<[1,768],f16>
    return %1765, %1934 : !torch.vtensor<[1,64,768],f16>, !torch.vtensor<[1,64,768],f16>
  }
}

{-#
  dialect_resources: {
    builtin: {
      torch_tensor_1_77_torch.int64: "0x0800000000000000000000000100000000000000020000000000000003000000000000000400000000000000050000000000000006000000000000000700000000000000080000000000000009000000000000000A000000000000000B000000000000000C000000000000000D000000000000000E000000000000000F0000000000000010000000000000001100000000000000120000000000000013000000000000001400000000000000150000000000000016000000000000001700000000000000180000000000000019000000000000001A000000000000001B000000000000001C000000000000001D000000000000001E000000000000001F0000000000000020000000000000002100000000000000220000000000000023000000000000002400000000000000250000000000000026000000000000002700000000000000280000000000000029000000000000002A000000000000002B000000000000002C000000000000002D000000000000002E000000000000002F0000000000000030000000000000003100000000000000320000000000000033000000000000003400000000000000350000000000000036000000000000003700000000000000380000000000000039000000000000003A000000000000003B000000000000003C000000000000003D000000000000003E000000000000003F0000000000000040000000000000004100000000000000420000000000000043000000000000004400000000000000450000000000000046000000000000004700000000000000480000000000000049000000000000004A000000000000004B000000000000004C00000000000000"
    }
  }
#-}
